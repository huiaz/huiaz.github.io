<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-bounce.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hui&#39;s Blog">
<meta property="og:url" content="http://example.com/page/11/index.html">
<meta property="og:site_name" content="Hui&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="六一">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/11/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Hui's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hui's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Code Life</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/Nginx/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/Nginx/" class="post-title-link" itemprop="url">Nginx</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:50:51" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/WEB/" itemprop="url" rel="index"><span itemprop="name">WEB</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/WEB/Nginx/" itemprop="url" rel="index"><span itemprop="name">Nginx</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>你好！作为一名运维工程师，我来为你详细解释一下 Nginx。</p>
<h3 id="Nginx-是什么？"><a href="#Nginx-是什么？" class="headerlink" title="Nginx 是什么？"></a>Nginx 是什么？</h3><p>Nginx是一个高性能的、免费开源的 <strong>Web 服务器</strong> 和 <strong>反向代理服务器</strong>，也可以用作 <strong>负载均衡器</strong> 和 <strong>HTTP 缓存</strong>。</p>
<p>Nginx 采用了<strong>事件驱动（event-driven）</strong>的异步非阻塞架构。这种架构使得 Nginx 在处理大量并发连接时，能够以极低的内存消耗和 CPU 占用率提供卓越的性能。</p>
<p><strong>主要特点：</strong></p>
<ul>
<li><strong>高性能和高并发：</strong> Nginx 的核心优势在于其事件驱动架构，能够以极低的资源消耗处理大量并发连接。</li>
<li><strong>低内存消耗：</strong> 即使在处理数万个并发请求时，Nginx 也只需要极少的内存。</li>
<li><strong>高可靠性：</strong> 即使在面对高负载时也能保持稳定运行。</li>
<li><strong>模块化设计：</strong> 易于扩展和维护。</li>
<li><strong>支持多种协议：</strong> 不仅支持 HTTP，还支持 HTTPS、SMTP、POP3、IMAP 等。</li>
<li><strong>反向代理能力：</strong> 可以将客户端请求转发到后端服务器，提高安全性、性能和可扩展性。</li>
<li><strong>负载均衡：</strong> 可以将流量分配到多个后端服务器，提高系统可用性和吞吐量。</li>
<li><strong>HTTP 缓存：</strong> 可以缓存静态或动态内容，减少后端服务器的压力并加速响应。</li>
</ul>
<h3 id="Nginx-有哪些应用场景？"><a href="#Nginx-有哪些应用场景？" class="headerlink" title="Nginx 有哪些应用场景？"></a>Nginx 有哪些应用场景？</h3><p>Nginx 的多功能性和高性能使其在各种复杂的 IT 架构中扮演着核心角色。以下是一些常见的应用场景：</p>
<ol>
<li><p><strong>静态文件服务和内容分发：</strong></p>
<ul>
<li><strong>网站和应用程序的静态资源：</strong> Nginx 是提供静态文件（HTML、CSS、JavaScript、图片、视频、字体等）的理想选择。其高效的事件驱动架构使其在处理大量小文件和高并发请求时表现出色。</li>
<li><strong>CDN 节点：</strong> 许多内容分发网络（CDN）使用 Nginx 作为边缘节点，将内容缓存并快速分发到离用户最近的位置。</li>
</ul>
</li>
<li><p><strong>反向代理服务器：</strong></p>
<ul>
<li><strong>隐藏后端服务器：</strong> 将用户的请求转发到后端（如 Apache、Tomcat、Node.js、Django、PHP-FPM、Golang 应用等）服务器，同时隐藏后端服务器的真实 IP 地址和端口，增加安全性。</li>
<li><strong>统一访问入口：</strong> 多个后台服务可以通过一个 Nginx 实例对外提供服务，简化客户端的访问。</li>
<li><strong>SSL&#x2F;TLS 卸载：</strong> 在 Nginx 上终止 SSL 连接，将解密后的请求转发给后端服务器，减轻后端服务器的加密&#x2F;解密负担，提高后端服务器的性能。</li>
<li><strong>A&#x2F;B 测试和灰度发布：</strong> 根据配置规则将一部分流量转发到新版本或测试版本的后端服务，实现渐进式发布。</li>
</ul>
</li>
<li><p><strong>负载均衡器：</strong></p>
<ul>
<li><strong>提高可用性：</strong> 当一个后端服务器出现故障时，Nginx 会自动将流量转发到其他健康的服务器，确保服务不中断。</li>
<li><strong>扩展性：</strong> 随着业务增长，可以通过增加后端服务器来扩展服务能力，Nginx 负责将流量均匀分配给它们。</li>
<li><strong>提高吞吐量：</strong> 将请求分发到多台服务器上并行处理，显著提高系统处理能力。</li>
<li><strong>支持多种负载均衡算法：</strong> 如轮询（round-robin）、IP Hash、least_conn（最少连接）、weight（加权轮询）等。</li>
</ul>
</li>
<li><p><strong>API 网关：</strong></p>
<ul>
<li><strong>路由和转发：</strong> 根据 URL 路径或 HTTP 头将请求路由到不同的微服务。</li>
<li><strong>鉴权和认证：</strong> 在请求到达后端服务之前进行用户身份验证和授权。</li>
<li><strong>限流：</strong> 限制单位时间内对 API 的访问次数，防止恶意攻击或系统过载。</li>
<li><strong>日志记录和监控：</strong> 收集 API 请求和响应的日志，便于监控和故障排查。</li>
</ul>
</li>
<li><p><strong>HTTP 缓存：</strong></p>
<ul>
<li><strong>加速响应：</strong> 将经常访问的静态或动态内容缓存在 Nginx 上，当用户再次请求时，直接从缓存返回，无需再次请求后端服务器，大大缩短了响应时间。</li>
<li><strong>减轻后端服务器压力：</strong> 尤其是对于那些计算密集型或数据库查询密集型的请求，缓存可以显著减少后端服务器的负载。</li>
</ul>
</li>
<li><p><strong>Web 应用防火墙 (WAF) 前置：</strong></p>
<ul>
<li>虽然 Nginx 本身不是专业的 WAF，但可以通过集成 OpenResty 或 Nginx 模块来实现一些基本的安全功能，如 IP 限制、请求体大小限制、URL 重写以防止某些攻击模式。</li>
</ul>
</li>
<li><p><strong>流媒体服务器：</strong></p>
<ul>
<li>Nginx 可以通过第三方模块支持 RTMP（Real-Time Messaging Protocol），用于直播和点播流媒体服务。</li>
</ul>
</li>
</ol>
<p><strong>总结来说，无论是在小型网站、中型应用，还是大规模的分布式系统和微服务架构中，Nginx 都扮演着至关重要的角色。它的高性能、高可靠性和灵活性，使其成为现代 Web 架构中不可或缺的组件。作为运维工程师，熟练掌握 Nginx 的配置和优化，是保障系统稳定高效运行的关键。</strong></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/OPA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/OPA/" class="post-title-link" itemprop="url">OPA</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:50:59" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">配置管理</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>19k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>18 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="OPA-策略引擎"><a href="#OPA-策略引擎" class="headerlink" title="OPA 策略引擎"></a>OPA 策略引擎</h1><p><a target="_blank" rel="noopener" href="https://www.openpolicyagent.org/">Open Policy Agent</a> 简称 OPA，是一种开源的通用策略代理引擎，是 CNCF 毕业的项目。OPA 提供了一种高级声明式语言 Rego，简化了策略规则的定义，以减轻程序中策略的决策负担。在微服务、Kubernetes、CI&#x2F;CD、API 网关等场景中均可以使用 OPA 来定义策略。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/p98vq1.png" alt="集成OPA"></p>
<p>我们这里主要讲解在 Kubernetes 中如何集成 OPA，在 Kubernetes 中 OPA 是通过 Admission Controllers 来实现安全策略的。事实上使用 Pod 安全策略（要废弃了）来执行我们的安全策略并没有什么问题，然而，根据定义，PSP 只能应用于 pods。它们不能处理其他 Kubernetes 资源，如 Ingresses、Deployments、Services 等，OPA 的强大之处在于它可以应用于任何 Kubernetes 资源。OPA 作为一个准入控制器部署到 Kubernetes，它拦截发送到 APIServer 的 API 调用，并验证和&#x2F;或修改它们。你可以有一个统一的 OPA 策略，适用于系统的不同组件，而不仅仅是 pods，例如，有一种策略，强制用户在其服务中使用公司的域，并确保用户只从公司的镜像仓库中拉取镜像。</p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>OPA 将策略决策与策略执行分离，当应用需要做出策略决策时，它会查询 OPA 并提供结构化数据（例如 JSON）作为输入，OPA 接受任意结构化数据作为输入。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/0khzif.png" alt="OPA decouples"></p>
<p>OPA 通过评估查询输入策略和数据来生成策略决策，你可以在你的策略中描述几乎任何的不变因素，例如：</p>
<ul>
<li>哪些用户可以访问哪些资源</li>
<li>哪些子网的出口流量被允许</li>
<li>工作负载必须部署到哪些集群</li>
<li>二进制文件可以从哪里下载</li>
<li>容器可以用哪些操作系统的能力来执行</li>
<li>系统在一天中的哪些时间可以被访问</li>
</ul>
<p>策略决定不限于简单的<strong>是&#x2F;否或允许&#x2F;拒绝</strong>，与查询输入一样，你的策略可以生成任意结构化数据作为输出。 让我们看一个例子。OPA 的策略是用一种叫做 Rego 的高级声明性语言来声明的，Rego 是专门为表达复杂的分层数据结构的策略而设计的。</p>
<p>在 Kubernetes 中，准入控制器在创建、更新和删除操作期间对对象实施策略。准入控制是 Kubernetes 中策略执行的基础。通过将 OPA 部署为准入控制器，可以：</p>
<ul>
<li>要求在所有资源上使用特定标签</li>
<li>要求容器镜像来自企业镜像仓库</li>
<li>要求所有 Pod 指定资源请求和限制</li>
<li>防止创建冲突的 Ingress 对象</li>
<li>……</li>
</ul>
<p>Kubernetes APIServer 配置为在创建、更新或删除对象时查询 OPA 以获取准入控制策略。APIServer 将 webhook 请求中的整个对象发送给 OPA，OPA 使用准入审查作为输入来评估它已加载的策略。这个其实和我们自己去实现一个准入控制器是类似的，只是不需要我们去编写代码，只需要编写策略规则，OPA 就可以根据我们的规则去对输入的对象进行验证。</p>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>接下来我们介绍下如何在 Kubernetes 集群中集成 OPA，由于 Kubernetes 中是通过准入控制器来集成 OPA 的，所以我们必须在集群中启用 <code>ValidatingAdmissionWebhook</code> 这个准入控制器。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/zzls81.png" alt="Admission"></p>
<p>首先创建一个名为 <code>opa</code> 的命名空间，可以让 OPA 从该命名空间中的 ConfigMap 去加载策略：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl create namespace opa</span><br></pre></td></tr></table></figure>



<p>并将上下文更改为 opa 命名空间：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl config current-context</span><br><span class="line">kubernetes-admin@kubernetes</span><br><span class="line">➜ kubectl config set-context kubernetes-admin@kubernetes --namespace=opa</span><br><span class="line">Context &quot;kubernetes-admin@kubernetes&quot; modified.</span><br><span class="line">➜ kubectl get pods</span><br><span class="line">No resources found in opa namespace.</span><br></pre></td></tr></table></figure>



<p>为了保护 APIServer 和 OPA 之间的通信，我们需要配置 TLS 证书。</p>
<ol>
<li>创建证书颁发机构和密钥：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ openssl genrsa -out ca.key 2048</span><br><span class="line">➜ openssl req -x509 -new -nodes -key ca.key -days 100000 -out ca.crt -subj &quot;/CN=admission_ca&quot;</span><br></pre></td></tr></table></figure>



<ol>
<li>为 OPA 生成密钥和证书：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;server.conf &lt;&lt;EOF</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[ v3_req ]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation, digitalSignature, keyEncipherment</span><br><span class="line">extendedKeyUsage = clientAuth, serverAuth</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[ alt_names ]</span><br><span class="line">DNS.1 = opa.opa.svc</span><br><span class="line">EOF</span><br><span class="line">➜ openssl genrsa -out server.key 2048</span><br><span class="line">➜ openssl req -new -key server.key -out server.csr -subj &quot;/CN=opa.opa.svc&quot; -config server.conf</span><br><span class="line">➜ openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 100000 -extensions v3_req -extfile server.conf</span><br></pre></td></tr></table></figure>



<ol>
<li>创建一个 Kubernetes TLS Secret 来存储我们的 OPA 凭证：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl create secret tls opa-server --cert=server.crt --key=server.key</span><br></pre></td></tr></table></figure>



<p>证书准备好后就可以部署准入控制器了，对应的资源清单文件如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># opa-admission-controller.yaml</span></span><br><span class="line"><span class="comment"># Grant OPA/kube-mgmt read-only access to resources. This lets kube-mgmt</span></span><br><span class="line"><span class="comment"># replicate resources into OPA so they can be used in policies.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">opa-viewer</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">view</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">system:serviceaccounts:opa</span></span><br><span class="line">    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Define role for OPA/kube-mgmt to update configmaps with policy status.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">configmap-modifier</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&#x27;&#x27;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&#x27;configmaps&#x27;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&#x27;update&#x27;</span>, <span class="string">&#x27;patch&#x27;</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Grant OPA/kube-mgmt role defined above.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">opa-configmap-modifier</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">configmap-modifier</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">system:serviceaccounts:opa</span></span><br><span class="line">    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">opa</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">443</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">opa</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">opa</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">opa</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">openpolicyagent/opa:latest</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;run&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--server&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--tls-cert-file=/certs/tls.crt&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--tls-private-key-file=/certs/tls.key&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--addr=0.0.0.0:443&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--addr=http://127.0.0.1:8181&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--log-level=debug&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;--log-format=json-pretty&#x27;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/certs</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">opa-server</span></span><br><span class="line">          <span class="attr">readinessProbe:</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/health</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTPS</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">          <span class="attr">livenessProbe:</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/health</span></span><br><span class="line">              <span class="attr">scheme:</span> <span class="string">HTTPS</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">15</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-mgmt</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">openpolicyagent/kube-mgmt:4.0.0</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--replicate-cluster=v1/namespaces</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--replicate=networking.k8s.io/v1/ingresses</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--opa-url=http://127.0.0.1:8181/v1</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--enable-data=true</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--enable-policies=true</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--policies=opa</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--require-policy-label=true</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">opa-server</span></span><br><span class="line">          <span class="attr">secret:</span></span><br><span class="line">            <span class="attr">secretName:</span> <span class="string">opa-server</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">opa-default-system-main</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">opa</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">openpolicyagent.org/policy:</span> <span class="string">rego</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">main:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    package system</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">    <span class="string">import</span> <span class="string">data.kubernetes.admission</span></span><br><span class="line"></span><br><span class="line">    <span class="string">main</span> <span class="string">=</span> &#123;</span><br><span class="line">      <span class="attr">&quot;apiVersion&quot;:</span> <span class="string">&quot;admission.k8s.io/v1&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;kind&quot;:</span> <span class="string">&quot;AdmissionReview&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;response&quot;:</span> <span class="string">response</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="string">default</span> <span class="string">uid</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="string">uid</span> <span class="string">=</span> <span class="string">input.request.uid</span></span><br><span class="line">    <span class="string">response</span> <span class="string">=</span> &#123;</span><br><span class="line">        <span class="attr">&quot;allowed&quot;:</span> <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">&quot;uid&quot;:</span> <span class="string">uid</span>,</span><br><span class="line">        <span class="attr">&quot;status&quot;:</span> &#123;</span><br><span class="line">            <span class="attr">&quot;message&quot;:</span> <span class="string">reason</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125; &#123;</span><br><span class="line">        <span class="string">reason</span> <span class="string">=</span> <span class="string">concat(&quot;</span>, <span class="string">&quot;, admission.deny)</span></span><br><span class="line"><span class="string">        reason != &quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    else = &#123;&quot;</span><span class="string">allowed&quot;:</span> <span class="literal">true</span>, <span class="attr">&quot;uid&quot;:</span> <span class="string">uid</span>&#125;</span><br></pre></td></tr></table></figure>



<p>上面的资源清单中我们添加了一个 <code>kube-mgmt</code> 的 Sidecar 容器，该容器可以将 ConfigMap 对象中的策略动态加载到 OPA 中，<code>kube-mgmt</code> 容器还可以将任何其他 Kubernetes 对象作为 JSON 数据加载到 OPA 中。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/nobebs.png" alt="kube-mgmt"></p>
<p>另外需要注意的是 Service 的名称（opa）必须与我们证书配置的 CN 匹配，否则 TLS 通信会失败。在 <code>kube-mgmt</code> 容器中还指定了以下命令行参数：</p>
<ul>
<li>–replicate-cluster&#x3D;v1&#x2F;namespaces</li>
<li>–replicate&#x3D;networking.k8s.io&#x2F;v1&#x2F;ingresses</li>
<li>–enable-policies&#x3D;true</li>
<li>–policies&#x3D;opa</li>
<li>–require-policy-label&#x3D;true</li>
</ul>
<p>前两个参数允许 sidecar 容器复制命名空间、Ingress 对象，并将它们加载到 OPA 引擎中，<code>enable-policies=true</code> 表示会通过 Configmap 加载 OPA 策略，下面的 <code>--policies=opa</code> 表示从 <code>opa</code> 命名空间中的 Configmap 来加载策略，如果还配置了 <code>--require-policy-label=true</code> 参数，则需要 Configmap 中带有 <code>openpolicyagent.org/policy=rego</code> 这个标签才会被自动加载。</p>
<p>现在直接应用上面的资源清单即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f opa-admission-controller.yaml</span><br><span class="line">➜ kubectl get pods</span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">opa-6cd68f74f-s9zcv   2/2     Running   0          5m28s</span><br></pre></td></tr></table></figure>



<p>为了让准入控制器工作，我们还需要一个准入 webhook 来接收准入 HTTP 回调并执行它们，创建如下所示的 webhook 配置文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">➜ cat &gt; webhook-configuration.yaml &lt;&lt;EOF</span><br><span class="line">kind: ValidatingWebhookConfiguration</span><br><span class="line">apiVersion: admissionregistration.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: opa-validating-webhook</span><br><span class="line">webhooks:</span><br><span class="line">  - name: validating-webhook.openpolicyagent.org</span><br><span class="line">    admissionReviewVersions: [&quot;v1&quot;, &quot;v1beta1&quot;]</span><br><span class="line">    namespaceSelector:</span><br><span class="line">      matchExpressions:</span><br><span class="line">      - key: openpolicyagent.org/webhook</span><br><span class="line">        operator: NotIn</span><br><span class="line">        values:</span><br><span class="line">        - ignore</span><br><span class="line">    failurePolicy: Ignore</span><br><span class="line">    rules:</span><br><span class="line">      - apiGroups:</span><br><span class="line">        - &#x27;*&#x27;</span><br><span class="line">        apiVersions:</span><br><span class="line">        - &#x27;*&#x27;</span><br><span class="line">        operations:</span><br><span class="line">        - &#x27;*&#x27;</span><br><span class="line">        resources:</span><br><span class="line">        - &#x27;*&#x27;</span><br><span class="line">    sideEffects: None</span><br><span class="line">    clientConfig:</span><br><span class="line">      caBundle: $(cat ca.crt | base64 | tr -d &#x27;\n&#x27;)</span><br><span class="line">      service:</span><br><span class="line">        namespace: opa</span><br><span class="line">        name: opa</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<p>上面的 webhook 中配置了以下属性：</p>
<ul>
<li>不会监听来自带有 <code>openpolicyagent.org/webhook=ignore</code> 标签的命名空间的操作</li>
<li>会监听所有资源上的 CREATE 和 UPDATE 操作</li>
<li>它使用我们之前创建的 CA 证书，以便能够与 OPA 通信</li>
</ul>
<p>现在，在使用配置之前，我们标记 <code>kube-system</code> 和 <code>opa</code> 命名空间，使它们不在 webhook 范围内：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl label ns kube-system openpolicyagent.org/webhook=ignore</span><br><span class="line">➜ kubectl label ns opa openpolicyagent.org/webhook=ignore</span><br></pre></td></tr></table></figure>



<p>然后应用上面的配置对象将 OPA 注册为准入控制器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f webhook-configuration.yaml</span><br><span class="line">➜ kubectl get pods</span><br><span class="line">NAME                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">opa-6cd68f74f-s9zcv   2/2     Running   0          72m</span><br><span class="line">➜ kubectl get validatingwebhookconfiguration</span><br><span class="line">NAME                                      WEBHOOKS   AGE</span><br><span class="line">opa-validating-webhook                    1          2m14s</span><br></pre></td></tr></table></figure>



<h2 id="策略示例"><a href="#策略示例" class="headerlink" title="策略示例"></a>策略示例</h2><p>OPA 使用 Rego 语言来描述策略，这里我们使用官方文档中提到的示例来进行说明，创建一个限制 Ingress 可以使用的主机名策略，只允许匹配指定正则表达式的主机名。</p>
<p>创建如下所示名为 <code>ingress-allowlist.rego</code> 的策略文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 在这里，我们声明规则属于什么包，这与其他语言的包装类似，是将类似规则归入同一命名空间的一种方式。 --&gt;</span><br><span class="line">package kubernetes.admission</span><br><span class="line"></span><br><span class="line">import data.kubernetes.namespaces</span><br><span class="line"></span><br><span class="line">operations = &#123;&quot;CREATE&quot;, &quot;UPDATE&quot;&#125;</span><br><span class="line"></span><br><span class="line">deny[msg] &#123;</span><br><span class="line">    input.request.kind.kind == &quot;Ingress&quot;</span><br><span class="line">    operations[input.request.operation]</span><br><span class="line">    host := input.request.object.spec.rules[_].host</span><br><span class="line">    not fqdn_matches_any(host, valid_ingress_hosts)</span><br><span class="line">    msg := sprintf(&quot;invalid ingress host %q&quot;, [host])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">valid_ingress_hosts = &#123;host |</span><br><span class="line">    allowlist := namespaces[input.request.namespace].metadata.annotations[&quot;ingress-allowlist&quot;]</span><br><span class="line">    hosts := split(allowlist, &quot;,&quot;)</span><br><span class="line">    host := hosts[_]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fqdn_matches_any(str, patterns) &#123;</span><br><span class="line">    fqdn_matches(str, patterns[_])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fqdn_matches(str, pattern) &#123;</span><br><span class="line">    pattern_parts := split(pattern, &quot;.&quot;)</span><br><span class="line">    pattern_parts[0] == &quot;*&quot;</span><br><span class="line">    str_parts := split(str, &quot;.&quot;)</span><br><span class="line">    n_pattern_parts := count(pattern_parts)</span><br><span class="line">    n_str_parts := count(str_parts)</span><br><span class="line">    suffix := trim(pattern, &quot;*.&quot;)</span><br><span class="line">    endswith(str, suffix)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fqdn_matches(str, pattern) &#123;</span><br><span class="line">    not contains(pattern, &quot;*&quot;)</span><br><span class="line">    str == pattern</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>如果你是 Rego 新手，上面的代码看上去可能有点陌生，但 Rego 让定义策略变得非常容易，我们来分析下这个策略是如何使用白名单中的 Ingress 命名空间强制执行的：</p>
<ul>
<li><p>第 1 行：<code>package</code> 的使用方式与在其他语言中的使用方式是一样的</p>
</li>
<li><p>第 5 行：我们定义一个包含两项操作的数据集：<code>CREATE</code> 和 <code>UPDATE</code></p>
</li>
<li><p>第 7 行：这是策略的核心部分，以 <code>deny</code> 开头，然后是策略正文。如果正文中的语句组合评估为真，则违反策略，便会阻止操作，并将消息返回给用户，说明操作被阻止的原因</p>
</li>
<li><p>第 8 行：指定输入对象，发送到 OPA 的任何 JSON 消息都是从输入对象的根部开始的，我们遍历 JSON 对象，直到找到有问题的资源，并且它必须是 <code>Ingress</code> 才能应用该策略</p>
</li>
<li><p>第 9 行：我们需要应用策略来创建或更新资源，在 Rego 中，我们可以通过使用 <code>operations[input.requset.operations]</code> 来实现，方括号内的代码会提取请求中指定的操作，如果它与第 5 行的操作集中定义的元素相匹配，则该语句为真</p>
</li>
<li><p>第 10 行：为了提取 Ingress 对象的 host 信息，我们需要迭代 JSON 对象的 rules 数组，同样 Rego 提供了 <code>_</code> 字符来循环浏览数组，并将所有元素返回到 <code>host</code> 变量中</p>
</li>
<li><p>第 11 行：现在我们有了 host 变量，我们需要确保它不是列入白名单的主机，要记住，只有在评估为 true 时才会违反该策略，为了检查主机是否有效，我们使用第 21 行中定义的 <code>fqdn_matches_any</code> 函数</p>
</li>
<li><p>第 12 行：定义应返回给用户的消息，说明无法创建 Ingress 对象的原因</p>
</li>
<li><p>第 15-19 行：这部分从 Ingress 命名空间的 <code>annotations</code> 中提取列入白名单的主机名，主机名添加在逗号分隔的列表中，使用 <code>split</code> 内置函数用于将其转换为列表。最后，<code>_</code> 用于遍历所有提取的主机列表，将结果通过 <code>|</code> 管道传送给 <code>host</code> 变量（这与 Python 中的列表推导非常类似）</p>
</li>
<li><p>第 21 行：该函数只接受一个字符串，并在一个 patterns 列表中搜索它，这是第二个参数。实际上是调用的下方的 <code>fqdn_matches</code> 函数来实现的。在 Rego 中，<strong>可以定义具有多个相同名称的函数</strong>，只要它们都产生相同的输出，当调用多次定义的函数时，将调用该函数的所有实例</p>
</li>
<li><p>第 25-33 行：第一个</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">fqdn_matches</span></span><br></pre></td></tr></table></figure>

<p>函数的定义。</p>
<ul>
<li>首先它通过点 <code>.</code> 将 pattern 进行拆分，比如 <code>*.example.com</code> 会分割成 <code>*</code>、<code>example</code> 和 <code>com</code></li>
<li>接下来确保 pattern 的第一个标记是星号，同样对输入的字符串按照 <code>.</code> 进行拆分</li>
<li>删除 pattern 中的 <code>*.</code></li>
<li>最后评估输入字符串是否以后缀结尾，比如如果允许的模式字符串是 <code>*.mydomain.com</code>，被评估的字符串是 <code>www.example.com</code>，则违反了该策略，因为该字符串不是 <code>mydomain.com</code> 的一部分</li>
</ul>
</li>
<li><p>第 35-38 行：第二个验证函数，该函数用于验证不使用通配符的模式，例如，当模式写为</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mycompany<span class="selector-class">.mydomain</span>.com</span><br></pre></td></tr></table></figure>

<p>的时候</p>
<ul>
<li>首先，需要确保提供的模式不包含通配符，否则，该语句将评估为 false 并且函数将不会继续</li>
<li>如果模式指的是特定的域名，那么我们只需要确保 fqdn 与该模式匹配。换句话说，如果模式是 <code>mycompany.mydomain.com</code>，那么主机的 fqdn 也必须是 <code>mycompany.mydomain.com</code></li>
</ul>
</li>
</ul>
<p>我们之所以有两个具有相同名称的函数，是因为 Rego 语言的一个限制，它会阻止函数产生一个以上的输出结果，所以，要想在同一时间用不同的逻辑进行多个验证，必须使用多个同名的函数。</p>
<p>在生产环境中，在将 Rego 代码应用到集群之前一定要进行全方位测试，比如可以添加单元测试，同时也可以使用 <a target="_blank" rel="noopener" href="https://play.openpolicyagent.org/">Rego Playground</a> 来对代码进行验证。</p>
<p>要将该策略应用于集群，我们需要将上面的 Rego 文件以 Configmap 的形式应用到 opa 命名空间中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl create configmap ingress-allowlist --from-file=ingress-allowlist.rego</span><br><span class="line">➜ kubectl label  configmap ingress-allowlist openpolicyagent.org/policy=rego</span><br></pre></td></tr></table></figure>



<p>由于我们开启了 <code>--require-policy-label</code> 参数，所以还需要带上对应的标签。创建完成后最好检查下我们的策略是否被 OPA 获取了，并且没有语法错误，可以通过检查 ConfigMap 的状态来判断：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get cm ingress-allowlist  -o json | jq &#x27;.metadata.annotations&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;openpolicyagent.org/policy-status&quot;: &quot;&#123;\&quot;status\&quot;:\&quot;ok\&quot;&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>接下来，让我们创建两个命名空间，一个用于 QA 环境，另一个用于生产环境。要注意它们都包含 <code>ingress-allowlist</code> 注解，其中包含 Ingress 主机名应该匹配的模式。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># qa-namespace.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">ingress-allowlist:</span> <span class="string">&#x27;*.qa.qikqiak.com,*.internal.qikqiak.com&#x27;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">qa</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># production-namespace.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">ingress-allowlist:</span> <span class="string">&#x27;*.qikqiak.com&#x27;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">production</span></span><br></pre></td></tr></table></figure>



<p>直接应用上面的两个资源清单文件即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f qa-namespace.yaml -f production-namespace.yaml</span><br></pre></td></tr></table></figure>



<p>接下来让我们创建一个被策略允许的 Ingress 对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f - &lt;&lt;EOT</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-ok</span><br><span class="line">  namespace: production</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: prod.qikqiak.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx</span><br><span class="line">            port:</span><br><span class="line">              number: 80</span><br><span class="line">        path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">EOT</span><br></pre></td></tr></table></figure>



<p>正常上面的资源对象可以创建：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get ing -n production</span><br><span class="line">NAME         CLASS   HOSTS              ADDRESS   PORTS   AGE</span><br><span class="line">ingress-ok   nginx   prod.qikqiak.com             80      17s</span><br></pre></td></tr></table></figure>



<p>接着我们创建一个不符合策略的 Ingress 对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f - &lt;&lt;EOT</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-bad</span><br><span class="line">  namespace: qa</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: opa.k8s.local</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx</span><br><span class="line">            port:</span><br><span class="line">              number: 80</span><br><span class="line">        path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">EOT</span><br><span class="line">Error from server: error when creating &quot;test.yaml&quot;: admission webhook &quot;validating-webhook.openpolicyagent.org&quot; denied the request: invalid ingress host &quot;opa.k8s.local&quot;</span><br></pre></td></tr></table></figure>



<p>从输出中可以看出，APIServer 拒绝创建 Ingress 对象，因为上面的对象违反了我们的 OPA 策略规则。</p>
<p>到这里我们就完成了理由 OPA 在 Kubernetes 集群中实施准入控制策略，而无需修改或重新编译任何 Kubernetes 组件。此外，还可以通过 OPA 的 Bundle 功能策略，可以定期从远程服务器下载以满足不断变化的操作要求。</p>
<h2 id="gatekeeper"><a href="#gatekeeper" class="headerlink" title="gatekeeper"></a>gatekeeper</h2><p>上面我们介绍了使用 <code>kube-mgmt</code> 这个 sidecar 容器来完成 OPA 策略的自动同步，此外还有另外一个更加高级的工具 <a target="_blank" rel="noopener" href="https://open-policy-agent.github.io/gatekeeper/website/docs/">Gatekeeper</a>，相比于之前的模式，<code>Gatekeeper(v3.0)</code> 准入控制器集成了 <code>OPA Constraint Framework</code>，以执行基于 CRD 的策略，并允许声明式配置的策略可靠地共享，使用 kubebuilder 构建，它提供了验证和修改准入控制和审计功能。这允许为 Rego 策略创建策略模板，将策略创建为 CRD，并在策略 CRD 上存储审计结果，这个项目是谷歌、微软、红帽和 Styra 一起合作实现的。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/wuyp4s.png" alt="gatekeeper"></p>
<p>直接使用下面的命令即可安装 <code>Gatekeeper</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/release-3.7/deploy/gatekeeper.yaml</span><br></pre></td></tr></table></figure>



<p>默认会将 <code>Gatekeeper</code> 安装到 <code>gatekeeper-system</code> 命名空间下面，同样会安装几个相关的 CRD：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -n gatekeeper-system</span><br><span class="line">NAME                                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">gatekeeper-audit-5cf4b9686-glndv                 1/1     Running   0          2m2s</span><br><span class="line">gatekeeper-controller-manager-77b7dc99fb-dvkvp   1/1     Running   0          2m2s</span><br><span class="line">gatekeeper-controller-manager-77b7dc99fb-gk4gr   1/1     Running   0          2m2s</span><br><span class="line">gatekeeper-controller-manager-77b7dc99fb-mt5wn   1/1     Running   0          2m2s</span><br><span class="line">➜ kubectl get crd |grep gate</span><br><span class="line">assign.mutations.gatekeeper.sh                       2022-03-27T06:47:24Z</span><br><span class="line">assignmetadata.mutations.gatekeeper.sh               2022-03-27T06:47:24Z</span><br><span class="line">configs.config.gatekeeper.sh                         2022-03-27T06:47:24Z</span><br><span class="line">constraintpodstatuses.status.gatekeeper.sh           2022-03-27T06:47:24Z</span><br><span class="line">constrainttemplatepodstatuses.status.gatekeeper.sh   2022-03-27T06:47:24Z</span><br><span class="line">constrainttemplates.templates.gatekeeper.sh          2022-03-27T06:47:24Z</span><br><span class="line">modifyset.mutations.gatekeeper.sh                    2022-03-27T06:47:24Z</span><br><span class="line">mutatorpodstatuses.status.gatekeeper.sh              2022-03-27T06:47:25Z</span><br><span class="line">providers.externaldata.gatekeeper.sh                 2022-03-27T06:47:25Z</span><br></pre></td></tr></table></figure>



<p><code>Gatekeeper</code> 使用 OPA 约束框架来描述和执行策略，在定义约束之前必须首先定义一个 <code>ConstraintTemplate</code> 对象，它描述了强制执行约束的 Rego 和约束的模式。约束的模式允许管理员对约束的行为进行微调，就像函数的参数一样。</p>
<p>如下所示是一个约束模板，描述了验证的对象必须要有标签存在：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k8srequiredlabels_template.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">templates.gatekeeper.sh/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConstraintTemplate</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">k8srequiredlabels</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">crd:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">names:</span></span><br><span class="line">        <span class="attr">kind:</span> <span class="string">K8sRequiredLabels</span></span><br><span class="line">      <span class="attr">validation:</span></span><br><span class="line">        <span class="attr">openAPIV3Schema:</span> <span class="comment"># Schema for the `parameters` field</span></span><br><span class="line">          <span class="attr">type:</span> <span class="string">object</span></span><br><span class="line">          <span class="attr">description:</span> <span class="string">Describe</span> <span class="string">K8sRequiredLabels</span> <span class="string">crd</span> <span class="string">parameters</span></span><br><span class="line">          <span class="attr">properties:</span></span><br><span class="line">            <span class="attr">labels:</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">array</span></span><br><span class="line">              <span class="attr">items:</span></span><br><span class="line">                <span class="attr">type:</span> <span class="string">string</span></span><br><span class="line">                <span class="attr">description:</span> <span class="string">A</span> <span class="string">label</span> <span class="string">string</span></span><br><span class="line">  <span class="attr">targets:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">target:</span> <span class="string">admission.k8s.gatekeeper.sh</span></span><br><span class="line">      <span class="attr">rego:</span> <span class="string">|</span></span><br><span class="line"><span class="string">        package k8srequiredlabels</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">        <span class="string">violation[&#123;&quot;msg&quot;:</span> <span class="string">msg,</span> <span class="attr">&quot;details&quot;:</span> &#123;<span class="attr">&quot;missing_labels&quot;:</span> <span class="string">missing</span>&#125;<span class="string">&#125;]</span> &#123;</span><br><span class="line">          <span class="string">provided</span> <span class="string">:=</span> &#123;<span class="string">label</span> <span class="string">|</span> <span class="string">input.review.object.metadata.labels</span>[<span class="string">label</span>]&#125;</span><br><span class="line">          <span class="string">required</span> <span class="string">:=</span> &#123;<span class="string">label</span> <span class="string">|</span> <span class="string">label</span> <span class="string">:=</span> <span class="string">input.parameters.labels</span>[<span class="string">_</span>]&#125;</span><br><span class="line">          <span class="string">missing</span> <span class="string">:=</span> <span class="string">required</span> <span class="bullet">-</span> <span class="string">provided</span></span><br><span class="line">          <span class="string">count(missing)</span> <span class="string">&gt;</span> <span class="number">0</span></span><br><span class="line">          <span class="string">msg</span> <span class="string">:=</span> <span class="string">sprintf(&quot;you</span> <span class="attr">must provide labels:</span> <span class="string">%v&quot;</span>, [<span class="string">missing</span>]<span class="string">)</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>



<p>直接应用上面的 <code>ConstraintTemplate</code> 资源清单：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f k8srequiredlabels_template.yaml</span><br><span class="line">constrainttemplate.templates.gatekeeper.sh/k8srequiredlabels created</span><br><span class="line">➜ kubectl get ConstraintTemplate</span><br><span class="line">NAME                AGE</span><br><span class="line">k8srequiredlabels   68s</span><br></pre></td></tr></table></figure>



<p>上面我们的定义的 <code>ConstraintTemplate</code> 对象就是一个模板，其中的 <code>crd</code> 部分描述了我们定义的 CRD 模板，比如类型叫 <code>K8sRequiredLabels</code>，需要和模板的名称保持一致，然后通过下面的 <code>validation</code> 定义了我们的 CRD 的属性 Schema，比如有一个 <code>labels</code> 的属性参数，类似是字符串数据类型：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">crd:</span></span><br><span class="line">  <span class="attr">spec:</span></span><br><span class="line">    <span class="attr">names:</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">K8sRequiredLabels</span></span><br><span class="line">    <span class="attr">validation:</span></span><br><span class="line">      <span class="attr">openAPIV3Schema:</span> <span class="comment"># Schema for the `parameters` field</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">object</span></span><br><span class="line">        <span class="attr">description:</span> <span class="string">Describe</span> <span class="string">K8sRequiredLabels</span> <span class="string">crd</span> <span class="string">parameters</span></span><br><span class="line">        <span class="attr">properties:</span></span><br><span class="line">          <span class="attr">labels:</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">array</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="attr">type:</span> <span class="string">string</span></span><br><span class="line">              <span class="attr">description:</span> <span class="string">A</span> <span class="string">label</span> <span class="string">string</span></span><br></pre></td></tr></table></figure>



<p>然后下面的 <code>targets</code> 部分就是定义的约束目标，使用 Rego 进行编写。</p>
<ul>
<li>首先通过 <code>provided := &#123;label | input.review.object.metadata.labels[label]&#125;</code> 获取到创建对象的所有 label 标签</li>
<li>然后通过 <code>required := &#123;label | label := input.parameters.labels[_]&#125;</code> 获取到需要提供的 label 标签</li>
<li>将上面两个标签集合相减（rego 语言支持该操作），得到未满足的 label</li>
<li>断言未满足的 label 数量&gt;0，如果大于 0，说明条件满足，violation 为 true，说明违反了约束，返回错误</li>
</ul>
<p>上面的约束模板创建完成后，实际上相当于创建了一个名为的 <code>K8sRequiredLabels</code> 对象，我们定义的属性位于 <code>spec.parameters</code> 属性下面：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get K8sRequiredLabels</span><br><span class="line">No resources found</span><br><span class="line">➜ kubectl explain K8sRequiredLabels.spec.parameters.labels</span><br><span class="line">KIND:     K8sRequiredLabels</span><br><span class="line">VERSION:  constraints.gatekeeper.sh/v1beta1</span><br><span class="line"></span><br><span class="line">FIELD:    labels &lt;[]string&gt;</span><br><span class="line"></span><br><span class="line">DESCRIPTION:</span><br><span class="line"></span><br><span class="line">     A label string</span><br></pre></td></tr></table></figure>



<p>现在我们就可以使用上面的 <code>K8sRequiredLabels</code> 这个约束模板来定义策略了，比如我们要求在所有命名空间上都定义一个 <code>gatekeeper</code> 的标签，则可以创建如下所示的对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># all_ns_must_have_gatekeeper.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">constraints.gatekeeper.sh/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">K8sRequiredLabels</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ns-must-have-gk</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">match:</span></span><br><span class="line">    <span class="attr">kinds:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&#x27;&#x27;</span>]</span><br><span class="line">        <span class="attr">kinds:</span> [<span class="string">&#x27;Namespace&#x27;</span>] <span class="comment"># 表示这个约束会在创建命名空间的时候被应用，可以使用 namespaceSelector、namespaces等进行过滤</span></span><br><span class="line">  <span class="attr">parameters:</span></span><br><span class="line">    <span class="attr">labels:</span> [<span class="string">&#x27;gatekeeper&#x27;</span>] <span class="comment"># 根据schema规范定义</span></span><br></pre></td></tr></table></figure>



<p>注意 match 字段，它定义了将应用给定约束的对象的范围，其中 <code>kinds: [&quot;Namespace&quot;]</code> 表示这个约束会在创建命名空间的时候被应用，此外它还支持其他匹配器：</p>
<ul>
<li><code>kind</code> 接受带有 apiGroups 和 kind 字段的对象列表，这些字段列出了约束将应用到的对象的组&#x2F;种类。如果指定了多个组&#x2F;种类对象，则资源在范围内只需要一个匹配项。</li>
<li><code>scope</code> 接受 <em>、Cluster 或 Namespaced 决定是否选择集群范围和&#x2F;或命名空间范围的资源。（默认为</em>）</li>
<li><code>namespaces</code> 是命名空间名称的列表。如果已定义，则约束仅适用于列出的命名空间中的资源。命名空间还支持基于前缀的 glob。例如，namespaces: [kube-*] 匹配 kube-system 和 kube-public。</li>
<li><code>excludeNamespaces</code> 是命名空间名称的列表。如果已定义，则约束仅适用于不在列出的命名空间中的资源。ExcludedNamespaces 还支持基于前缀的 glob，例如，excludedNamespaces: [kube-*] 匹配 kube-system 和 kube-public。</li>
<li><code>labelSelector</code> 是标准的 Kubernetes 标签选择器。</li>
<li><code>namespaceSelector</code> 是针对对象的包含名称空间或对象本身的标签选择器，如果对象是名称空间。name 是对象的名称。如果已定义，则匹配具有指定名称的对象。Name 还支持基于前缀的 glob。例如，名称：pod-* 匹配 pod-a 和 pod-b。</li>
</ul>
<p>下面的 <code>parameters.labels</code> 就是根据上面的 CRD 规范定义的属性，该值是传递给 opa 的参数，此处表示一个 key 为 labels，value 为一个列表的字典，与 <code>ConstraintTemplate</code> 里的 <code>properties</code> 要匹配上，此处表示要创建的对象需要含有 <code>gatekeeper</code> 的 label。</p>
<p>直接应用上面的这个资源对象即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f all_ns_must_have_gatekeeper.yaml</span><br><span class="line">k8srequiredlabels.constraints.gatekeeper.sh/ns-must-have-gk created</span><br></pre></td></tr></table></figure>



<p>创建完成后可以查看到这个 <code>constraints</code> 对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get k8srequiredlabels</span><br><span class="line">NAME              AGE</span><br><span class="line">ns-must-have-gk   73s</span><br><span class="line">➜ kubectl get constraints  # 和上面对象一样</span><br><span class="line">NAME              AGE</span><br><span class="line">ns-must-have-gk   81s</span><br></pre></td></tr></table></figure>



<p>由于 <code>Gatekeeper</code> 具有审计功能，可以根据集群中执行的约束条件对资源进行定期评估，以检测预先存在的错误配置，<code>Gatekeeper</code> 将审计结果存储为相关约束条件的 <code>status</code> 字段中列出违规行为。我们可以查看 <code>K8sRequiredLabels</code> 对象的 <code>status</code> 字段来查看不符合约束的行为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get constraints ns-must-have-gk -o yaml</span><br><span class="line">apiVersion: constraints.gatekeeper.sh/v1beta1</span><br><span class="line">kind: K8sRequiredLabels</span><br><span class="line">......</span><br><span class="line">status:</span><br><span class="line">  auditTimestamp: &quot;2022-03-27T07:42:38Z&quot;</span><br><span class="line">  ......</span><br><span class="line">  totalViolations: 11</span><br><span class="line">  violations:</span><br><span class="line">  - enforcementAction: deny</span><br><span class="line">    kind: Namespace</span><br><span class="line">    message: &#x27;you must provide labels: &#123;&quot;gatekeeper&quot;&#125;&#x27;</span><br><span class="line">    name: apisix</span><br><span class="line">  - enforcementAction: deny</span><br><span class="line">    kind: Namespace</span><br><span class="line">    message: &#x27;you must provide labels: &#123;&quot;gatekeeper&quot;&#125;&#x27;</span><br><span class="line">    name: default</span><br><span class="line">  ......</span><br></pre></td></tr></table></figure>



<p>比如现在我们创建一个如下所示的 Namespace：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test-namespace.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ns-test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">a:</span> <span class="string">b</span></span><br><span class="line">    <span class="comment">#gatekeeper: abc</span></span><br></pre></td></tr></table></figure>



<p>此时不给命名空间添加 key 为 <code>gatekeeper</code> 的 label，创建的时候就会报错：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error from server ([ns-must-have-gk] you must provide labels: &#123;&quot;gatekeeper&quot;&#125;): error when creating &quot;test-namespace.yaml&quot;: admission webhook &quot;validation.gatekeeper.sh&quot; denied the request: [ns-must-have-gk] you must provide labels: &#123;&quot;gatekeeper&quot;&#125;</span><br></pre></td></tr></table></figure>



<p>然后把 <code>gatekeeper: abc</code> 这行的注释打开，则能成功创建了，这就是 <code>Gatekeeper</code> 的基本用法。</p>
<p>从上面我们可以知道定义约束模板的策略会经常从 <code>input</code> 对象中获取数据，但是如果需要创建自己的约束，但是不知道传入的参数即 <code>input</code> 是什么，有一种简单方法是使用拒绝所有请求并将请求对象作为其拒绝消息输出的约束&#x2F;模板。我们可以在创建模板时在 <code>violation</code> 中只保留一行 <code>msg := sprintf(&quot;input: %v&quot;, [input])</code>，此时创建对象时必定会失败，然后获取到输出的错误信息，里面即包含所有 <code>input</code> 信息，之后再通过 Rego 语法去获取需要的数据即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: templates.gatekeeper.sh/v1</span><br><span class="line">kind: ConstraintTemplate</span><br><span class="line">metadata:</span><br><span class="line">  name: k8sdenyall</span><br><span class="line">spec:</span><br><span class="line">  crd:</span><br><span class="line">    spec:</span><br><span class="line">      names:</span><br><span class="line">        kind: K8sDenyAll</span><br><span class="line">  targets:</span><br><span class="line">    - target: admission.k8s.gatekeeper.sh</span><br><span class="line">      rego: |</span><br><span class="line">        package k8sdenyall</span><br><span class="line"></span><br><span class="line">        violation[&#123;&quot;msg&quot;: msg&#125;] &#123;</span><br><span class="line">          msg := sprintf(&quot;input:  %v&quot;, [input])</span><br><span class="line">        &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: constraints.gatekeeper.sh/v1beta1</span><br><span class="line">kind: K8sDenyAll</span><br><span class="line">metadata:</span><br><span class="line">  name: deny-all-namespaces</span><br><span class="line">spec:</span><br><span class="line">  match:</span><br><span class="line">    kinds:</span><br><span class="line">      - apiGroups: [&quot;&quot;]</span><br><span class="line">        kinds: [&quot;Namespace&quot;]</span><br></pre></td></tr></table></figure>



<p>由于约束模板或者说策略库具有一定的通用性，所以 <code>OPA Gatekeeper</code> 社区提供了一个通用的策略库：<a target="_blank" rel="noopener" href="https://github.com/open-policy-agent/gatekeeper-library%EF%BC%8C%E8%AF%A5%E4%BB%93%E5%BA%93%E4%B8%AD%E5%8C%85%E5%90%AB%E4%BA%86%E5%A4%A7%E9%87%8F%E9%80%9A%E7%94%A8%E7%9A%84%E7%BA%A6%E6%9D%9F%E6%A8%A1%E6%9D%BF%E3%80%82">https://github.com/open-policy-agent/gatekeeper-library，该仓库中包含了大量通用的约束模板。</a></p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/1jmruk.png" alt="gatekeeper-library"></p>
<p>每个模板库下面都包含一个 <code>template.yaml</code> 文件用来描述约束模板，<code>samples</code> 目录下面就包含具体的约束对象和示例资源清单，这些策略也是我们去学习 Rego 语言的很好的案例。</p>
<h2 id="Rego"><a href="#Rego" class="headerlink" title="Rego"></a>Rego</h2><p>上面的示例为我们详细介绍了如何使用 OPA 来配置我们的策略规则，其中最核心的就是使用 Rego 编写的策略规则，Rego 是专门为表达复杂的分层数据结构的策略而设计的，所以要掌握 OPA 的使用对 Rego 的了解是必不可少的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/POD%20Pending/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/POD%20Pending/" class="post-title-link" itemprop="url">POD Pending</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:55" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E9%9D%A2%E8%AF%95%E9%A2%98/" itemprop="url" rel="index"><span itemprop="name">面试题</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="彻底搞懂-K8S-Pod-Pending-故障原因及解决方案"><a href="#彻底搞懂-K8S-Pod-Pending-故障原因及解决方案" class="headerlink" title="彻底搞懂 K8S Pod Pending 故障原因及解决方案"></a>彻底搞懂 K8S Pod Pending 故障原因及解决方案</h1><p>即使在高成熟度级别 Kubernetes 集群中 pod pending 也是无处不在。</p>
<p>如果您随机询问任何使用 Kubernetes DevOps 工程师来确定折磨他们噩梦的最常见错误，pod pending 可能是非常常见的问题（可能仅次于 CrashLoopBackOff）。</p>
<p>尝试推送更新并看到它卡住会使 DevOps 紧张。即使解决方案相当简单，找到 pod 挂起的原因并了解您需要应用的更改也很重要（Kubernetes 故障排除很少是微不足道的）。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/sw044c.jpg" alt="图片"></p>
<p>在本文中，我们将阐明导致此问题的不同情况，让 DevOps 团队能够快速找到解决方案，最重要的是，尽可能避免它。</p>
<h3 id="Kubernetes-Pod-pending-是什么意思？"><a href="#Kubernetes-Pod-pending-是什么意思？" class="headerlink" title="Kubernetes Pod pending 是什么意思？"></a>Kubernetes Pod pending 是什么意思？</h3><p>Kubernetes 中的 Pod 的生命周期由几个不同的阶段组成：</p>
<ul>
<li>创建 pod 时，它从Pending阶段开始。</li>
<li>一旦 pod 被调度并且容器已经启动，pod 就会进入Running阶段。</li>
</ul>
<p>大多数 pod 只需要几秒钟就可以从 Pending 到 Running 并在该状态下度过大部分时间。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/hswjd7.jpg" alt="图片"></p>
<p>至此，Pod 已被 Kubernetes 集群接受。但是一个或多个容器尚未准备好对外提供服务。这包括 Pod 等待调度所花费的时间以及通过网络下载容器镜像所花费的时间。</p>
<p>当 pod 无法从 PendingtoRunning 阶段前进时，生命周期将停止并保留 pod，直到阻止它前进的问题得到修复。</p>
<p>如果我们使用 kubectl 列出 pod，我们将看到显示 Kubernetes pod 挂起情况的输出：</p>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n troubleshooting get pods</span><br><span class="line"><span class="keyword">NAME</span>                                           READY   <span class="keyword">STATUS</span>    RESTARTS   AGE</span><br><span class="line">stress-<span class="number">6d6</span>cbc8b9d-s4sbh                        <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">17</span>s</span><br></pre></td></tr></table></figure>

<p>除非我们解决问题，否则 pod 被卡住并且不会运行。</p>
<h3 id="排查-Kubernetes-pod-Pending-的常见原因"><a href="#排查-Kubernetes-pod-Pending-的常见原因" class="headerlink" title="排查 Kubernetes pod Pending 的常见原因"></a>排查 Kubernetes pod Pending 的常见原因</h3><p>有几个原因可以阻止 Pod 运行，但我们将描述三个主要问题：</p>
<ul>
<li>调度问题：无法在任何节点上调度 Pod。</li>
<li>镜像问题：下载容器镜像时出现问题。</li>
<li>依赖性问题：Pod 需要一个卷、Secret 或 ConfigMap 才能运行。</li>
</ul>
<p>第一个是最常见的，最后一个很少见。让我们详细说明每种情况。</p>
<h4 id="调度问题导致-Kubernetes-Pod-Pending"><a href="#调度问题导致-Kubernetes-Pod-Pending" class="headerlink" title="调度问题导致 Kubernetes Pod Pending"></a>调度问题导致 Kubernetes Pod Pending</h4><p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>创建 Pod 后，Kubernetes 集群做的第一件事就是尝试调度 Pod 在其中一个节点上运行。这个过程通常非常快，并且 pod 被快速分配给具有足够资源来运行它的节点。</p>
<p>为了放置它，集群中的 Pod 被分配给具有更多未请求资源的节点，并继续其快乐而美好的生活，其中充满了对请求的符合 SLO 的回复。</p>
<p>但是，如果此过程每次都有效，有几个因素可能导致集群无法分配 pod。</p>
<p>让我们回顾一下最常见的。</p>
<h5 id="任何节点中都没有足够的资源来分配-pod"><a href="#任何节点中都没有足够的资源来分配-pod" class="headerlink" title="任何节点中都没有足够的资源来分配 pod"></a>任何节点中都没有足够的资源来分配 pod</h5><p>Kubernetes 使用调度请求来决定fits节点中是否有 pod。资源的真正使用无关紧要，只有其他 pod 已经请求的资源。</p>
<p>effective requests当一个 pod 有足够的可请求资源来参与该 pod 的内存和 CPU 时，它将被调度到一个节点中。并且节点必须没有达到它可以运行的最大 pod 数。</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>当没有任何节点满足 pod 的所有要求时，它将保持在 Kubernetes pod 挂起状态，直到释放一些资源。</p>
<h5 id="不可调度的节点"><a href="#不可调度的节点" class="headerlink" title="不可调度的节点"></a>不可调度的节点</h5><p>由于不同的问题（节点压力）或人为行为（节点封锁），节点可能会变为不可调度的状态。这些节点在状态发生变化之前不会调度任何 pod。</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<h5 id="污点和容忍度"><a href="#污点和容忍度" class="headerlink" title="污点和容忍度"></a>污点和容忍度</h5><p>污点是 Kubernetes 的一种机制，它允许我们限制可以分配给不同节点的 pod。当节点具有 taint 时，只有匹配容忍度的 pod 才能在该节点中运行。</p>
<p>这种机制允许 Kubernetes 的特殊用途，例如为不同的工作负载使用不同类型的节点（具有 GPU 的节点，具有不同的 CPU&#x2F;内存比率等）。</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>即使我们分别描述每个原因，调度问题也往往是由这些问题的组合引起的。通常，您无法调度，因为某些节点已满而其他节点已被污染，或者某个节点可能由于内存压力而无法调度。</p>
<p>为了找出调度问题是什么，您需要查看调度程序生成的关于 pod 的事件，其中将详细描述阻止节点分配的原因。我们可以使用 kubectl describe 查看事件，例如：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">-n</span> <span class="string">troubleshooting</span> <span class="string">describe</span> <span class="string">pod</span> <span class="string">stress-6d6cbc8b9d-s4sbh</span></span><br><span class="line"><span class="attr">Name:</span>           <span class="string">stress-6d6cbc8b9d-s4sbh</span></span><br><span class="line"><span class="attr">Namespace:</span>      <span class="string">troubleshooting</span></span><br><span class="line"><span class="attr">Priority:</span>       <span class="number">0</span></span><br><span class="line"><span class="attr">Node:</span>           <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Labels:</span>         <span class="string">app=stress</span></span><br><span class="line">                <span class="string">pod-template-hash=6d6cbc8b9d</span></span><br><span class="line"><span class="attr">Annotations:</span>    <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Status:</span>         <span class="string">Pending</span></span><br><span class="line"><span class="attr">IP:</span></span><br><span class="line"><span class="attr">IPs:</span>            <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Controlled By:</span>  <span class="string">ReplicaSet/stress-6d6cbc8b9d</span></span><br><span class="line"><span class="attr">Containers:</span></span><br><span class="line">  <span class="attr">stress:</span></span><br><span class="line">    <span class="attr">Image:</span>      <span class="string">progrium/stress</span></span><br><span class="line">    <span class="attr">Port:</span>       <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="attr">Host Port:</span>  <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="attr">Args:</span></span><br><span class="line">      <span class="string">--cpu</span></span><br><span class="line">      <span class="number">1</span></span><br><span class="line">      <span class="string">--vm</span></span><br><span class="line">      <span class="number">2</span></span><br><span class="line">      <span class="string">--vm-bytes</span></span><br><span class="line">      <span class="string">150M</span></span><br><span class="line">    <span class="attr">Limits:</span></span><br><span class="line">      <span class="attr">cpu:</span>     <span class="string">300m</span></span><br><span class="line">      <span class="attr">memory:</span>  <span class="string">120000Mi</span></span><br><span class="line">    <span class="attr">Requests:</span></span><br><span class="line">      <span class="attr">cpu:</span>        <span class="string">200m</span></span><br><span class="line">      <span class="attr">memory:</span>     <span class="string">100000Mi</span></span><br><span class="line">    <span class="attr">Environment:</span>  <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="attr">Mounts:</span></span><br><span class="line">      <span class="string">/var/run/secrets/kubernetes.io/serviceaccount</span> <span class="string">from</span> <span class="string">kube-api-access-snrww</span> <span class="string">(ro)</span></span><br><span class="line"><span class="attr">Conditions:</span></span><br><span class="line">  <span class="string">Type</span>           <span class="string">Status</span></span><br><span class="line">  <span class="string">PodScheduled</span>   <span class="literal">False</span></span><br><span class="line"><span class="attr">Volumes:</span></span><br><span class="line">  <span class="attr">kube-api-access-snrww:</span></span><br><span class="line">    <span class="attr">Type:</span>                    <span class="string">Projected</span> <span class="string">(a</span> <span class="string">volume</span> <span class="string">that</span> <span class="string">contains</span> <span class="string">injected</span> <span class="string">data</span> <span class="string">from</span> <span class="string">multiple</span> <span class="string">sources)</span></span><br><span class="line">    <span class="attr">TokenExpirationSeconds:</span>  <span class="number">3607</span></span><br><span class="line">    <span class="attr">ConfigMapName:</span>           <span class="string">kube-root-ca.crt</span></span><br><span class="line">    <span class="attr">ConfigMapOptional:</span>       <span class="string">&lt;nil&gt;</span></span><br><span class="line">    <span class="attr">DownwardAPI:</span>             <span class="literal">true</span></span><br><span class="line"><span class="attr">QoS Class:</span>                   <span class="string">Burstable</span></span><br><span class="line"><span class="attr">Node-Selectors:</span>              <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Tolerations:</span>                 <span class="string">node.kubernetes.io/not-ready:NoExecute</span> <span class="string">op=Exists</span> <span class="string">for</span> <span class="string">300s</span></span><br><span class="line">                             <span class="string">node.kubernetes.io/unreachable:NoExecute</span> <span class="string">op=Exists</span> <span class="string">for</span> <span class="string">300s</span></span><br><span class="line"><span class="attr">Events:</span></span><br><span class="line">  <span class="string">Type</span>     <span class="string">Reason</span>            <span class="string">Age</span>                   <span class="string">From</span>               <span class="string">Message</span></span><br><span class="line">  <span class="string">----</span>     <span class="string">------</span>            <span class="string">----</span>                  <span class="string">----</span>               <span class="string">-------</span></span><br><span class="line">  <span class="attr">Warning  FailedScheduling  4m17s (x41 over 34m)  default-scheduler  0/5 nodes are available:</span> <span class="number">1</span> <span class="string">node(s)</span> <span class="string">had</span> <span class="string">taint</span> &#123;<span class="attr">node-role.kubernetes.io/master:</span> &#125;<span class="string">,</span> <span class="string">that</span> <span class="string">the</span> <span class="string">pod</span> <span class="string">didn&#x27;t</span> <span class="string">tolerate,</span> <span class="number">4</span> <span class="string">Insufficient</span> <span class="string">memory.</span></span><br></pre></td></tr></table></figure>

<p>我们可以在输出中看到消息中的确切原因：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>/<span class="number">5</span> nodes are available: <span class="number">1</span> <span class="keyword">node</span><span class="title">(s</span>) had taint &#123;<span class="keyword">node</span><span class="title">-role</span>.kubernetes.io/<span class="literal">master</span>: &#125;, that the pod didn&#x27;t tolerate, <span class="number">4</span> Insufficient memory.</span><br></pre></td></tr></table></figure>

<ul>
<li>其中一个节点被污染。</li>
<li>其中四个节点没有足够的可请求内存。</li>
</ul>
<p>为了解决这个问题，我们有两个选择：</p>
<ul>
<li>减少 pod 定义中的资源请求大小。</li>
<li>通过添加更多节点或增加每个节点的大小来增加集群的容量。</li>
</ul>
<p>如果要更新当前运行的工作负载，还需要考虑另一个重要因素：升级策略。</p>
<p>由于此策略，Kubernetes 可以允许工作负载在更新过程中创建比平时更多的 Pod，在创建新 Pod 时保留旧 Pod 一段时间。这意味着工作负载可能会在一段时间内请求比预期更多的资源。如果集群没有足够的备用资源，更新将被阻塞，留下一些 pod 待处理，直到进程被解除阻塞（或回滚超时停止更新）。</p>
<h4 id="由于镜像问题，Pod-Pending"><a href="#由于镜像问题，Pod-Pending" class="headerlink" title="由于镜像问题，Pod Pending"></a>由于镜像问题，Pod Pending</h4><p>一旦在一个节点中分配了 pod，kubelet就会尝试启动 pod 中的所有容器。为此，它将尝试下载镜像并运行它。</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>有几个错误会阻止镜像被下载：</p>
<ul>
<li>镜象名称错误。</li>
<li>错误的镜像标签。</li>
<li>错误的存储仓库。</li>
<li>存储仓库需要身份验证。</li>
</ul>
<h4 id="Kubernetes-Pod-由于依赖问题而挂起"><a href="#Kubernetes-Pod-由于依赖问题而挂起" class="headerlink" title="Kubernetes Pod 由于依赖问题而挂起"></a>Kubernetes Pod 由于依赖问题而挂起</h4><p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>在 pod 启动之前，kubelet将尝试检查与其他 Kubernetes 元素的所有依赖关系。如果无法满足这些依赖项之一，则 pod 将保持挂起状态，直到满足依赖项。</p>
<p>![图片](data:image&#x2F;svg+xml,%3C%3Fxml version&#x3D;’1.0’ encoding&#x3D;’UTF-8’%3F%3E%3Csvg width&#x3D;’1px’ height&#x3D;’1px’ viewBox&#x3D;’0 0 1 1’ version&#x3D;’1.1’ xmlns&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg">http://www.w3.org/2000/svg</a>‘ xmlns:xlink&#x3D;’<a target="_blank" rel="noopener" href="http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg">http://www.w3.org/1999/xlink&#39;%3E%3Ctitle%3E%3C/title%3E%3Cg</a> stroke&#x3D;’none’ stroke-width&#x3D;’1’ fill&#x3D;’none’ fill-rule&#x3D;’evenodd’ fill-opacity&#x3D;’0’%3E%3Cg transform&#x3D;’translate(-249.000000, -126.000000)’ fill&#x3D;’%23FFFFFF’%3E%3Crect x&#x3D;’249’ y&#x3D;’126’ width&#x3D;’1’ height&#x3D;’1’%3E%3C&#x2F;rect%3E%3C&#x2F;g%3E%3C&#x2F;g%3E%3C&#x2F;svg%3E)</p>
<p>在这种情况下，kubectl 将像这样显示 pod：</p>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n mysql get pods </span><br><span class="line"><span class="keyword">NAME</span> READY <span class="keyword">STATUS</span> RESTARTS AGE </span><br><span class="line">mysql-<span class="number">0</span> <span class="number">0</span>/<span class="number">1</span> ContainerCreating <span class="number">0</span> <span class="number">97</span>s</span><br></pre></td></tr></table></figure>

<p>在事件中，我们可以看到如下内容：</p>
<figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  <span class="keyword">Type</span>     Reason       Age                  From               Message</span><br><span class="line">  <span class="comment">----     ------       ----                 ----               -------</span></span><br><span class="line">  Normal   Scheduled    <span class="number">3</span>m19s                <span class="keyword">default</span>-scheduler  Successfully assigned mysql/mysql-<span class="number">0</span> <span class="keyword">to</span> ip-<span class="number">172</span>-<span class="number">20</span>-<span class="number">38</span>-<span class="number">115</span>.eu-west-<span class="number">1</span>.compute.internal</span><br><span class="line">  <span class="literal">Warning</span>  FailedMount  <span class="number">76</span>s                  kubelet            Unable <span class="keyword">to</span> attach <span class="keyword">or</span> mount volumes: unmounted volumes=[config], unattached volumes=[kube-api-<span class="keyword">access</span>-gxjf8 data config]: timed <span class="keyword">out</span> waiting <span class="keyword">for</span> the condition</span><br><span class="line">  <span class="literal">Warning</span>  FailedMount  <span class="number">71</span>s (x9 over <span class="number">3</span>m19s)  kubelet            MountVolume.SetUp failed <span class="keyword">for</span> volume <span class="string">&quot;config&quot;</span> : configmap <span class="string">&quot;mysql&quot;</span> <span class="keyword">not</span> found</span><br></pre></td></tr></table></figure>

<p>该 Message 列将为您提供足够的信息，以便能够查明缺失的元素。常见的原因有：</p>
<ul>
<li>尚未创建 ConfigMap 或者 Secret，或提供的名称不正确。</li>
<li>无法在节点中挂载卷，因为它尚未被另一个节点释放。这尤其发生在更新 statefulset 的过程中，挂载的卷必须与旧 pod 相同。</li>
</ul>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>了解 pod 保持在该 Pending 阶段的原因是在 Kubernetes 中安全部署和更新工作负载的关键。能够快速定位问题并加快部署进度将为您省去一些麻烦并减少停机时间。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/PPP%20%E5%8D%8F%E8%AE%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/PPP%20%E5%8D%8F%E8%AE%AE/" class="post-title-link" itemprop="url">PPP 协议</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:52:08" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/WEB/" itemprop="url" rel="index"><span itemprop="name">WEB</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/WEB/Http/" itemprop="url" rel="index"><span itemprop="name">Http</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="PPP-协议（点对点协议-Point-to-Point-Protocol）"><a href="#PPP-协议（点对点协议-Point-to-Point-Protocol）" class="headerlink" title="PPP 协议（点对点协议 &#x2F; Point-to-Point Protocol）"></a>PPP 协议（点对点协议 &#x2F; Point-to-Point Protocol）</h3><p>PPP (Point-to-Point Protocol) 是一种用于在两个网络节点之间建立<strong>直接连接</strong>的数据链路层协议。它主要用于通过串行线缆（如电话线、ISDN、DSL、光纤）连接计算机到互联网，或者在路由器之间建立点对点连接。它是替代早期的 SLIP (Serial Line Internet Protocol) 协议而生的，并解决了 SLIP 的许多限制。</p>
<p><strong>核心作用：</strong></p>
<p>PPP 提供了一种标准的方法来：</p>
<ol>
<li><strong>封装</strong>网络层数据包（如 IP 数据包），以便在点对点链路上传输。</li>
<li><strong>建立、配置和测试</strong>数据链路连接的可靠性。</li>
<li>提供<strong>网络层地址协商</strong>（例如，分配 IP 地址）。</li>
<li>提供<strong>身份验证</strong>机制（可选）。</li>
</ol>
<p>简而言之，PPP 就是在两点之间架起一座数据传输的桥梁，并确保桥梁能正常工作和通信。</p>
<hr>
<h3 id="PPP-协议的基本工作流程"><a href="#PPP-协议的基本工作流程" class="headerlink" title="PPP 协议的基本工作流程"></a>PPP 协议的基本工作流程</h3><p>PPP 的工作流程分为几个阶段，通过使用不同的子协议来完成：</p>
<ol>
<li>**链路控制协议 (LCP - Link Control Protocol)**：负责建立、配置和测试数据链路。</li>
<li>**网络控制协议 (NCP - Network Control Protocol)**：负责协商和配置网络层协议（例如 IP）。</li>
<li>**身份验证协议 (Authentication Protocols)**：可选，例如 PAP (Password Authentication Protocol) 或 CHAP (Challenge-Handshake Authentication Protocol)。</li>
</ol>
<h4 id="PPP-工作流程的阶段："><a href="#PPP-工作流程的阶段：" class="headerlink" title="PPP 工作流程的阶段："></a>PPP 工作流程的阶段：</h4><h4 id="阶段-1：链路建立阶段-Link-Establishment-Phase-由-LCP-管理"><a href="#阶段-1：链路建立阶段-Link-Establishment-Phase-由-LCP-管理" class="headerlink" title="阶段 1：链路建立阶段 (Link Establishment Phase) - 由 LCP 管理"></a>阶段 1：链路建立阶段 (Link Establishment Phase) - 由 LCP 管理</h4><p>这个阶段的目标是建立一个可靠的、能传输数据的点对点链路。</p>
<ol>
<li><p><strong>LCP 配置帧交换：</strong></p>
<ul>
<li>当两个 PPP 设备（例如，用户的拨号软件和 ISP 的调制解调器&#x2F;路由器）连接建立后，它们会开始交换一系列 LCP 配置请求帧。</li>
<li>这些帧会协商各种链路参数，例如：<ul>
<li><strong>最大接收单元 (MRU - Maximum Receive Unit)：</strong> 决定了在链路上最大允许传输的数据包大小。</li>
<li><strong>认证协议：</strong> 协商使用哪种认证协议（如果需要认证）。</li>
<li><strong>魔术数字 (Magic Number)：</strong> 用于检测链路环回（loopback）情况。</li>
<li><strong>异步控制字符映射 (ACCM)：</strong> 处理控制字符的转义。</li>
</ul>
</li>
<li>双方会反复发送 <code>Configure-Request</code>，直到它们对所有参数达成一致，然后发送 <code>Configure-ACK</code>。如果无法接受某个参数，则发送 <code>Configure-Reject</code> 或 <code>Configure-Nak</code>。</li>
</ul>
</li>
<li><p><strong>链路测试（可选）：</strong></p>
<ul>
<li>LCP 还可以发送 <code>Echo-Request</code> 和 <code>Echo-Reply</code> 来测试链路的连通性和延迟。</li>
<li>如果链路质量不佳或出现故障，LCP 可以发送 <code>Terminate-Request</code> 来终止链路，并在双方确认后发送 <code>Terminate-ACK</code>。</li>
</ul>
</li>
<li><p><strong>链路开放：</strong></p>
<ul>
<li>一旦 LCP 协商成功，链路就进入 OPEN 状态，可以开始进行网络层配置。</li>
</ul>
</li>
</ol>
<h4 id="阶段-2：身份验证阶段-Authentication-Phase-可选，由-PAP-CHAP-管理"><a href="#阶段-2：身份验证阶段-Authentication-Phase-可选，由-PAP-CHAP-管理" class="headerlink" title="阶段 2：身份验证阶段 (Authentication Phase) - 可选，由 PAP&#x2F;CHAP 管理"></a>阶段 2：身份验证阶段 (Authentication Phase) - 可选，由 PAP&#x2F;CHAP 管理</h4><p>这个阶段的目标是验证连接发起方的身份，确保只有授权用户才能接入网络。</p>
<ol>
<li><p><strong>认证请求：</strong></p>
<ul>
<li>通常由服务器方向客户端发起或客户端主动发送认证信息。</li>
<li><strong>PAP (Password Authentication Protocol)：</strong><ul>
<li>客户端直接发送用户名和密码给服务器。</li>
<li>简单但不安全，因为用户名和密码是明文传输的。</li>
<li>服务器验证后发送 <code>Authenticate-ACK</code> 或 <code>Authenticate-NAK</code>。</li>
</ul>
</li>
<li><strong>CHAP (Challenge-Handshake Authentication Protocol)：</strong><ul>
<li>服务器向客户端发送一个“挑战 (Challenge)”消息（通常包含一个随机数）。</li>
<li>客户端使用用户名、密码（双方都知道的密钥）和随机数计算出一个哈希值作为“响应 (Response)”发送给服务器。</li>
<li>服务器独立计算一个哈希值，与客户端的响应进行比较。</li>
<li>更安全，因为密码永不以明文形式在链路上发送，且挑战值不断变化，防止了重放攻击。</li>
<li>服务器验证后发送 <code>Authentication-Success</code> 或 <code>Authentication-Failure</code>。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>成功或失败：</strong></p>
<ul>
<li>如果身份验证成功，链路进入网络层阶段。</li>
<li>如果身份验证失败，LCP 会终止链路。</li>
</ul>
</li>
</ol>
<h4 id="阶段-3：网络层协议阶段-Network-Layer-Protocol-Phase-由-NCP-管理"><a href="#阶段-3：网络层协议阶段-Network-Layer-Protocol-Phase-由-NCP-管理" class="headerlink" title="阶段 3：网络层协议阶段 (Network-Layer Protocol Phase) - 由 NCP 管理"></a>阶段 3：网络层协议阶段 (Network-Layer Protocol Phase) - 由 NCP 管理</h4><p>这个阶段的目标是配置网络层协议，例如为客户端分配 IP 地址。</p>
<ol>
<li><p><strong>NCP 配置帧交换：</strong></p>
<ul>
<li>最常用的 NCP 是 **IP Control Protocol (IPCP)**，用于配置 IP 网络层。</li>
<li>客户端通常发送 <code>IPCP Configure-Request</code>，请求分配一个 IP 地址、DNS 服务器地址、默认网关等。</li>
<li>服务器接收请求后，会根据其策略分配这些参数，并发送 <code>IPCP Configure-ACK</code> 进行确认。</li>
<li>例如，客户端会通过 IPCP 协商：<ul>
<li><code>IP-Addresses</code>：获取自身的 IP 地址。</li>
<li><code>Primary-DNS</code>、<code>Secondary-DNS</code>：获取 DNS 服务器地址。</li>
<li><code>IP-Compression</code>：协商 IP 数据包压缩。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>网络层就绪：</strong></p>
<ul>
<li>一旦 IPCP 协商成功，客户端就获得了 IP 地址和其他必要的网络配置信息，可以开始像普通网络设备一样发送和接收 IP 数据包了。</li>
</ul>
</li>
</ol>
<h4 id="阶段-4：数据传输阶段-Data-Transfer-Phase"><a href="#阶段-4：数据传输阶段-Data-Transfer-Phase" class="headerlink" title="阶段 4：数据传输阶段 (Data Transfer Phase)"></a>阶段 4：数据传输阶段 (Data Transfer Phase)</h4><ul>
<li>链路建立并配置完成后，网络层数据包（如 IP 数据包）就可以通过 PPP 链路进行封装和传输了。</li>
</ul>
<h4 id="阶段-5：链路终止阶段-Link-Termination-Phase"><a href="#阶段-5：链路终止阶段-Link-Termination-Phase" class="headerlink" title="阶段 5：链路终止阶段 (Link Termination Phase)"></a>阶段 5：链路终止阶段 (Link Termination Phase)</h4><ul>
<li>当连接不再需要时（例如用户挂断电话，或会话超时），任意一方都可以发送 LCP <code>Terminate-Request</code> 帧。</li>
<li>另一方收到后，发送 LCP <code>Terminate-ACK</code> 帧，链路被关闭。</li>
<li>如果链路出现故障，LCP 也会负责将其终止。</li>
</ul>
<p><strong>总结：</strong></p>
<p>PPP 协议通过分阶段的协商和自动化流程，使得两个只能通过串行方式连接的设备能够建立起一个功能齐全、可传输 IP 数据包的网络链路。它的模块化设计（LCP 负责链路，NCP 负责网络层）使其非常灵活和可扩展。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/OpenKruise/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/OpenKruise/" class="post-title-link" itemprop="url">OpenKruise</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:10" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E6%8E%A7%E5%88%B6%E5%99%A8/" itemprop="url" rel="index"><span itemprop="name">控制器</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>38k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>34 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="OpenKruise"><a href="#OpenKruise" class="headerlink" title="OpenKruise"></a>OpenKruise</h1><p><a target="_blank" rel="noopener" href="https://openkruise.io/">OpenKruise</a> 是一个基于 Kubernetes 的<strong>扩展套件</strong>，主要聚焦于云原生应用的自动化，比如部署、发布、运维以及可用性防护。OpenKruise 提供的绝大部分能力都是基于 CRD 扩展来定义的，它们不存在于任何外部依赖，可以运行在任意纯净的 Kubernetes 集群中。Kubernetes 自身提供的一些应用部署管理功能，对于大规模应用与集群的场景这些功能是远远不够的，OpenKruise 弥补了 Kubernetes 在应用部署、升级、防护、运维等领域的不足。</p>
<p>OpenKruise 提供了以下的一些核心能力：</p>
<ul>
<li><strong>增强版本的 Workloads</strong>：OpenKruise 包含了一系列增强版本的工作负载，比如 CloneSet、Advanced StatefulSet、Advanced DaemonSet、BroadcastJob 等。它们不仅支持类似于 Kubernetes 原生 Workloads 的基础功能，还提供了如原地升级、可配置的扩缩容&#x2F;发布策略、并发操作等。其中，原地升级是一种升级应用容器镜像甚至环境变量的全新方式，它只会用新的镜像重建 Pod 中的特定容器，整个 Pod 以及其中的其他容器都不会被影响。因此它带来了更快的发布速度，以及避免了对其他 Scheduler、CNI、CSI 等组件的负面影响。</li>
<li><strong>应用的旁路管理</strong>：OpenKruise 提供了多种通过旁路管理应用 sidecar 容器、多区域部署的方式，“旁路” 意味着你可以不需要修改应用的 Workloads 来实现它们。比如，SidecarSet 能帮助你在所有匹配的 Pod 创建的时候都注入特定的 sidecar 容器，甚至可以原地升级已经注入的 sidecar 容器镜像、并且对 Pod 中其他容器不造成影响。而 WorkloadSpread 可以约束无状态 Workload 扩容出来 Pod 的区域分布，赋予单一 workload 的多区域和弹性部署的能力。</li>
<li><strong>高可用性防护</strong>：OpenKruise 可以保护你的 Kubernetes 资源不受级联删除机制的干扰，包括 CRD、Namespace、以及几乎全部的 Workloads 类型资源。相比于 Kubernetes 原生的 PDB 只提供针对 Pod Eviction 的防护，PodUnavailableBudget 能够防护 Pod Deletion、Eviction、Update 等许多种 voluntary disruption 场景。</li>
<li><strong>高级的应用运维能力</strong>：OpenKruise 也提供了很多高级的运维能力来帮助你更好地管理应用，比如可以通过 ImagePullJob 来在任意范围的节点上预先拉取某些镜像，或者指定某个 Pod 中的一个或多个容器被原地重启。</li>
</ul>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>下图是 OpenKruise 的整体架构：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/6rivp2.png" alt="架构"></p>
<p>首先我们要清楚所有 OpenKruise 的功能都是通过 Kubernetes CRD 来提供的：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get crd | grep kruise.io</span><br><span class="line">advancedcronjobs.apps.kruise.io            2021-09-16T06:02:36Z</span><br><span class="line">broadcastjobs.apps.kruise.io               2021-09-16T06:02:36Z</span><br><span class="line">clonesets.apps.kruise.io                   2021-09-16T06:02:36Z</span><br><span class="line">containerrecreaterequests.apps.kruise.io   2021-09-16T06:02:36Z</span><br><span class="line">daemonsets.apps.kruise.io                  2021-09-16T06:02:36Z</span><br><span class="line">imagepulljobs.apps.kruise.io               2021-09-16T06:02:36Z</span><br><span class="line">nodeimages.apps.kruise.io                  2021-09-16T06:02:36Z</span><br><span class="line">podunavailablebudgets.policy.kruise.io     2021-09-16T06:02:36Z</span><br><span class="line">resourcedistributions.apps.kruise.io       2021-09-16T06:02:36Z</span><br><span class="line">sidecarsets.apps.kruise.io                 2021-09-16T06:02:36Z</span><br><span class="line">statefulsets.apps.kruise.io                2021-09-16T06:02:36Z</span><br><span class="line">uniteddeployments.apps.kruise.io           2021-09-16T06:02:37Z</span><br><span class="line">workloadspreads.apps.kruise.io             2021-09-16T06:02:37Z</span><br></pre></td></tr></table></figure>



<p>其中 <code>Kruise-manager</code> 是一个运行控制器和 webhook 的中心组件，它通过 Deployment 部署在 <code>kruise-system</code> 命名空间中。 从逻辑上来看，如 <code>cloneset-controller</code>、<code>sidecarset-controller</code> 这些的控制器都是独立运行的，不过为了减少复杂度，它们都被打包在一个独立的二进制文件、并运行在 <code>kruise-controller-manager-xxx</code> 这个 Pod 中。除了控制器之外，<code>kruise-controller-manager-xxx</code> 中还包含了针对 Kruise CRD 以及 Pod 资源的 admission webhook。<code>Kruise-manager</code> 会创建一些 webhook configurations 来配置哪些资源需要感知处理、以及提供一个 Service 来给 kube-apiserver 调用。</p>
<p>从 v0.8.0 版本开始提供了一个新的 <code>Kruise-daemon</code> 组件，它通过 DaemonSet 部署到每个节点上，提供镜像预热、容器重启等功能。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>这里我们同样还是使用 Helm 方式来进行安装，需要注意从 v1.0.0 开始，OpenKruise 要求在 Kubernetes &gt;&#x3D; 1.16 以上版本的集群中安装和使用。</p>
<p>首先添加 charts 仓库：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ helm repo add openkruise https://openkruise.github.io/charts</span><br><span class="line">➜ helm repo update</span><br></pre></td></tr></table></figure>



<p>然后执行下面的命令安装最新版本的应用：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ helm upgrade --install kruise openkruise/kruise --version 1.0.1</span><br></pre></td></tr></table></figure>



<p>该 charts 在模板中默认定义了命名空间为 <code>kruise-system</code>，所以在安装的时候可以不用指定，如果你的环境访问 DockerHub 官方镜像较慢，则可以使用下面的命令将镜像替换成阿里云的镜像：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ helm upgrade --install kruise openkruise/kruise --set manager.image.repository=openkruise-registry.cn-hangzhou.cr.aliyuncs.com/openkruise/kruise-manager --version 1.0.1</span><br></pre></td></tr></table></figure>



<p>应用部署完成后会在 <code>kruise-system</code> 命名空间下面运行 2 个 <code>kruise-manager</code> 的 Pod，同样它们之间采用 leader-election 的方式选主，同一时间只有一个提供服务，达到高可用的目的，此外还会以 DaemonSet 的形式启动 <code>kruise-daemon</code> 组件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -n kruise-system</span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">kruise-controller-manager-f5c9b55c5-7hgt9   1/1     Running   0          4m3s</span><br><span class="line">kruise-controller-manager-f5c9b55c5-v9ptf   1/1     Running   0          4m3s</span><br><span class="line">kruise-daemon-bqf5v                         1/1     Running   0          4m3s</span><br><span class="line">kruise-daemon-hvgwv                         1/1     Running   0          4m3s</span><br><span class="line">kruise-daemon-tnqsx                         1/1     Running   0          4m3s</span><br></pre></td></tr></table></figure>



<p>如果不想使用默认的参数进行安装，也可以自定义配置，可配置的 values 值可以参考 charts 文档 <a target="_blank" rel="noopener" href="https://github.com/openkruise/charts/tree/master/versions/1.0.1">https://github.com/openkruise/charts</a> 进行定制。</p>
<h2 id="CloneSet"><a href="#CloneSet" class="headerlink" title="CloneSet"></a>CloneSet</h2><p><code>CloneSet</code> 控制器是 OpenKruise 提供的对原生 Deployment 的增强控制器，在使用方式上和 Deployment 几乎一致，如下所示是我们声明的一个 CloneSet 资源对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cloneset-demo.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CloneSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cs-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">cs</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">cs</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nginx:alpine</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<p>直接创建上面的这个 CloneSet 对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f cloneset-demo.yaml</span><br><span class="line">➜ kubectl get cloneset cs-demo</span><br><span class="line">NAME      DESIRED   UPDATED   UPDATED_READY   READY   TOTAL   AGE</span><br><span class="line">cs-demo   3         3         3               3       3       112s</span><br><span class="line">➜ kubectl describe cloneset cs-demo</span><br><span class="line">Name:         cs-demo</span><br><span class="line">Namespace:    default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubectl.kubernetes.io/last-applied-configuration:</span><br><span class="line">                &#123;&quot;apiVersion&quot;:&quot;apps.kruise.io/v1alpha1&quot;,&quot;kind&quot;:&quot;CloneSet&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;cs-demo&quot;,&quot;namespace&quot;:&quot;default&quot;&#125;,&quot;spec&quot;:&#123;&quot;re...</span><br><span class="line">API Version:  apps.kruise.io/v1alpha1</span><br><span class="line">Kind:         CloneSet</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age   From                 Message</span><br><span class="line">  ----    ------            ----  ----                 -------</span><br><span class="line">  Normal  SuccessfulCreate  53s   cloneset-controller  succeed to create pod cs-demo-b6r6t</span><br><span class="line">  Normal  SuccessfulCreate  53s   cloneset-controller  succeed to create pod cs-demo-fsbx5</span><br><span class="line">  Normal  SuccessfulCreate  53s   cloneset-controller  succeed to create pod cs-demo-fv5gb</span><br></pre></td></tr></table></figure>



<p>该对象创建完成后我们可以通过 <code>kubectl describe</code> 命令查看对应的 Events 信息，可以发现 <code>cloneset-controller</code> 是直接创建的 Pod，这个和原生的 Deployment 就有一些区别了，Deployment 是通过 ReplicaSet 去创建的 Pod，所以从这里也可以看出来 CloneSet 是直接管理 Pod 的，3 个副本的 Pod 此时也创建成功了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=cs</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">cs-demo-b6r6t   1/1     Running   0          5m19s</span><br><span class="line">cs-demo-fsbx5   1/1     Running   0          5m19s</span><br><span class="line">cs-demo-fv5gb   1/1     Running   0          5m19s</span><br></pre></td></tr></table></figure>



<p>CloneSet 虽然在使用上和 Deployment 比较类似，但还是有非常多比 Deployment 更高级的功能，下面我们来详细介绍下。</p>
<h3 id="扩缩容"><a href="#扩缩容" class="headerlink" title="扩缩容"></a>扩缩容</h3><p>CloneSet 在扩容的时候可以通过 <code>ScaleStrategy.MaxUnavailable</code> 来限制扩容的步长，这样可以对服务应用的影响最小，可以设置一个绝对值或百分比，如果不设置该值，则表示不限制。</p>
<p>比如我们在上面的资源清单中添加如下所示数据：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CloneSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cs-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minReadySeconds:</span> <span class="number">60</span></span><br><span class="line">  <span class="attr">scaleStrategy:</span></span><br><span class="line">    <span class="attr">maxUnavailable:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="string">......</span></span><br></pre></td></tr></table></figure>



<p>上面我们配置 <code>scaleStrategy.maxUnavailable</code> 为 1，结合 <code>minReadySeconds</code> 参数，表示在扩容时，只有当上一个扩容出的 Pod 已经 Ready 超过一分钟后，CloneSet 才会执行创建下一个 Pod，比如这里我们扩容成 5 个副本，更新上面对象后查看 CloneSet 的事件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl describe cloneset cs-demo</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason            Age                   From                 Message</span><br><span class="line">  ----     ------            ----                  ----                 -------</span><br><span class="line">  Normal   SuccessfulCreate  35m                   cloneset-controller  succeed to create pod cs-demo-b6r6t</span><br><span class="line">  Normal   SuccessfulCreate  35m                   cloneset-controller  succeed to create pod cs-demo-fsbx5</span><br><span class="line">  Normal   SuccessfulCreate  35m                   cloneset-controller  succeed to create pod cs-demo-fv5gb</span><br><span class="line">  Warning  ScaleUpLimited    2m39s                 cloneset-controller  scaleUp is limited because of scaleStrategy.maxUnavailable, limit: 1</span><br><span class="line">  Normal   SuccessfulCreate  2m39s                 cloneset-controller  succeed to create pod cs-demo-xlsdg</span><br><span class="line">  Normal   SuccessfulCreate  98s                   cloneset-controller  succeed to create pod cs-demo-8w7h4</span><br><span class="line">  Warning  ScaleUpLimited    68s (x12 over 2m39s)  cloneset-controller  scaleUp is limited because of scaleStrategy.maxUnavailable, limit: 0</span><br><span class="line">  Normal   SuccessfulCreate  37s                   cloneset-controller  succeed to create pod cs-demo-79rcx</span><br></pre></td></tr></table></figure>



<p>可以看到第一时间扩容了一个 Pod，由于我们配置了 <code>minReadySeconds: 60</code>，也就是新扩容的 Pod 创建成功超过 1 分钟后才会扩容另外一个 Pod，上面的 Events 信息也能表现出来，查看 Pod 的 <code>AGE</code> 也能看出来扩容的 2 个 Pod 之间间隔了 1 分钟左右：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=cs</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">cs-demo-79rcx   1/1     Running   0          2m3s</span><br><span class="line">cs-demo-8w7h4   1/1     Running   0          3m4s</span><br><span class="line">cs-demo-b6r6t   1/1     Running   0          36m</span><br><span class="line">cs-demo-fv5gb   1/1     Running   0          36m</span><br><span class="line">cs-demo-p4kmw   1/1     Running   0          36s</span><br></pre></td></tr></table></figure>



<p>当 CloneSet 被缩容时，我们还可以指定一些 Pod 来删除，这对于 StatefulSet 或者 Deployment 来说是无法实现的， StatefulSet 是根据序号来删除 Pod，而 Deployment&#x2F;ReplicaSet 目前只能根据控制器里定义的排序来删除。而 CloneSet 允许用户在缩小 replicas 数量的同时，指定想要删除的 Pod 名字，如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CloneSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cs-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">minReadySeconds:</span> <span class="number">60</span></span><br><span class="line">  <span class="attr">scaleStrategy:</span></span><br><span class="line">    <span class="attr">maxUnavailable:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">podsToDelete:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">cs-demo-79rcx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">4</span></span><br><span class="line">  <span class="string">......</span></span><br></pre></td></tr></table></figure>



<p>更新上面的资源对象后，会将应用缩到 4 个 Pod，如果在 <code>podsToDelete</code> 列表中指定了 Pod 名字，则控制器会优先删除这些 Pod，对于已经被删除的 Pod，控制器会自动从 <code>podsToDelete</code> 列表中清理掉。比如我们更新上面的资源对象后 <code>cs-demo-79rcx</code> 这个 Pod 会被移除，其余会保留下来：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=cs</span><br><span class="line">NAME            READY   STATUS    RESTARTS      AGE</span><br><span class="line">cs-demo-8w7h4   1/1     Running   4 (51m ago)   3d6h</span><br><span class="line">cs-demo-b6r6t   1/1     Running   4 (51m ago)   3d6h</span><br><span class="line">cs-demo-fv5gb   1/1     Running   4 (51m ago)   3d6h</span><br><span class="line">cs-demo-p4kmw   1/1     Running   4 (51m ago)   3d6h</span><br></pre></td></tr></table></figure>



<p>如果你只把 Pod 名字加到 <code>podsToDelete</code>，但没有修改 replicas 数量，那么控制器会先把指定的 Pod 删掉，然后再扩一个新的 Pod，另一种直接删除 Pod 的方式是在要删除的 Pod 上打 <code>apps.kruise.io/specified-delete: true</code> 标签。</p>
<p>相比于手动直接删除 Pod，使用 <code>podsToDelete</code> 或 <code>apps.kruise.io/specified-delete: true</code> 方式会有 CloneSet 的 <code>maxUnavailable/maxSurge</code> 来保护删除， 并且会触发 <code>PreparingDelete</code> 生命周期的钩子。</p>
<h3 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h3><p>CloneSet 一共提供了 3 种升级方式：</p>
<ul>
<li><code>ReCreate</code>: 删除旧 Pod 和它的 PVC，然后用新版本重新创建出来，这是默认的方式</li>
<li><code>InPlaceIfPossible</code>: 会优先尝试原地升级 Pod，如果不行再采用重建升级</li>
<li><code>InPlaceOnly</code>: 只允许采用原地升级，因此，用户只能修改上一条中的限制字段，如果尝试修改其他字段会被拒绝</li>
</ul>
<p>这里有一个重要概念：<strong>原地升级</strong>，这也是 OpenKruise 提供的核心功能之一，当我们要升级一个 Pod 中镜像的时候，下图展示了<strong>重建升级</strong>和<strong>原地升级</strong>的区别：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/yzpb5x.png" alt="原地升级"></p>
<p><strong>重建升级</strong>时我们需要删除旧 Pod、创建新 Pod：</p>
<ul>
<li>Pod 名字和 uid 发生变化，因为它们是完全不同的两个 Pod 对象（比如 Deployment 升级）</li>
<li>Pod 名字可能不变、但 uid 变化，因为它们是不同的 Pod 对象，只是复用了同一个名字（比如 StatefulSet 升级）</li>
<li>Pod 所在 Node 名字可能发生变化，因为新 Pod 很可能不会调度到之前所在的 Node 节点</li>
<li>Pod IP 发生变化，因为新 Pod 很大可能性是不会被分配到之前的 IP 地址</li>
</ul>
<p>但是对于<strong>原地升级</strong>，我们仍然复用同一个 Pod 对象，只是修改它里面的字段：</p>
<ul>
<li>可以避免如<em>调度</em>、<em>分配 IP</em>、<em>挂载盘</em>等额外的操作和代价</li>
<li>更快的镜像拉取，因为会复用已有旧镜像的大部分 layer 层，只需要拉取新镜像变化的一些 layer</li>
<li>当一个容器在原地升级时，Pod 中的其他容器不会受到影响，仍然维持运行</li>
</ul>
<p>所以显然如果能用<strong>原地升级</strong>方式来升级我们的工作负载，对在线应用的影响是最小的。上面我们提到 CloneSet 升级类型支持 <code>InPlaceIfPossible</code>，这意味着 Kruise 会尽量对 Pod 采取原地升级，如果不能则退化到重建升级，以下的改动会被允许执行原地升级：</p>
<ul>
<li>更新 workload 中的 <code>spec.template.metadata.*</code>，比如 labels&#x2F;annotations，Kruise 只会将 metadata 中的改动更新到存量 Pod 上。</li>
<li>更新 workload 中的 <code>spec.template.spec.containers[x].image</code>，Kruise 会原地升级 Pod 中这些容器的镜像，而不会重建整个 Pod。</li>
<li>从 Kruise v1.0 版本开始，更新 <code>spec.template.metadata.labels/annotations</code> 并且 container 中有配置 env from 这些改动的 <code>labels/anntations</code>，Kruise 会原地升级这些容器来生效新的 env 值。</li>
</ul>
<p>否则，其他字段的改动，比如 <code>spec.template.spec.containers[x].env</code> 或 <code>spec.template.spec.containers[x].resources</code>，都是会回退为重建升级。</p>
<p>比如我们将上面的应用升级方式设置为 <code>InPlaceIfPossible</code>，只需要在资源清单中添加 <code>spec.updateStrategy.type: InPlaceIfPossible</code> 即可：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CloneSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cs-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">InPlaceIfPossible</span></span><br><span class="line">  <span class="string">......</span></span><br></pre></td></tr></table></figure>



<p>更新后可以发现 Pod 的状态并没有发生什么大的变化，名称、IP 都一样，唯一变化的是镜像 tag：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=cs</span><br><span class="line">NAME            READY   STATUS    RESTARTS      AGE</span><br><span class="line">cs-demo-8w7h4   1/1     Running   4 (55m ago)   3d6h</span><br><span class="line">cs-demo-b6r6t   1/1     Running   4 (55m ago)   3d6h</span><br><span class="line">cs-demo-fv5gb   1/1     Running   5 (20s ago)   3d6h</span><br><span class="line">cs-demo-p4kmw   1/1     Running   5 (83s ago)   3d6h</span><br><span class="line">➜ kubectl describe cloneset cs-demo</span><br><span class="line">Name:         cs-demo</span><br><span class="line">Namespace:    default</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">API Version:  apps.kruise.io/v1alpha1</span><br><span class="line">Kind:         CloneSet</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                      Age    From                 Message</span><br><span class="line">  ----    ------                      ----   ----                 -------</span><br><span class="line">  Normal  SuccessfulDelete            4m44s  cloneset-controller  succeed to delete pod cs-demo-79rcx</span><br><span class="line">  Normal  SuccessfulUpdatePodInPlace  97s    cloneset-controller  successfully update pod cs-demo-p4kmw in-place(revision cs-demo-7cb9c88699)</span><br><span class="line">  Normal  SuccessfulUpdatePodInPlace  34s    cloneset-controller  successfully update pod cs-demo-fv5gb in-place(revision cs-demo-7cb9c88699)</span><br><span class="line">➜ kubectl describe pod cs-demo-p4kmw</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                  Age                  From     Message</span><br><span class="line">  ----     ------                  ----                 ----     -------</span><br><span class="line">  Normal   Pulled                  56m                  kubelet  Container image &quot;nginx:alpine&quot; already present on machine</span><br><span class="line">  Normal   Created                 2m28s (x2 over 56m)  kubelet  Created container nginx</span><br><span class="line">  Normal   Killing                 2m28s                kubelet  Container nginx definition changed, will be restarted</span><br><span class="line">  Normal   Pulled                  2m28s                kubelet  Container image &quot;nginx:1.7.9&quot; already present on machine</span><br><span class="line">  Normal   Started                 2m27s (x2 over 56m)  kubelet  Started container nginx</span><br></pre></td></tr></table></figure>



<p>这就是原地升级的效果，原地升级整体工作流程如下图所示：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/o56ayy.png" alt="原地升级流程"></p>
<p>如果你在安装或升级 Kruise 的时候启用了 <code>PreDownloadImageForInPlaceUpdate</code> 这个 feature-gate，CloneSet 控制器会自动在所有旧版本 pod 所在节点上预热你正在灰度发布的新版本镜像，这对于应用发布加速很有帮助。</p>
<p>默认情况下 CloneSet 每个新镜像预热时的并发度都是 1，也就是一个个节点拉镜像，如果需要调整，你可以在 CloneSet annotation 上设置并发度：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CloneSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">apps.kruise.io/image-predownload-parallelism:</span> <span class="string">&#x27;5</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意，为了避免大部分不必要的镜像拉取，目前只针对 <code>replicas &gt; 3</code> 的 CloneSet 做自动预热。</p>
</blockquote>
<p>此外 CloneSet 还支持分批进行灰度，在 <code>updateStrategy</code> 属性中可以配置 <code>partition</code> 参数，该参数可以用来<strong>保留旧版本 Pod 的数量或百分比</strong>，默认为 0：</p>
<ul>
<li>如果是数字，控制器会将 <code>(replicas - partition)</code> 数量的 Pod 更新到最新版本</li>
<li>如果是百分比，控制器会将 <code>(replicas * (100% - partition))</code> 数量的 Pod 更新到最新版本</li>
</ul>
<p>比如，我们将上面示例中的的 image 更新为 <code>nginx:latest</code> 并且设置 <code>partition=2</code>，更新后，过一会查看可以发现只升级了 2 个 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=cs -L controller-revision-hash</span><br><span class="line">NAME            READY   STATUS    RESTARTS      AGE    CONTROLLER-REVISION-HASH</span><br><span class="line">cs-demo-dx4lb   1/1     Running   0             69s    cs-demo-6599fc6cdd</span><br><span class="line">cs-demo-fv5gb   1/1     Running   0             3d7h   cs-demo-7cb9c88699</span><br><span class="line">cs-demo-nngtm   1/1     Running   0             8s     cs-demo-6599fc6cdd</span><br><span class="line">cs-demo-p4kmw   1/1     Running   0             3d6h   cs-demo-7cb9c88699</span><br></pre></td></tr></table></figure>



<p>此外 CloneSet 还支持一些更高级的用法，比如可以定义优先级策略来控制 Pod 发布的优先级规则，还可以定义策略来将一类 Pod 打散到整个发布过程中，也可以暂停 Pod 发布等操作。</p>
<h2 id="Advanced-StatefulSet"><a href="#Advanced-StatefulSet" class="headerlink" title="Advanced StatefulSet"></a>Advanced StatefulSet</h2><p>该控制器在原生的 StatefulSet 基础上增强了发布能力，比如 <code>maxUnavailable</code> 并行发布、原地升级等，该对象的名称也是 StatefulSet，但是 apiVersion 是 <code>apps.kruise.io/v1beta1</code>，这个 CRD 的所有默认字段、默认行为与原生 StatefulSet 完全一致，除此之外还提供了一些 optional 字段来扩展增强的策略。因此，用户从原生 StatefulSet 迁移到 Advanced StatefulSet，只需要把 apiVersion 修改后提交即可：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span>  <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="string">+</span>  <span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1beta1</span></span><br><span class="line">   <span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line">   <span class="attr">metadata:</span></span><br><span class="line">     <span class="attr">name:</span> <span class="string">sample</span></span><br><span class="line">   <span class="attr">spec:</span></span><br><span class="line">     <span class="comment">#...</span></span><br></pre></td></tr></table></figure>



<h3 id="最大不可用"><a href="#最大不可用" class="headerlink" title="最大不可用"></a>最大不可用</h3><p>Advanced StatefulSet 在滚动更新策略中新增了 maxUnavailable 来支持并行 Pod 发布，它会保证发布过程中最多有多少个 Pod 处于不可用状态。注意，maxUnavailable 只能配合 <code>podManagementPolicy</code> 为 Parallel 来使用。</p>
<p>这个策略的效果和 Deployment 中的类似，但是可能会导致发布过程中的 order 顺序不能严格保证，如果不配置 maxUnavailable，它的默认值为 1，也就是和原生 StatefulSet 一样只能串行发布 Pod，即使把 podManagementPolicy 配置为 Parallel 也是这样。</p>
<p>比如现在我们创建一个如下所示的 Advanced StatefulSet：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&#x27;nginx-headless&#x27;</span></span><br><span class="line">  <span class="attr">podManagementPolicy:</span> <span class="string">Parallel</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">3</span></span><br><span class="line">      <span class="comment"># partition: 4</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># @</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<p>直接创建该对象，由于对象名称也是 StatefulSet，所以不能直接用 <code>get sts</code> 来获取了，要通过 <code>get asts</code> 获取：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get asts</span><br><span class="line">NAME   DESIRED   CURRENT   UPDATED   READY   AGE</span><br><span class="line">web    5         5         5         5       8m28s</span><br><span class="line">➜ kubectl get pods -l app=nginx</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">web-0   1/1     Running   0          7m52s</span><br><span class="line">web-1   1/1     Running   0          7m52s</span><br><span class="line">web-2   1/1     Running   0          7m52s</span><br><span class="line">web-3   1/1     Running   0          7m52s</span><br><span class="line">web-4   1/1     Running   0          7m52s</span><br></pre></td></tr></table></figure>



<p>该应用下有五个 Pod，假设应用能容忍 3 个副本不可用，当我们把 StatefulSet 里的 Pod 升级版本的时候，可以通过以下步骤来做：</p>
<ul>
<li><ol>
<li>设置 maxUnavailable&#x3D;3</li>
</ol>
</li>
<li><ol>
<li>(可选) 如果需要灰度升级，设置 partition&#x3D;4，Partition 默认的意思是 order 大于等于这个数值的 Pod 才会更新，在这里就只会更新 P4，即使我们设置了 maxUnavailable&#x3D;3。</li>
</ol>
</li>
<li><ol>
<li>在 P4 升级完成后，把 partition 调整为 0，此时，控制器会同时升级 P1、P2、P3 三个 Pod。注意，如果是原生 StatefulSet，只能串行升级 P3、P2、P1。</li>
</ol>
</li>
<li><ol>
<li>一旦这三个 Pod 中有一个升级完成了，控制器会立即开始升级 P0。</li>
</ol>
</li>
</ul>
<p>比如这里我们把上面应用的镜像版本进行修改，更新后查看 Pod 状态，可以看到有 3 个 Pod 并行升级的：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=nginx</span><br><span class="line">NAME    READY   STATUS              RESTARTS   AGE</span><br><span class="line">web-0   1/1     Running             0          2m41s</span><br><span class="line">web-1   1/1     Running             0          2m41s</span><br><span class="line">web-2   0/1     ContainerCreating   0          10s</span><br><span class="line">web-3   0/1     ContainerCreating   0          10s</span><br><span class="line">web-4   0/1     ContainerCreating   0          10s</span><br></pre></td></tr></table></figure>



<h3 id="原地升级"><a href="#原地升级" class="headerlink" title="原地升级"></a>原地升级</h3><p>Advanced StatefulSet 增加了 <code>podUpdatePolicy</code> 来允许用户指定重建升级还是原地升级。此外还在原地升级中提供了 graceful period 选项，作为优雅原地升级的策略。用户如果配置了 <code>gracePeriodSeconds</code> 这个字段，控制器在原地升级的过程中会先把 Pod status 改为 not-ready，然后等一段时间（gracePeriodSeconds），最后再去修改 Pod spec 中的镜像版本。这样，就为 endpoints-controller 这些控制器留出了充足的时间来将 Pod 从 endpoints 端点列表中去除。</p>
<p>如果使用 <code>InPlaceIfPossible</code> 或 <code>InPlaceOnly</code> 策略，必须要增加一个 <code>InPlaceUpdateReady readinessGate</code>，用来在原地升级的时候控制器将 Pod 设置为 NotReady，比如设置上面的应用为原地升级的方式：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&#x27;nginx-headless&#x27;</span></span><br><span class="line">  <span class="attr">podManagementPolicy:</span> <span class="string">Parallel</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">podUpdatePolicy:</span> <span class="string">InPlaceIfPossible</span> <span class="comment"># 尽可能执行原地升级</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">3</span> <span class="comment"># 允许并行更新，最大不可以实例数为3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">readinessGates:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">conditionType:</span> <span class="string">InPlaceUpdateReady</span> <span class="comment"># 一个新的条件，可确保 Pod 在发生原地更新时保持在 NotReady 状态</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<p>这里我们设置 <code>updateStrategy.rollingUpdate.podUpdatePolicy</code> 为 <code>InPlaceIfPossible</code> 模式，表示尽可能使用原地升级的方式进行更新，此外在 Pod 模板中我们还添加了一个 <code>readinessGates</code> 属性，可以用来确保 Pod 在发生原地更新时保持在 NotReady 状态。比如我们现在使用上面资源清单更新应用，然后重新修改镜像的版本更新，则会进行原地升级：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl describe asts web</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason                      Age                  From                    Message</span><br><span class="line">  ----    ------                      ----                 ----                    -------</span><br><span class="line">  Normal  SuccessfulUpdatePodInPlace  3m30s                statefulset-controller  successfully update pod web-4 in-place(revision web-84644dfc7d)</span><br><span class="line">  Normal  SuccessfulUpdatePodInPlace  3m30s                statefulset-controller  successfully update pod web-3 in-place(revision web-84644dfc7d)</span><br><span class="line">  Normal  SuccessfulUpdatePodInPlace  3m30s                statefulset-controller  successfully update pod web-2 in-place(revision web-84644dfc7d)</span><br></pre></td></tr></table></figure>



<p>同样的 Advanced StatefulSet 也支持原地升级自动预热。</p>
<p>也可以通过设置 paused 为 true 来暂停发布，不过控制器还是会做 replicas 数量管理：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">paused:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<p>另外 Advanced StatefulSet 还支持序号保留功能，通过在 <code>reserveOrdinals</code> 字段中写入需要保留的序号，Advanced StatefulSet 会自动跳过创建这些序号的 Pod，如果 Pod 已经存在，则会被删除。</p>
<blockquote>
<p>注意，<code>spec.replicas</code> 是期望运行的 Pod 数量，<code>spec.reserveOrdinals</code> 是要跳过的序号。</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">4</span></span><br><span class="line">  <span class="attr">reserveOrdinals:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>



<p>比如上面的描述 <code>replicas=4, reserveOrdinals=[1]</code> 的 Advanced StatefulSet，表示实际运行的 Pod 序号为 [0,2,3,4]。</p>
<ul>
<li>如果要把 Pod-3 做迁移并保留序号，则把 3 追加到 reserveOrdinals 列表中，控制器会把 Pod-3 删除并创建 Pod-5（此时运行中 Pod 为 [0,2,4,5]）。</li>
<li>如果只想删除 Pod-3，则把 3 追加到 reserveOrdinals 列表并同时把 replicas 减一修改为 3。控制器会把 Pod-3 删除（此时运行中 Pod 为 [0,2,4]）。</li>
</ul>
<p>为了避免在一个新 Advanced StatefulSet 创建后有大量失败的 pod 被创建出来，从 Kruise v0.10.0 版本开始引入了在 scale strategy 中的 maxUnavailable 策略。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">scaleStrategy:</span></span><br><span class="line">    <span class="attr">maxUnavailable:</span> <span class="number">10</span><span class="string">%</span> <span class="comment"># percentage or absolute number</span></span><br></pre></td></tr></table></figure>



<p>当这个字段被设置之后，Advanced StatefulSet 会保证创建 pod 之后不可用 pod 数量不超过这个限制值。比如说，上面这个 StatefulSet 一开始只会一次性创建 100*10%&#x3D;10 个 pod，在此之后，每当一个 pod 变为 running、ready 状态后，才会再创建一个新 pod 出来。</p>
<blockquote>
<p>注意，这个功能只允许在 podManagementPolicy 是 <code>Parallel</code> 的 StatefulSet 中使用。</p>
</blockquote>
<h2 id="Advanced-DaemonSet"><a href="#Advanced-DaemonSet" class="headerlink" title="Advanced DaemonSet"></a>Advanced DaemonSet</h2><p>这个控制器基于原生 DaemonSet 上增强了发布能力，比如灰度分批、按 Node label 选择、暂停、热升级等。同样的该对象的 Kind 名字也是 DaemonSet，只是 apiVersion 是 <code>apps.kruise.io/v1alpha1</code>，这个 CRD 的所有默认字段、默认行为与原生 DaemonSet 完全一致，除此之外还提供了一些 optional 字段来扩展增强的策略。</p>
<p>因此，用户从原生 DaemonSet 迁移到 Advanced DaemonSet，只需要把 apiVersion 修改后提交即可：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span>  <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="string">+</span>  <span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line">   <span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line">   <span class="attr">metadata:</span></span><br><span class="line">     <span class="attr">name:</span> <span class="string">sample-ds</span></span><br><span class="line">   <span class="attr">spec:</span></span><br><span class="line">     <span class="comment">#...</span></span><br></pre></td></tr></table></figure>



<h3 id="升级-1"><a href="#升级-1" class="headerlink" title="升级"></a>升级</h3><p>Advanced DaemonSet 在 <code>spec.updateStrategy.rollingUpdate</code> 中有一个 <code>rollingUpdateType</code> 字段，标识了如何进行滚动升级：</p>
<ul>
<li><code>Standard</code>: 对于每个节点，控制器会先删除旧的 daemon Pod，再创建一个新 Pod，和原生 DaemonSet 行为一致。</li>
<li><code>Surging</code>: 对于每个 node，控制器会先创建一个新 Pod，等它 ready 之后再删除老 Pod。</li>
</ul>
<p>创建如下所示的资源对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">rollingUpdateType:</span> <span class="string">Standard</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<p>创建后需要通过 <code>get daemon</code> 来获取该对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get daemon</span><br><span class="line">NAME    DESIREDNUMBER   CURRENTNUMBER   UPDATEDNUMBERSCHEDULED   AGE</span><br><span class="line">nginx   2               2               2                        7s</span><br><span class="line">➜ kubectl get pods -l k8s-app=nginx -o wide</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-59mbd   1/1     Running   0          52s   10.244.1.8    node1   &lt;none&gt;           1/1</span><br><span class="line">nginx-qvvkz   1/1     Running   0          52s   10.244.3.12   node2   &lt;none&gt;           1/1</span><br></pre></td></tr></table></figure>



<p>我们这里只有两个 Work 节点，所以一共运行了 2 个 Pod，每个节点上一个，和默认的 DaemonSet 行为基本一致。此外这个策略还支持用户通过配置 node 标签的 selector，来指定灰度升级某些特定类型 node 上的 Pod，比如现在我们只升级 node1 节点的应用，则可以使用 <code>selector</code> 标签来标识：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">rollingUpdateType:</span> <span class="string">Standard</span></span><br><span class="line">      <span class="attr">selector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">kubernetes.io/hostname:</span> <span class="string">node1</span></span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure>



<p>更新应用后可以看到只会更新 node1 节点上的 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl describe daemon nginx</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age    From                  Message</span><br><span class="line">  ----    ------            ----   ----                  -------</span><br><span class="line">  Normal  SuccessfulCreate  4m25s  daemonset-controller  Created pod: nginx-59mbd</span><br><span class="line">  Normal  SuccessfulCreate  4m25s  daemonset-controller  Created pod: nginx-qvvkz</span><br><span class="line">  Normal  SuccessfulDelete  13s    daemonset-controller  Deleted pod: nginx-59mbd</span><br><span class="line">  Normal  SuccessfulCreate  13s    daemonset-controller  Created pod: nginx-7jl22</span><br></pre></td></tr></table></figure>



<p>和前面两个控制器一样，Advanced DaemonSet 也支持分批灰度升级，使用 Partition 进行配置，Partition 的语义是<strong>保留旧版本 Pod 的数量</strong>，默认为 0，如果在发布过程中设置了 partition，则控制器只会将 <code>(status.DesiredNumberScheduled - partition)</code> 数量的 Pod 更新到最新版本。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">partition:</span> <span class="number">10</span></span><br><span class="line">      <span class="attr">paused:</span> <span class="literal">true</span> <span class="comment"># 暂停发布</span></span><br></pre></td></tr></table></figure>



<p>同样 Advanced DaemonSet 也是支持原地升级的，只需要设置 <code>rollingUpdateType</code> 为支持原地升级的类型即可，比如这里我们将上面的应用升级方式设置为 <code>InPlaceIfPossible</code> 即可：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># ...</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">rollingUpdateType:</span> <span class="string">InPlaceIfPossible</span></span><br></pre></td></tr></table></figure>



<p>更新后可以通过查看控制器的事件来验证是否是通过原地升级方式更新应用：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl describe daemon nginx</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason                            Age                From                  Message</span><br><span class="line">  ----     ------                            ----               ----                  -------</span><br><span class="line">  Normal   SuccessfulCreate                  32s                daemonset-controller  Created pod: nginx-m9vj9</span><br><span class="line">  Normal   SuccessfulCreate                  32s                daemonset-controller  Created pod: nginx-tg89g</span><br><span class="line">  Normal   SuccessfulUpdatePodInPlace        16s                daemonset-controller  successfully update pod nginx-tg89g in-place</span><br><span class="line">  Warning  numUnavailable &gt;= maxUnavailable  15s (x7 over 16s)  daemonset-controller  default/nginx number of unavailable DaemonSet pods: 1, is equal to or exceeds allowed maximum: 1</span><br><span class="line">  Normal   SuccessfulUpdatePodInPlace        14s                daemonset-controller  successfully update pod nginx-m9vj9 in-place</span><br></pre></td></tr></table></figure>



<h2 id="BroadcastJob"><a href="#BroadcastJob" class="headerlink" title="BroadcastJob"></a>BroadcastJob</h2><p>这个控制器将 Pod 分发到集群中每个节点上，类似于 DaemonSet，但是 BroadcastJob 管理的 Pod 并不是长期运行的 daemon 服务，而是类似于 Job 的任务类型 Pod，在每个节点上的 Pod 都执行完成退出后，BroadcastJob 和这些 Pod 并不会占用集群资源。 这个控制器非常有利于做升级基础软件、巡检等过一段时间需要在整个集群中跑一次的工作。</p>
<p>比如我们声明一个如下所示的 BroadcastJob 对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BroadcastJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bcj-demo</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">      <span class="attr">containers:</span> <span class="comment"># 一定不是一个常驻前台的进程，一定是一个任务，执行完成后需要退出的</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">          <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;/bin/sh&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;for i in 9 8 7 6 5 4 3 2 1; do echo $i; done&#x27;</span></span><br></pre></td></tr></table></figure>



<p>直接创建上面的资源对象，</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get bcj bcj-demo</span><br><span class="line">NAME       DESIRED   ACTIVE   SUCCEEDED   FAILED   AGE</span><br><span class="line">bcj-demo   2         0        2           0        113s</span><br><span class="line">➜ kubectl get pods -o wide</span><br><span class="line">NAME                     READY   STATUS        RESTARTS        AGE     IP             NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">bcj-demo-m4mrw           0/1     Completed     0               5m16s   10.244.1.12    node1   &lt;none&gt;           1/1</span><br><span class="line">bcj-demo-v2fdx           0/1     Completed     0               5m16s   10.244.3.37    node2   &lt;none&gt;           1/1</span><br></pre></td></tr></table></figure>



<p>我们可以看到创建了一个 BroadcastJob 对象后，同时启动了两个 Pod 任务，每个节点上一个，这和原生的 Job 是不太一样的。创建的 BroadcastJob 一共有以下几种状态：</p>
<ul>
<li>Desired : 期望的 Pod 数量（等同于当前集群中匹配的节点数量）</li>
<li>Active: 运行中的 Pod 数量</li>
<li>SUCCEEDED: 执行成功的 Pod 数量</li>
<li>FAILED: 执行失败的 Pod 数量</li>
</ul>
<p>此外在 BroadcastJob 对象中还可以配置任务完成后的一些策略，比如配置 <code>completionPolicy.ttlSecondsAfterFinished: 30</code>，表示这个 job 会在执行结束后 30s 被删除。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BroadcastJob</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">completionPolicy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Always</span></span><br><span class="line">    <span class="attr">ttlSecondsAfterFinished:</span> <span class="number">30</span></span><br><span class="line">  <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>



<p>配置 <code>completionPolicy.activeDeadlineSeconds</code> 为 10，表示这个 job 会在运行超过 10s 之后被标记为失败，并把下面还在运行的 Pod 删除掉。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BroadcastJob</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">completionPolicy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Always</span></span><br><span class="line">    <span class="attr">activeDeadlineSeconds:</span> <span class="number">10</span></span><br><span class="line">  <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>



<p>completionPolicy 类型除了 Always 之外还可以设置为 <code>Never</code>，表示这个 job 会持续运行即使当前所有节点上的 Pod 都执行完成了。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">BroadcastJob</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">completionPolicy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Never</span></span><br><span class="line">  <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>



<h2 id="AdvancedCronJob"><a href="#AdvancedCronJob" class="headerlink" title="AdvancedCronJob"></a>AdvancedCronJob</h2><p>AdvancedCronJob 是对于原生 CronJob 的扩展版本，根据用户设置的 schedule 规则，周期性创建 Job 执行任务，而 AdvancedCronJob 的 template 支持多种不同的 job 资源：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">AdvancedCronJob</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="comment"># Option 1: use jobTemplate, which is equivalent to original CronJob</span></span><br><span class="line">    <span class="attr">jobTemplate:</span></span><br><span class="line">      <span class="comment"># ...</span></span><br><span class="line">    <span class="comment"># Option 2: use broadcastJobTemplate, which will create a BroadcastJob object when cron schedule triggers</span></span><br><span class="line">    <span class="attr">broadcastJobTemplate:</span></span><br><span class="line">      <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>



<ul>
<li><code>jobTemplate</code>：与原生 CronJob 一样创建 Job 执行任务</li>
<li><code>broadcastJobTemplate</code>：周期性创建 BroadcastJob 执行任务</li>
</ul>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/m1vjlt.png" alt="AdvancedCronJob"></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">AdvancedCronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">acj-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&#x27;*/1 * * * *&#x27;</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">broadcastJobTemplate:</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">completionPolicy:</span></span><br><span class="line">          <span class="attr">type:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">ttlSecondsAfterFinished:</span> <span class="number">30</span></span><br><span class="line">        <span class="attr">template:</span></span><br><span class="line">          <span class="attr">spec:</span></span><br><span class="line">            <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">            <span class="attr">containers:</span> <span class="comment"># 一定不是一个常驻前台的进程，一定是一个任务，执行完成后需要退出的</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line">                <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">                <span class="attr">command:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">&#x27;/bin/sh&#x27;</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">&#x27;for i in 9 8 7 6 5 4 3 2 1; do echo $i; done&#x27;</span></span><br></pre></td></tr></table></figure>



<p>上述 YAML 定义了一个 AdvancedCronJob，每分钟创建一个 BroadcastJob 对象，这个 BroadcastJob 会在所有节点上运行一个 job 任务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get acj</span><br><span class="line">NAME       SCHEDULE      TYPE           LASTSCHEDULETIME   AGE</span><br><span class="line">acj-test   */1 * * * *   BroadcastJob                      8s</span><br><span class="line">➜ kubectl get bcj</span><br><span class="line">NAME                  DESIRED   ACTIVE   SUCCEEDED   FAILED   AGE</span><br><span class="line">acj-test-1646305200   2         0        2           0        25s</span><br><span class="line">➜ kubectl get pods</span><br><span class="line">NAME                        READY   STATUS        RESTARTS        AGE</span><br><span class="line">acj-test-1646305200-c4jbr   0/1     Completed     0               41s</span><br><span class="line">acj-test-1646305200-stsm9   0/1     Completed     0               41s</span><br></pre></td></tr></table></figure>



<h2 id="SidecarSet"><a href="#SidecarSet" class="headerlink" title="SidecarSet"></a>SidecarSet</h2><p>SidecarSet 支持通过 admission webhook 来自动为集群中创建的符合条件的 Pod 注入 sidecar 容器，除了在 Pod 创建时候注入外，SidecarSet 还提供了为 Pod 原地升级其中已经注入的 sidecar 容器镜像的能力。SidecarSet 将 sidecar 容器的定义和生命周期与业务容器解耦，它主要用于管理无状态的 sidecar 容器，比如监控、日志等 agent。</p>
<p>比如我们定义一个如下所示的 SidecarSet 资源对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sidecarset.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SidecarSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-sidecarset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">maxUnavailable:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sidecar1</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&#x27;sleep&#x27;</span>, <span class="string">&#x27;999d&#x27;</span>]</span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">  <span class="attr">volumes:</span> <span class="comment"># this field will be merged into pod.spec.volumes</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">log-volume</span></span><br><span class="line">      <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>



<p>直接创建这个资源对象即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get sidecarset</span><br><span class="line">NAME              MATCHED   UPDATED   READY   AGE</span><br><span class="line">test-sidecarset   0         0         0       34s</span><br></pre></td></tr></table></figure>



<p>需要注意上面我们在定义 SidecarSet 对象的时候里面有一个非常终于的属性就是 label selector，会去匹配具有 <code>app=nginx</code> 的 Pod，然后向其中注入下面定义的 <code>sidecar1</code> 这个容器，比如定义如下所示的一个 Pod，该 Pod 中包含 <code>app=nginx</code> 的标签，这样可以和上面的 SidecarSet 对象匹配：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># matches the SidecarSet&#x27;s selector</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br></pre></td></tr></table></figure>



<p>直接创建上面的资源对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pod test-pod</span><br><span class="line">NAME       READY   STATUS    RESTARTS   AGE</span><br><span class="line">test-pod   2/2     Running   0          19s</span><br></pre></td></tr></table></figure>



<p>可以看到该 Pod 中有 2 个容器，被自动注入了上面定义的 <code>sidecar1</code> 容器：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">➜</span> <span class="string">kubectl</span> <span class="string">get</span> <span class="string">pod</span> <span class="string">test-pod</span> <span class="string">-o</span> <span class="string">yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="string">......</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">999d</span></span><br><span class="line">    <span class="attr">env:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">IS_INJECTED</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">sidecar1</span></span><br><span class="line">    <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line">    <span class="attr">terminationMessagePolicy:</span> <span class="string">File</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">log-volume</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">kube-api-access-whxz7</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">name:</span> <span class="string">log-volume</span></span><br><span class="line"><span class="string">......</span></span><br></pre></td></tr></table></figure>



<p>现在我们去更新 SidecarSet 中的 sidecar 容器镜像替换成 <code>busybox:1.35.0</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl patch sidecarset test-sidecarset --type=&#x27;json&#x27; -p=&#x27;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/containers/0/image&quot;, &quot;value&quot;: &quot;busybox:1.35.0&quot;&#125;]&#x27;</span><br><span class="line">sidecarset.apps.kruise.io/test-sidecarset patched</span><br></pre></td></tr></table></figure>



<p>更新后再去查看 Pod 中的 sidecar 容器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pod test-pod</span><br><span class="line">NAME       READY   STATUS    RESTARTS      AGE</span><br><span class="line">test-pod   2/2     Running   1 (67s ago)   28m</span><br><span class="line">➜ kubectl get pod test-pod</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age                From               Message</span><br><span class="line">  ----    ------     ----               ----               -------</span><br><span class="line">  ......</span><br><span class="line">  Normal  Killing    109s               kubelet            Container sidecar1 definition changed, will be restarted</span><br><span class="line">  Normal  Pulling    79s                kubelet            Pulling image &quot;busybox:1.35.0&quot;</span><br><span class="line">  Normal  Started    62s (x2 over 28m)  kubelet            Started container sidecar1</span><br><span class="line">  Normal  Created    62s (x2 over 28m)  kubelet            Created container sidecar1</span><br><span class="line">  Normal  Pulled     62s                kubelet            Successfully pulled image &quot;busybox:1.35.0&quot; in 17.239369684s</span><br><span class="line">➜ kubectl get pod test-pod -o yaml |grep busybox</span><br><span class="line">    kruise.io/sidecarset-inplace-update-state: &#x27;&#123;&quot;test-sidecarset&quot;:&#123;&quot;revision&quot;:&quot;f78z4854d9855xd6478fzx9c84645z2548v24z26455db46bdfzw44v49v98f2cw&quot;,&quot;updateTimestamp&quot;:&quot;2022-03-06T09:56:15Z&quot;,&quot;lastContainerStatuses&quot;:&#123;&quot;sidecar1&quot;:&#123;&quot;imageID&quot;:&quot;docker.io/library/busybox@sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678&quot;&#125;&#125;&#125;&#125;&#x27;</span><br><span class="line">    image: busybox:1.35.0</span><br><span class="line">    image: docker.io/library/busybox:1.35.0</span><br><span class="line">    imageID: docker.io/library/busybox@sha256:130df6999605f982ec67e5bee29d3a52614a075e949490f0a41702ee1dd98f3f</span><br></pre></td></tr></table></figure>



<p>可以看到 Pod 中的 sidecar 容器镜像被原地升级成 <code>busybox:1.35.0</code> 了， 对主容器没有产生任何影响。</p>
<h3 id="同意特性"><a href="#同意特性" class="headerlink" title="同意特性"></a>同意特性</h3><p>需要注意的是 sidecar 的注入只会发生在 Pod 创建阶段，并且只有 Pod spec 会被更新，不会影响 Pod 所属的 workload template 模板。 <code>spec.containers</code> 除了默认的 k8s container 字段，还扩展了如下一些字段，来方便注入：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SidecarSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sidecarset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">sample</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="comment"># 默认的K8s容器字段</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx:alpine</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/nginx/conf</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx.conf</span></span><br><span class="line">      <span class="comment"># 扩展的sidecar容器字段</span></span><br><span class="line">      <span class="attr">podInjectPolicy:</span> <span class="string">BeforeAppContainer</span></span><br><span class="line">      <span class="attr">shareVolumePolicy:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">disabled</span> <span class="string">|</span> <span class="string">enabled</span></span><br><span class="line">      <span class="attr">transferEnv:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">sourceContainerName:</span> <span class="string">main</span></span><br><span class="line">          <span class="attr">envName:</span> <span class="string">PROXY_IP</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">Name:</span> <span class="string">nginx.conf</span></span><br><span class="line">      <span class="attr">hostPath:</span> <span class="string">/data/nginx/conf</span></span><br></pre></td></tr></table></figure>



<ul>
<li><pre><code>podInjectPolicy
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">定义了容器 注入到</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br></pre></td></tr></table></figure>
pod.spec.containers
<figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">  中的位置</span><br><span class="line"></span><br><span class="line">  - `BeforeAppContainer`：表示注入到 pod 原 containers 的前面（(默认) ）</span><br><span class="line">  - `AfterAppContainer`： 表示注入到 pod 原 containers 的后面</span><br><span class="line"></span><br><span class="line">- 数据卷共享</span><br><span class="line"></span><br><span class="line">  - 共享指定卷：通过 `spec.volumes` 来定义 sidecar 自身需要的 volume</span><br><span class="line">  - 共享所有卷：通过 `spec.containers[i].shareVolumePolicy.type = enabled | disabled` 来控制是否挂载 pod 应用容器的卷，常用于日志收集等 sidecar，配置为 `enabled` 后会把应用容器中所有挂载点注入 sidecar 同一路经下(sidecar 中本身就有声明的数据卷和挂载点除外）</span><br><span class="line"></span><br><span class="line">- 环境变量共享：可以通过 `spec.containers[i].transferEnv` 来从别的容器获取环境变量，会把名为 `sourceContainerName` 容器中名为 `envName` 的环境变量拷贝到本容器</span><br><span class="line"></span><br><span class="line">SidecarSet 不仅支持 sidecar 容器的原地升级，而且提供了非常丰富的升级、灰度策略。同样在 SidecarSet 对象中 `updateStrategy` 属性下面也可以配置 `partition` 来定义保留旧版本 Pod 的数量或百分比，默认为 <span class="number">0</span>；同样还可以配置的有 `maxUnavailable` 属性，表示在发布过程中的最大不可用数量。</span><br><span class="line"></span><br><span class="line">- 当 `&#123;matched pod&#125;=<span class="number">100</span>,partition=<span class="number">50</span>,maxUnavailable=<span class="number">10</span>`，控制器会发布 <span class="number">50</span> 个 Pod 到新版本，但是同一时间只会发布 <span class="number">10</span> 个 Pod，每发布好一个 Pod 才会再找一个发布，直到 <span class="number">50</span> 个发布完成。</span><br><span class="line">- 当 `&#123;matched pod&#125;=<span class="number">100</span>,partition=<span class="number">80</span>,maxUnavailable=<span class="number">30</span>`，控制器会发布 <span class="number">20</span> 个 Pod 到新版本，因为满足 maxUnavailable 数量，所以这 <span class="number">20</span> 个 Pod 会同时发布。</span><br><span class="line"></span><br><span class="line"><span class="title">同样也可以设置 `paused:</span> <span class="literal">true</span>` 来暂停发布，此时对于新创建的、扩容的 pod 依旧会实现注入能力，已经更新的 pod 会保持更新后的版本不动，还没有更新的 pod 会暂停更新。</span><br><span class="line"></span><br><span class="line">```yaml</span><br><span class="line"><span class="title">apiVersion:</span> apps.kruise.io/v1alpha1</span><br><span class="line"><span class="title">kind:</span> SidecarSet</span><br><span class="line"><span class="title">metadata:</span></span><br><span class="line"><span class="title">  name:</span> sidecarset</span><br><span class="line"><span class="title">spec:</span></span><br><span class="line">  # ...</span><br><span class="line"><span class="title">  updateStrategy:</span></span><br><span class="line"><span class="title">    type:</span> RollingUpdate</span><br><span class="line"><span class="title">    maxUnavailable:</span> <span class="number">20</span>%</span><br><span class="line"><span class="title">    partition:</span> <span class="number">10</span></span><br><span class="line"><span class="title">    paused:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<h3 id="金丝雀发布"><a href="#金丝雀发布" class="headerlink" title="金丝雀发布"></a>金丝雀发布</h3><p>对于有金丝雀发布需求的业务，可以通过 <code>selector</code> 来实现，对于需要率先金丝雀灰度的 pod 打上固定的 <code>[canary.release] = true</code> 的标签，再通过 <code>selector.matchLabels</code> 来选中该 pod 即可。</p>
<p>比如现在我们有一个 3 副本的 Pod，也具有 <code>app=nginx</code> 的标签，如下所示</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ngx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<p>创建后现在就具有 4 个 <code>app=nginx</code> 标签的 Pod 了，由于都匹配上面创建的 SidecarSet 对象，所以都会被注入一个 <code>sidecar1</code> 的容器，镜像为 <code>busybox</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=nginx</span><br><span class="line">NAME                    READY   STATUS    RESTARTS       AGE</span><br><span class="line">nginx-6457955f7-7hnjw   2/2     Running   0              51s</span><br><span class="line">nginx-6457955f7-prkgz   2/2     Running   0              51s</span><br><span class="line">nginx-6457955f7-tbtxk   2/2     Running   0              51s</span><br><span class="line">test-pod                2/2     Running   0              4m2s</span><br></pre></td></tr></table></figure>



<p>现在如果我们想为 <code>test-pod</code> 这个应用来执行灰度策略，将 sidecar 容器镜像更新成 <code>busybox:1.35.0</code>，则可以在 <code>updateStrategy</code> 下面添加 <code>selector.matchLabels</code> 属性 <code>canary.release: &quot;true&quot;</code>：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">piVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SidecarSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-sidecarset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">selector:</span></span><br><span class="line">      <span class="attr">matchLabels:</span></span><br><span class="line">        <span class="attr">canary.release:</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sidecar1</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox:1.35.0</span></span><br><span class="line">  <span class="comment"># ......</span></span><br></pre></td></tr></table></figure>



<p>然后同样需要给 test-pod 添加上 <code>canary.release=true</code> 这个标签：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">canary.release:</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br></pre></td></tr></table></figure>



<p>更新后可以发现 test-pod 的 sidecar 镜像更新了，其他 Pod 没有变化，这样就实现了 sidecar 的灰度功能：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl describe pod test-pod</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age                    From               Message</span><br><span class="line">  ----    ------     ----                   ----               -------</span><br><span class="line">  Normal  Killing    7m53s                  kubelet            Container sidecar1 definition changed, will be restarted</span><br><span class="line">  Normal  Created    7m23s (x2 over 8m17s)  kubelet            Created container sidecar1</span><br><span class="line">  Normal  Started    7m23s (x2 over 8m17s)  kubelet            Started container sidecar1</span><br><span class="line">  Normal  Pulling    7m23s                  kubelet            Pulling image &quot;busybox&quot;</span><br><span class="line">  Normal  Pulled     7m23s                  kubelet            Successfully pulled image &quot;busybox&quot; in 603.928658ms</span><br></pre></td></tr></table></figure>



<h3 id="热升级"><a href="#热升级" class="headerlink" title="热升级"></a>热升级</h3><p>SidecarSet 原地升级会先停止旧版本的容器，然后创建新版本的容器，这种方式适合不影响 Pod 服务可用性的 sidecar 容器，比如说日志收集的 Agent。</p>
<p>但是对于很多代理或运行时的 sidecar 容器，例如 Istio Envoy，这种升级方法就有问题了，Envoy 作为 Pod 中的一个代理容器，代理了所有的流量，如果直接重启，Pod 服务的可用性会受到影响，如果需要单独升级 envoy sidecar，就需要复杂的优雅终止和协调机制，所以我们为这种 sidecar 容器的升级提供了一种新的解决方案。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SidecarSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hotupgrade-sidecarset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">hotupgrade</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sidecar</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">openkruise/hotupgrade-sample:sidecarv1</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">      <span class="attr">lifecycle:</span></span><br><span class="line">        <span class="attr">postStart:</span></span><br><span class="line">          <span class="attr">exec:</span></span><br><span class="line">            <span class="attr">command:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">/migrate.sh</span></span><br><span class="line">      <span class="attr">upgradeStrategy:</span></span><br><span class="line">        <span class="attr">upgradeType:</span> <span class="string">HotUpgrade</span></span><br><span class="line">        <span class="attr">hotUpgradeEmptyImage:</span> <span class="string">openkruise/hotupgrade-sample:empty</span></span><br></pre></td></tr></table></figure>



<ul>
<li><code>upgradeType</code>: <code>HotUpgrade</code> 代表该 sidecar 容器的类型是热升级方案</li>
<li><code>hotUpgradeEmptyImage</code>: 当热升级 sidecar 容器时，业务必须要提供一个 empty 容器用于热升级过程中的容器切换，empty 容器同 sidecar 容器具有相同的配置（除了镜像地址），例如：command、lifecycle、probe 等，但是它不做任何工作。</li>
<li><code>lifecycle.postStart</code>: 在 postStart 这个 hook 中完成热升级过程中的状态迁移，该脚本需要由业务根据自身的特点自行实现，例如：nginx 热升级需要完成 Listen FD 共享以及 reload 操作。</li>
</ul>
<p>整体来说热升级特性总共包含以下两个过程：</p>
<ul>
<li>Pod 创建时，注入热升级容器</li>
<li>原地升级时，完成热升级流程</li>
</ul>
<p><strong>注入热升级容器</strong></p>
<p>Pod 创建时，SidecarSet Webhook 将会注入两个容器：</p>
<ul>
<li><code>&#123;sidecarContainer.name&#125;-1</code>: 如下图所示 envoy-1，这个容器代表正在实际工作的 sidecar 容器，例如：envoy:1.16.0</li>
<li><code>&#123;sidecarContainer.name&#125;-2</code>: 如下图所示 envoy-2，这个容器是业务配置的 hotUpgradeEmptyImage 容器，例如：empty:1.0，用于后面的热升级机制</li>
</ul>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/nzt57y.png" alt="注入热升级容器"></p>
<p><strong>热升级流程</strong></p>
<p>热升级流程主要分为三个步骤：</p>
<ul>
<li><code>Upgrade</code>: 将 empty 容器升级为当前最新的 sidecar 容器，例如：envoy-2.Image &#x3D; envoy:1.17.0</li>
<li><code>Migration</code>: <code>lifecycle.postStart</code> 完成热升级流程中的状态迁移，当迁移完成后退出</li>
<li><code>Reset</code>: 状态迁移完成后，热升级流程将设置 envoy-1 容器为 empty 镜像，例如：envoy-1.Image &#x3D; empty:1.0</li>
</ul>
<p>上述三个步骤完成了热升级中的全部流程，当对 Pod 执行多次热升级时，将重复性的执行上述三个步骤。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/qckmck.png" alt="热升级流程"></p>
<p>这里我们以 OpenKruise 的官方示例来进行说明，首先创建上面的 <code>hotupgrade-sidecarset</code> 这个 SidecarSet。然后创建一个如下所示的 CloneSet 对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CloneSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">hotupgrade</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">hotupgrade</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">hotupgrade</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">openkruise/hotupgrade-sample:busybox</span></span><br></pre></td></tr></table></figure>



<p>创建完成后，CloneSet 管理的 Pod 已经注入 <code>sidecar-1</code> 和 <code>sidecar-2</code> 两个容器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get sidecarset hotupgrade-sidecarset</span><br><span class="line">NAME                    MATCHED   UPDATED   READY   AGE</span><br><span class="line">hotupgrade-sidecarset   1         1         0       6s</span><br><span class="line">➜ kubectl get pods -l app=hotupgrade</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox-t7phd   3/3     Running   0          79s</span><br><span class="line">kubectl get pods -l app=hotupgrade</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox-t7phd   3/3     Running   0          79s</span><br><span class="line">➜ kubectl describe pods busybox-t7phd</span><br><span class="line">Name:         busybox-t7phd</span><br><span class="line">Namespace:    default</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         node2/192.168.31.174</span><br><span class="line">......</span><br><span class="line">Controlled By:  CloneSet/busybox</span><br><span class="line">Containers:</span><br><span class="line">  sidecar-1:</span><br><span class="line">    Container ID:   containerd://5afe9c26923508bf480238a232a2ab1457d96b51ff28024a36980544ad5c0d94</span><br><span class="line">    Image:          openkruise/hotupgrade-sample:sidecarv1</span><br><span class="line">    Environment:</span><br><span class="line">      IS_INJECTED:             true</span><br><span class="line">      SIDECARSET_VERSION:       (v1:metadata.annotations[&#x27;version.sidecarset.kruise.io/sidecar-1&#x27;])</span><br><span class="line">      SIDECARSET_VERSION_ALT:   (v1:metadata.annotations[&#x27;versionalt.sidecarset.kruise.io/sidecar-1&#x27;])</span><br><span class="line">  sidecar-2:</span><br><span class="line">    Container ID:   containerd://e17b576eb24985efd4154f3bc94e88bb6231b37bb391b6d611b0dc12e7a8db0b</span><br><span class="line">    Image:          openkruise/hotupgrade-sample:empty</span><br><span class="line">    Environment:</span><br><span class="line">      IS_INJECTED:             true</span><br><span class="line">      SIDECARSET_VERSION:       (v1:metadata.annotations[&#x27;version.sidecarset.kruise.io/sidecar-2&#x27;])</span><br><span class="line">      SIDECARSET_VERSION_ALT:   (v1:metadata.annotations[&#x27;versionalt.sidecarset.kruise.io/sidecar-2&#x27;])</span><br><span class="line">  busybox:</span><br><span class="line">    Container ID:   containerd://6d0d45a1981f63df45ce2fba958b734ccac25d010192f441d98dcc4a1b421646</span><br><span class="line">    Image:          openkruise/hotupgrade-sample:busybox</span><br><span class="line">......</span><br></pre></td></tr></table></figure>



<p>busybox 主容器每 100 毫秒会请求一次 sidecar(version&#x3D;v1)服务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl logs -f busybox-t7phd -c busybox</span><br><span class="line">I0306 11:07:38.363847       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br><span class="line">I0306 11:07:38.474805       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br><span class="line">I0306 11:07:38.585975       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br><span class="line">I0306 11:07:38.697097       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br><span class="line">......</span><br></pre></td></tr></table></figure>



<p>现在我们去升级 sidecar 容器，将镜像修改为 <code>openkruise/hotupgrade-sample:sidecarv2</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl patch sidecarset hotupgrade-sidecarset --type=&#x27;json&#x27; -p=&#x27;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/containers/0/image&quot;, &quot;value&quot;: &quot;openkruise/hotupgrade-sample:sidecarv2&quot;&#125;]&#x27;</span><br></pre></td></tr></table></figure>



<p>更新后再去观察 pod 的状态，可以看到 sidecar-2 镜像正常更新了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods busybox-t7phd</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox-t7phd   3/3     Running   0          6m59s</span><br><span class="line">➜ kubectl describe pods busybox-t7phd</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  ......</span><br><span class="line">  Normal  Created    6m12s  kubelet            Created container busybox</span><br><span class="line">  Normal  Started    6m12s  kubelet            Started container busybox</span><br><span class="line">  Normal  Killing    32s    kubelet            Container sidecar-2 definition changed, will be restarted</span><br><span class="line">  Normal  Pulling    32s    kubelet            Pulling image &quot;openkruise/hotupgrade-sample:sidecarv2&quot;</span><br></pre></td></tr></table></figure>



<p>并且在更新过程中观察 busybox 容器仍然会不断请求 sidecar 服务，但是并没有失败的请求出现：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl logs -f busybox-t7phd -c busybox</span><br><span class="line">I0306 11:08:47.365196       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br><span class="line">I0306 11:08:47.476553       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br><span class="line">I0306 11:08:47.587727       1 main.go:39] request sidecar server success, and response(body=This is version(v1) sidecar)</span><br></pre></td></tr></table></figure>



<p>整个热升级示例代码可以参考仓库的实现：<a target="_blank" rel="noopener" href="https://github.com/openkruise/samples/tree/master/hotupgrade%E3%80%82">https://github.com/openkruise/samples/tree/master/hotupgrade。</a></p>
<h2 id="Container-Restart"><a href="#Container-Restart" class="headerlink" title="Container Restart"></a>Container Restart</h2><p><code>ContainerRecreateRequest</code> 控制器可以帮助用户重启&#x2F;重建存量 Pod 中一个或多个容器。和 Kruise 提供的原地升级类似，当一个容器重建的时候，Pod 中的其他容器还保持正常运行，重建完成后，Pod 中除了该容器的 restartCount 增加以外不会有什么其他变化。</p>
<p>为要重建容器的 Pod 提交一个 <code>ContainerRecreateRequest</code> 自定义资源（缩写 CRR）：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ContainerRecreateRequest</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">pod-namespace</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">xxx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podName:</span> <span class="string">pod-name</span></span><br><span class="line">  <span class="attr">containers:</span> <span class="comment"># 要重建的容器名字列表，至少要有 1 个</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sidecar</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">failurePolicy:</span> <span class="string">Fail</span> <span class="comment"># &#x27;Fail&#x27; 或 &#x27;Ignore&#x27;，表示一旦有某个容器停止或重建失败， CRR 立即结束</span></span><br><span class="line">    <span class="attr">orderedRecreate:</span> <span class="literal">false</span> <span class="comment"># &#x27;true&#x27; 表示要等前一个容器重建完成了，再开始重建下一个</span></span><br><span class="line">    <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span> <span class="comment"># 等待容器优雅退出的时间，不填默认用 Pod 中定义的</span></span><br><span class="line">    <span class="attr">unreadyGracePeriodSeconds:</span> <span class="number">3</span> <span class="comment"># 在重建之前先把 Pod 设为 not ready，并等待这段时间后再开始执行重建</span></span><br><span class="line">    <span class="attr">minStartedSeconds:</span> <span class="number">10</span> <span class="comment"># 重建后新容器至少保持运行这段时间，才认为该容器重建成功</span></span><br><span class="line">  <span class="attr">activeDeadlineSeconds:</span> <span class="number">300</span> <span class="comment"># 如果 CRR 执行超过这个时间，则直接标记为结束（未结束的容器标记为失败）</span></span><br><span class="line">  <span class="attr">ttlSecondsAfterFinished:</span> <span class="number">1800</span> <span class="comment"># CRR 结束后，过了这段时间自动被删除掉</span></span><br></pre></td></tr></table></figure>



<p>一般来说，列表中的容器会一个个被停止，但可能同时在被重建和启动，除非 <code>orderedRecreate</code> 被设置为 true。 <code>unreadyGracePeriodSeconds</code> 功能依赖于 <code>KruisePodReadinessGate</code> 这个 feature-gate，后者会在每个 Pod 创建的时候注入一个 <code>readinessGate</code>，否则，默认只会给 Kruise workload 创建的 Pod 注入 readinessGate，也就是说只有这些 Pod 才能在 CRR 重建时使用 <code>unreadyGracePeriodSeconds</code>。</p>
<h2 id="ImagePullJob"><a href="#ImagePullJob" class="headerlink" title="ImagePullJob"></a>ImagePullJob</h2><p><code>NodeImage</code> 和 <code>ImagePullJob</code> 是从 Kruise v0.8.0 版本开始提供的 CRD。Kruise 会自动为每个 Node 创建一个 NodeImage，它包含了哪些镜像需要在这个 Node 上做预热，比如我们这里 3 个节点，则会自动创建 3 个 NodeImage 对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get nodeimage</span><br><span class="line">NAME      DESIRED   PULLING   SUCCEED   FAILED   AGE</span><br><span class="line">master1   0         0         0         0        10d</span><br><span class="line">node1     0         0         0         0        10d</span><br><span class="line">node2     0         0         0         0        10d</span><br></pre></td></tr></table></figure>



<p>比如我们查看 node1 节点上的 NodeImage 对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">➜</span>  <span class="string">kruise</span> <span class="string">kubectl</span> <span class="string">get</span> <span class="string">nodeimage</span> <span class="string">node1</span> <span class="string">-o</span> <span class="string">yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NodeImage</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">beta.kubernetes.io/arch:</span> <span class="string">amd64</span></span><br><span class="line">    <span class="attr">beta.kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">    <span class="attr">kubernetes.io/arch:</span> <span class="string">amd64</span></span><br><span class="line">    <span class="attr">kubernetes.io/hostname:</span> <span class="string">node1</span></span><br><span class="line">    <span class="attr">kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node1</span></span><br><span class="line"><span class="attr">spec:</span> &#123;&#125;</span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">desired:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">failed:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">pulling:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">succeeded:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>



<p>比如我们希望在这个节点上拉去一个 <code>ubuntu:latest</code> 镜像，则可以按照如下所示的去修改 spec：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">......</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">images:</span></span><br><span class="line">    <span class="attr">ubuntu:</span>  <span class="comment"># 镜像 name</span></span><br><span class="line">      <span class="attr">tags:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">tag:</span> <span class="string">latest</span>  <span class="comment"># 镜像 tag</span></span><br><span class="line">        <span class="attr">pullPolicy:</span></span><br><span class="line">          <span class="attr">ttlSecondsAfterFinished:</span> <span class="number">300</span>  <span class="comment"># [required] 拉取完成（成功或失败）超过 300s 后，将这个任务从 NodeImage 中清除</span></span><br><span class="line">          <span class="attr">timeoutSeconds:</span> <span class="number">600</span>           <span class="comment"># [optional] 每一次拉取的超时时间, 默认为 600</span></span><br><span class="line">          <span class="attr">backoffLimit:</span> <span class="number">3</span>               <span class="comment"># [optional] 拉取的重试次数，默认为 3</span></span><br><span class="line">          <span class="attr">activeDeadlineSeconds:</span> <span class="number">1200</span>   <span class="comment"># [optional] 整个任务的超时时间，无默认值</span></span><br></pre></td></tr></table></figure>



<p>更新后我们可以从 status 中看到拉取进度以及结果，并且你会发现拉取完成 600s 后任务会被清除。</p>
<p>此外用户可以创建 <code>ImagePullJob</code> 对象，来指定一个镜像要在哪些节点上做预热。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/4pfalb.png" alt="ImagePullJob"></p>
<p>比如创建如下所示的 <code>ImagePullJob</code> 资源对象：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps.kruise.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ImagePullJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">job-with-always</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">nginx:1.9.1</span> <span class="comment"># [required] 完整的镜像名 name:tag</span></span><br><span class="line">  <span class="attr">parallelism:</span> <span class="number">10</span> <span class="comment"># [optional] 最大并发拉取的节点梳理, 默认为 1</span></span><br><span class="line">  <span class="attr">selector:</span> <span class="comment"># [optional] 指定节点的 名字列表 或 标签选择器 (只能设置其中一种)</span></span><br><span class="line">    <span class="attr">names:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node-1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node-2</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">node-type:</span> <span class="string">xxx</span></span><br><span class="line">  <span class="comment"># podSelector:         # [optional] pod label 选择器来在这些 pod 所在节点上拉取镜像, 与 selector 不能同时设置.</span></span><br><span class="line">  <span class="comment">#  pod-label: xxx</span></span><br><span class="line">  <span class="attr">completionPolicy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Always</span> <span class="comment"># [optional] 默认为 Always</span></span><br><span class="line">    <span class="attr">activeDeadlineSeconds:</span> <span class="number">1200</span> <span class="comment"># [optional] 无默认值, 只对 Alway 类型生效</span></span><br><span class="line">    <span class="attr">ttlSecondsAfterFinished:</span> <span class="number">300</span> <span class="comment"># [optional] 无默认值, 只对 Alway 类型生效</span></span><br><span class="line">  <span class="attr">pullPolicy:</span> <span class="comment"># [optional] 默认 backoffLimit=3, timeoutSeconds=600</span></span><br><span class="line">    <span class="attr">backoffLimit:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">timeoutSeconds:</span> <span class="number">300</span></span><br><span class="line">  <span class="attr">pullSecrets:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">secret-name1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">secret-name2</span></span><br></pre></td></tr></table></figure>



<p>我们可以在 <code>selector</code> 字段中指定节点的名字列表或标签选择器 (只能设置其中一种)，如果没有设置 selector 则会选择所有节点做预热。或者可以配置 <code>podSelector</code> 来在这些 pod 所在节点上拉取镜像，podSelector 与 selector 不能同时设置。</p>
<p>同时，ImagePullJob 有两种 <code>completionPolicy</code> 类型:</p>
<ul>
<li><code>Always</code>：表示这个 job 是一次性预热，不管成功、失败都会结束</li>
<li><code>activeDeadlineSeconds</code>：整个 job 的 deadline 结束时间</li>
<li><code>ttlSecondsAfterFinished</code>：结束后超过这个时间，自动清理删除 job</li>
<li><code>Never</code>：表示这个 job 是长期运行、不会结束，并且会每天都会在匹配的节点上重新预热一次指定的镜像</li>
</ul>
<p>同样如果你要预热的镜像来自私有仓库，则可以通过 <code>pullSecrets</code> 来指定仓库的 Secret 信息。</p>
<h2 id="容器启动顺序"><a href="#容器启动顺序" class="headerlink" title="容器启动顺序"></a>容器启动顺序</h2><p><code>Container Launch Priority</code> 提供了控制一个 Pod 中容器启动顺序的方法。通常来说 Pod 容器的启动和退出顺序是由 Kubelet 管理的，Kubernetes 曾经有一个 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/753-sidecar-containers">KEP</a> 计划在 container 中增加一个 type 字段来标识不同类型容器的启停优先级，但是由于<a target="_blank" rel="noopener" href="https://github.com/kubernetes/enhancements/issues/753#issuecomment-713471597">sig-node 考虑到对现有代码架构的改动太大</a>，所以将该提案拒绝了。</p>
<blockquote>
<p>这个功能作用在 Pod 对象上，不管它的 owner 是什么类型的，因此可以适用于 Deployment、CloneSet 以及其他的 workload 种类。</p>
</blockquote>
<p>比如我们可以设置按照容器顺序启动，只需要在 Pod 中定义一个 <code>apps.kruise.io/container-launch-priority</code> 的注解即可：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">apps.kruise.io/container-launch-priority:</span> <span class="string">Ordered</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sidecar</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main</span></span><br><span class="line">    <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>



<p>Kruise 会保证前面的容器（sidecar）会在后面容器（main）之前启动。</p>
<p>此外我们还可以按自定义顺序启动，但是需要在 Pod 容器中添加 <code>KRUISE_CONTAINER_PRIORITY</code> 这个环境变量:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">main</span></span><br><span class="line">      <span class="comment"># ...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">sidecar</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">KRUISE_CONTAINER_PRIORITY</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">      <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>



<p>该环境变量值的范围在 <code>[-2147483647, 2147483647]</code>，不写默认是 0，权重高的容器，会保证在权重低的容器之前启动，但是需要注意相同权重的容器不保证启动顺序。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/Pod%20%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/Pod%20%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">Pod 基本原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:28" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">基础知识</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Pod-基本原理"><a href="#Pod-基本原理" class="headerlink" title="Pod 基本原理"></a>Pod 基本原理</h1><p><img data-src="https://mudutestmenu.mudu.tv/upload/bzibzw.jpg" alt="pod demo"></p>
<p>前面的课程中我们了解了 Kubernetes 的基本架构，以及如何使用资源清单在集群中部署一个应用。我们也了解到了 Pod 是 Kubernetes 集群中最基本的调度单元，我们平时在集群中部署的应用都是以 Pod 为单位的，而并不是我们熟知的容器，这样设计的目的是什么呢？为何不直接使用容器呢？</p>
<h2 id="为什么需要-Pod"><a href="#为什么需要-Pod" class="headerlink" title="为什么需要 Pod"></a>为什么需要 Pod</h2><p>假设 Kubernetes 中调度的基本单元就是容器，对于一个非常简单的应用可以直接被调度直接使用，没有什么问题，但是往往还有很多应用程序是由多个进程组成的，有的同学可能会说把这些进程都打包到一个容器中去不就可以了吗？理论上是可以实现的，但是不要忘记了容器运行时管理的进程是 <code>pid=1</code> 的主进程，其他进程死掉了就会成为僵尸进程，没办法进行管理了，这种方式本身也不是容器推荐的运行方式，一个容器最好<code>只干一件事情</code>，所以在真实的环境中不会使用这种方式。</p>
<p>那么我们就把这个应用的进程进行拆分，拆分成一个一个的容器总可以了吧？但是不要忘记一个问题，拆分成一个一个的容器后，是不是就有可能出现一个应用下面的某个进程容器被调度到了不同的节点上呀？往往我们应用内部的进程与进程间通信（通过 IPC 或者共享本地文件之类）都是要求在本地进行的，也就是需要在同一个节点上运行。</p>
<p>所以我们需要一个更高级别的结构来将这些容器绑定在一起，并将他们作为一个基本的调度单元进行管理，这样就可以保证这些容器始终在同一个节点上面，这也就是 Pod 设计的初衷。</p>
<h2 id="Pod-原理"><a href="#Pod-原理" class="headerlink" title="Pod 原理"></a>Pod 原理</h2><p>在一个 Pod 下面运行几个关系非常密切的容器进程，这样一来这些进程本身又可以收到容器的管控，又具有几乎一致的运行环境，也就完美解决了上面提到的问题。</p>
<p>其实 Pod 也只是一个逻辑概念，真正起作用的还是 Linux 容器的 Namespace 和 Cgroup 这两个最基本的概念，Pod 被创建出来其实是一组共享了一些资源的容器而已。首先 Pod 里面的所有容器，都是共享的同一个 Network Namespace，但是涉及到文件系统的时候，默认情况下 Pod 里面的容器之间的文件系统是完全隔离的，但是我们可以通过声明来共享同一个 Volume。</p>
<p>我们可以指定新创建的容器和一个已经存在的容器共享一个 Network Namespace，在运行容器（docker 容器）的时候只需要指定 <code>--net=container:目标容器名</code> 这个参数就可以了，但是这种模式有一个明显的问题那就是容器的启动有先后顺序问题，那么 Pod 是怎么来处理这个问题的呢？那就是加入一个中间容器（没有什么架构是加一个中间件解决不了的？），这个容器叫做 Infra 容器，而且这个容器在 Pod 中永远都是第一个被创建的容器，这样是不是其他容器都加入到这个 Infra 容器就可以了，这样就完全实现了 Pod 中的所有容器都和 Infra 容器共享同一个 Network Namespace 了，如下图所示：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/camtql.jpg" alt="pod infra container"></p>
<p>所以当我们部署完成 Kubernetes 集群的时候，首先需要保证在所有节点上可以拉取到默认的 Infra 镜像，默认情况下 Infra 镜像地址为 <code>k8s.gcr.io/pause:3.5</code>，这个容器占用的资源非常少，但是这个镜像默认是需要科学上网的，所以很多时候我们在部署应用的时候一直处于 <code>Pending</code> 状态或者报 <code>sandbox image</code> 相关的错误信息，大部分是因为所有 Pod 最先启动的容器镜像都拉不下来，肯定启动不了，启动不了其他容器肯定也就不能启动了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubelet --<span class="built_in">help</span> |grep infra</span></span><br><span class="line">      --pod-infra-container-image string                                                                          The image whose network/ipc namespaces containers in each pod will use. This docker-specific flag only works when container-runtime is set to docker. (default &quot;k8s.gcr.io/pause:3.5&quot;)</span><br></pre></td></tr></table></figure>



<p>从上面图中我们可以看出普通的容器加入到了 Infra 容器的 Network Namespace 中，所以这个 Pod 下面的所有容器就是共享同一个 Network Namespace 了，普通容器不会创建自己的网卡，配置自己的 IP，而是和 Infra 容器共享 IP、端口范围等，而且容器之间的进程可以通过 lo 网卡设备进行通信：</p>
<ul>
<li>也就是容器之间是可以直接使用 <code>localhost</code> 进行通信的；</li>
<li>看到的网络设备信息都是和 Infra 容器完全一样的；</li>
<li>也就意味着同一个 Pod 下面的容器运行的多个进程不能绑定相同的端口；</li>
<li>而且 Pod 的生命周期只跟 Infra 容器一致，而与容器 A 和 B 无关。</li>
</ul>
<p>对于文件系统 Kubernetes 是怎么实现让一个 Pod 中的容器共享的呢？默认情况下容器的文件系统是互相隔离的，要实现共享只需要在 Pod 的顶层声明一个 Volume，然后在需要共享这个 Volume 的容器中声明挂载即可。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/6gbmeg.jpg" alt="pod containers share volumes"></p>
<p>比如下面的示例：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">counter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/var/log/counter</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">count</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">          i=0;</span></span><br><span class="line"><span class="string">          while true;</span></span><br><span class="line"><span class="string">          do</span></span><br><span class="line"><span class="string">            echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log;</span></span><br><span class="line"><span class="string">            i=$((i+1));</span></span><br><span class="line"><span class="string">            sleep 1;</span></span><br><span class="line"><span class="string">          done</span></span><br><span class="line"><span class="string"></span>      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">count-log</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">args:</span> [<span class="string">/bin/sh</span>, <span class="string">-c</span>, <span class="string">&#x27;tail -n+1 -f /opt/log/1.log&#x27;</span>]</span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/opt/log</span></span><br></pre></td></tr></table></figure>



<p>示例中我们在 Pod 的顶层声明了一个名为 varlog 的 <code>Volume</code>，而这个 <code>Volume</code> 的类型是 <code>hostPath</code>，也就意味这个宿主机的 <code>/var/log/counter</code> 目录将被这个 Pod 共享，共享给谁呢？在需要用到这个数据目录的容器上声明挂载即可，也就是通过 <code>volumeMounts</code> 声明挂载的部分，这样我们这个 Pod 就实现了共享容器的 <code>/var/log</code> 目录，而且数据被持久化到了宿主机目录上。</p>
<p>这个方式也是 Kubernetes 中一个非常重要的设计模式：<code>sidecar 模式</code>的常用方式。典型的场景就是容器日志收集，比如上面我们的这个应用，其中应用的日志是被输出到容器的 &#x2F;var&#x2F;log 目录上的，这个时候我们可以把 Pod 声明的 Volume 挂载到容器的 &#x2F;var&#x2F;log 目录上，然后在这个 Pod 里面同时运行一个 sidecar 容器，他也声明挂载相同的 Volume 到自己容器的 &#x2F;var&#x2F;log （或其他）目录上，这样我们这个 sidecar 容器就只需要从 &#x2F;var&#x2F;log 目录下面不断消费日志发送到 Elasticsearch 中存储起来就完成了最基本的应用日志的基本收集工作了。</p>
<p>除了这个应用场景之外使用更多的还是利用 Pod 中的所有容器共享同一个 Network Namespace 这个特性，这样我们就可以把 Pod 网络相关的配置和管理也可以交给一个 sidecar 容器来完成，完全不需要去干涉用户容器，这个特性在现在非常火热的 Service Mesh（服务网格）中应用非常广泛，典型的应用就是 <a target="_blank" rel="noopener" href="https://istio.io/">Istio</a>，不过也不用着急，后面也会和大家一起探讨的。</p>
<h2 id="如何划分-Pod"><a href="#如何划分-Pod" class="headerlink" title="如何划分 Pod"></a>如何划分 Pod</h2><p>上面我们介绍了 Pod 的实现原理，了解到了应该把关系紧密的容器划分到同一个 Pod 中运行，那么怎么来区分“关系紧密”呢？举一个简单的示例，比如我们的 Wordpress 应用，是一个典型的前端服务器和后端数据服务的应用，那么你认为应该使用一个 Pod 还是两个 Pod 呢？</p>
<p>如果在同一个 Pod 中同时运行服务器程序和后端的数据库服务这两个容器，理论上肯定是可行的，但是不推荐这样使用，我们知道一个 Pod 中的所有容器都是同一个整体进行调度的，但是对于我们这个应用 Wordpress 和 MySQL 数据库一定需要运行在一起吗？当然不需要，我们甚至可以将 MySQL 部署到集群之外对吧？所以 Wordpress 和 MySQL 即使不运行在同一个节点上也是可行的，只要能够访问到即可。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/uwjut1.jpg" alt="pod wordpress demo1"></p>
<p>但是如果你非要强行部署到同一个 Pod 中呢？从某个角度来说是错误的，比如现在我们的应用访问量非常大，一个 Pod 已经满足不了我们的需求了，怎么办呢？扩容对吧，但是扩容的目标也是 Pod，并不是容器，比如我们再添加一个 Pod，这个时候我们就有两个 Wordpress 的应用和两个 MySQL 数据库了，而且这两个 Pod 之间的数据是互相独立的，因为 MySQL 数据库并不是简单的增加副本就可以共享数据了，所以这个时候就得分开部署了，采用第二种方案，这个时候我们只需要单独扩容 Wordpress 的这个 Pod，后端的 MySQL 数据库并不会受到扩容的影响。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/91cebr.jpg" alt="pod wordpress demo2"></p>
<p>将多个容器部署到同一个 Pod 中的最主要参考就是应用可能由一个主进程和一个或多个的辅助进程组成，比如上面我们的日志收集的 Pod，需要其他的 sidecar 容器来支持日志的采集。所以当我们判断是否需要在 Pod 中使用多个容器的时候，我们可以按照如下的几个方式来判断：</p>
<ul>
<li>这些容器是否一定需要一起运行，是否可以运行在不同的节点上</li>
<li>这些容器是一个整体还是独立的组件</li>
<li>这些容器一起进行扩缩容会影响应用吗</li>
</ul>
<p>基本上我们能够回答上面的几个问题就能够判断是否需要在 Pod 中运行多个容器了。</p>
<p>Pod 的设计</p>
<p>其实在我们理解 Pod 的时候，有一个比较好的类比的方式就是把 Pod 看成我们之前的<strong>“虚拟机”</strong>，而容器就是虚拟机中运行的一个用户程序，这样就可以很好的来理解 Pod 的设计。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/Pod%20%E6%8B%93%E6%89%91%E5%88%86%E5%B8%83%E7%BA%A6%E6%9D%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/Pod%20%E6%8B%93%E6%89%91%E5%88%86%E5%B8%83%E7%BA%A6%E6%9D%9F/" class="post-title-link" itemprop="url">Pod 拓扑分布约束</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:49" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E8%B0%83%E5%BA%A6%E5%99%A8/" itemprop="url" rel="index"><span itemprop="name">调度器</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Pod-拓扑分布约束"><a href="#Pod-拓扑分布约束" class="headerlink" title="Pod 拓扑分布约束"></a>Pod 拓扑分布约束</h1><p>在 k8s 集群调度中，<strong>亲和性</strong>相关的概念本质上都是控制 Pod 如何被调度 – <strong>堆叠或打散</strong>。<code>podAffinity</code> 以及 <code>podAntiAffinity</code> 两个特性对 Pod 在不同拓扑域的分布进行了一些控制，<code>podAffinity</code> 可以将无数个 Pod 调度到特定的某一个拓扑域，这是<strong>堆叠</strong>的体现；<code>podAntiAffinity</code> 则可以控制一个拓扑域只存在一个 Pod，这是<strong>打散</strong>的体现。但这两种情况都太极端了，在不少场景下都无法达到理想的效果，例如为了实现容灾和高可用，将业务 Pod 尽可能均匀的分布在不同可用区就很难实现。</p>
<p><code>PodTopologySpread（Pod 拓扑分布约束）</code> 特性的提出正是为了对 Pod 的调度分布提供更精细的控制，以提高服务可用性以及资源利用率，<code>PodTopologySpread</code> 由 <code>EvenPodsSpread</code> 特性门所控制，在 v1.16 版本第一次发布，并在 v1.18 版本进入 beta 阶段默认启用。</p>
<h2 id="使用规范"><a href="#使用规范" class="headerlink" title="使用规范"></a>使用规范</h2><p>在 Pod 的 Spec 规范中新增了一个 <code>topologySpreadConstraints</code> 字段即可配置拓扑分布约束，如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">topologySpreadConstraints:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">maxSkew:</span> <span class="string">&lt;integer&gt;</span></span><br><span class="line">      <span class="attr">topologyKey:</span> <span class="string">&lt;string&gt;</span></span><br><span class="line">      <span class="attr">whenUnsatisfiable:</span> <span class="string">&lt;string&gt;</span></span><br><span class="line">      <span class="attr">labelSelector:</span> <span class="string">&lt;object&gt;</span></span><br></pre></td></tr></table></figure>



<p>由于这个新增的字段是在 Pod spec 层面添加，因此更高层级的控制 (Deployment、DaemonSet、StatefulSet) 也能使用 <code>PodTopologySpread</code> 功能。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/39urvj.png" alt="Pod拓扑分布约束"></p>
<p>让我们结合上图来理解 <code>topologySpreadConstraints</code> 中各个字段的含义和作用：</p>
<ul>
<li><p><code>labelSelector</code>: 用来查找匹配的 Pod，我们能够计算出每个拓扑域中匹配该 label selector 的 Pod 数量，在上图中，假如 label selector 是 <code>app:foo</code>，那么 zone1 的匹配个数为 2， zone2 的匹配个数为 0。</p>
</li>
<li><p><code>topologyKey</code>: 是 Node label 的 key，如果两个 Node 的 label 同时具有该 key 并且值相同，就说它们在同一个拓扑域。在上图中，指定 <code>topologyKey</code> 为 zone， 则具有 <code>zone=zone1</code> 标签的 Node 被分在一个拓扑域，具有 <code>zone=zone2</code> 标签的 Node 被分在另一个拓扑域。</p>
</li>
<li><pre><code>maxSkew
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">:这个属性理解起来不是很直接，它描述了 Pod在不同拓扑域中不均匀分布的最大程度（指定拓扑类型中任意两个拓扑域中匹配的 Pod 之间的最大允许差值），它必须大于零。每个拓扑域都有一个 skew 值，计算的公式是:</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
skew[i] = 拓扑域[i]中匹配的 Pod 个数 - min&#123;其他拓扑域中匹配的 Pod 个数&#125;
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">。在上图中，我们新建一个带有</span><br><span class="line"></span><br></pre></td></tr></table></figure>
app=foo
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  标签的 Pod：</span><br><span class="line"></span><br><span class="line">  - 如果该 Pod 被调度到 zone1，那么 zone1 中 <span class="keyword">Node</span> <span class="title">的 skew</span> 值变为 <span class="number">3</span>，zone2 中 <span class="keyword">Node</span> <span class="title">的 skew</span> 值变为 <span class="number">0</span> (zone1 有 <span class="number">3</span> 个匹配的 Pod，zone2 有 <span class="number">0</span> 个匹配的 Pod )</span><br><span class="line">  - 如果该 Pod 被调度到 zone2，那么 zone1 中 <span class="keyword">Node</span> <span class="title">的 skew</span> 值变为 <span class="number">2</span>，zone2 中 <span class="keyword">Node</span> <span class="title">的 skew</span> 值变为 <span class="number">1</span>(zone2 有 <span class="number">1</span> 个匹配的 Pod，拥有全局最小匹配 Pod 数的拓扑域正是 zone2 自己 )，则它满足`maxSkew: <span class="number">1</span>` 的约束（差值为 <span class="number">1</span>）</span><br><span class="line"></span><br><span class="line">- ```</span><br><span class="line">  whenUnsatisfiable</span><br></pre></td></tr></table></figure>

: 描述了如果 Pod 不满足分布约束条件该采取何种策略：

- **DoNotSchedule** (默认) 告诉调度器不要调度该 Pod，因此也可以叫作硬策略；
- **ScheduleAnyway** 告诉调度器根据每个 Node 的 skew 值打分排序后仍然调度，因此也可以叫作软策略。
</code></pre>
</li>
</ul>
<h2 id="单个拓扑约束"><a href="#单个拓扑约束" class="headerlink" title="单个拓扑约束"></a>单个拓扑约束</h2><p>假设你拥有一个 4 节点集群，其中标记为  <code>foo:bar</code> 的 3 个 Pod 分别位于 node1、node2 和 node3 中：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/l6cnjy.png" alt="单个 TopologySpreadConstraint"></p>
<p>如果希望新来的 Pod 均匀分布在现有的可用区域，则可以按如下设置其约束：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mypod</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">foo:</span> <span class="string">bar</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">topologySpreadConstraints:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">maxSkew:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">topologyKey:</span> <span class="string">zone</span></span><br><span class="line">      <span class="attr">whenUnsatisfiable:</span> <span class="string">DoNotSchedule</span></span><br><span class="line">      <span class="attr">labelSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">foo:</span> <span class="string">bar</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pause</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">k8s.gcr.io/pause:3.1</span></span><br></pre></td></tr></table></figure>



<p><code>topologyKey: zone</code> 意味着均匀分布将只应用于存在标签键值对为 <code>zone:&lt;any value&gt;</code> 的节点。 <code>whenUnsatisfiable: DoNotSchedule</code> 告诉调度器如果新的 Pod 不满足约束，则不可调度。如果调度器将新的 Pod 放入 “zoneA”，Pods 分布将变为 <code>[3, 1]</code>，因此实际的偏差为 <code>2(3 - 1)</code>，这违反了  <code>maxSkew: 1</code> 的约定。此示例中，新 Pod 只能放置在 “zoneB” 上：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/h8snpn.png" alt="zoneB"></p>
<p>或者</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/2j2o65.png" alt="zoneB"></p>
<p>你可以调整 Pod 约束以满足各种要求：</p>
<ul>
<li>将  <code>maxSkew</code> 更改为更大的值，比如 “2”，这样新的 Pod 也可以放在 “zoneA” 上。</li>
<li>将  <code>topologyKey</code> 更改为 “node”，以便将 Pod 均匀分布在节点上而不是区域中。 在上面的例子中，如果  <code>maxSkew</code> 保持为 “1”，那么传入的 Pod 只能放在 “node4” 上。</li>
<li>将  <code>whenUnsatisfiable: DoNotSchedule</code> 更改为  <code>whenUnsatisfiable: ScheduleAnyway</code>， 以确保新的 Pod 可以被调度。</li>
</ul>
<h2 id="多个拓扑约束"><a href="#多个拓扑约束" class="headerlink" title="多个拓扑约束"></a>多个拓扑约束</h2><p>上面是单个 Pod 拓扑分布约束的情况，下面的例子建立在前面例子的基础上来对多个 Pod 拓扑分布约束进行说明。假设你拥有一个 4 节点集群，其中 3 个标记为  <code>foo:bar</code> 的 Pod 分别位于 node1、node2 和 node3 上：</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/7sxwhl.png" alt="多个 TopologySpreadConstraint"></p>
<p>我们可以使用 2 个 <code>TopologySpreadConstraint</code> 来控制 Pod 在区域和节点两个维度上的分布：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># two-constraints.yaml</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mypod</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">foo:</span> <span class="string">bar</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">topologySpreadConstraints:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">maxSkew:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">topologyKey:</span> <span class="string">zone</span></span><br><span class="line">      <span class="attr">whenUnsatisfiable:</span> <span class="string">DoNotSchedule</span></span><br><span class="line">      <span class="attr">labelSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">foo:</span> <span class="string">bar</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">maxSkew:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">topologyKey:</span> <span class="string">node</span></span><br><span class="line">      <span class="attr">whenUnsatisfiable:</span> <span class="string">DoNotSchedule</span></span><br><span class="line">      <span class="attr">labelSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">foo:</span> <span class="string">bar</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pause</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">k8s.gcr.io/pause:3.1</span></span><br></pre></td></tr></table></figure>



<p>在这种情况下，为了匹配第一个约束，新的 Pod 只能放置在 “zoneB” 中；而在第二个约束中， 新的 Pod 只能放置在 “node4” 上，最后两个约束的结果加在一起，唯一可行的选择是放置 在 “node4” 上。</p>
<p>多个约束之间是可能存在冲突的，假设有一个跨越 2 个区域的 3 节点集群：</p>
<p><img data-src="https://picdn.youdianzhishi.com/images/20210325154257.png" alt="冲突"></p>
<p>如果对集群应用 <code>two-constraints.yaml</code>，会发现 “mypod” 处于  <code>Pending</code> 状态，这是因为为了满足第一个约束，”mypod” 只能放在 “zoneB” 中，而第二个约束要求 “mypod” 只能放在 “node2” 上，Pod 调度无法满足这两种约束，所以就冲突了。</p>
<p>为了克服这种情况，你可以增加  <code>maxSkew</code> 或修改其中一个约束，让其使用  <code>whenUnsatisfiable: ScheduleAnyway</code>。</p>
<h2 id="与-NodeSelector-NodeAffinity-一起使用"><a href="#与-NodeSelector-NodeAffinity-一起使用" class="headerlink" title="与 NodeSelector&#x2F;NodeAffinity 一起使用"></a>与 NodeSelector&#x2F;NodeAffinity 一起使用</h2><p>仔细观察可能你会发现我们并没有类似于 <code>topologyValues</code> 的字段来限制 Pod 将被调度到哪些拓扑去，默认情况会搜索所有节点并按 <code>topologyKey</code> 对其进行分组。有时这可能不是理想的情况，比如假设有一个集群，其节点标记为 <code>env=prod</code>、<code>env=staging</code>和 <code>env=qa</code>，现在你想跨区域将 Pod 均匀地放置到 <code>qa</code> 环境中，是否可行?</p>
<p>答案是肯定的，我们可以结合 <code>NodeSelector</code> 或 <code>NodeAffinity</code> 一起使用，<code>PodTopologySpread</code> 会计算满足选择器的节点之间的传播约束。</p>
<p><img data-src="https://mudutestmenu.mudu.tv/upload/f0qage.png" alt="高级用法-1"></p>
<p>如上图所示我们可以通过指定 <code>spec.affinity.nodeAffinity</code> 将<strong>搜索范围</strong>限制为 <code>qa</code> 环境，在该范围内 Pod 将被调度到一个满足 <code>topologySpreadConstraints</code> 的区域，这里就只能被调度到 <code>zone=zone2</code> 的节点上去了。</p>
<h2 id="集群默认约束"><a href="#集群默认约束" class="headerlink" title="集群默认约束"></a>集群默认约束</h2><p>除了为单个 Pod 设置拓扑分布约束，也可以为集群设置默认的拓扑分布约束，默认拓扑分布约束在且仅在以下条件满足 时才会应用到 Pod 上：</p>
<ul>
<li>Pod 没有在其  <code>.spec.topologySpreadConstraints</code> 设置任何约束；</li>
<li>Pod 隶属于某个服务、副本控制器、ReplicaSet 或 StatefulSet。</li>
</ul>
<p>你可以在  <a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/reference/scheduling/config/#profiles">调度方案（Schedulingg Profile）</a>中将默认约束作为  <code>PodTopologySpread</code> 插件参数的一部分来进行设置。 约束的设置采用和前面 Pod 中的规范一致，只是  <code>labelSelector</code> 必须为空。配置的示例可能看起来像下面这个样子：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeSchedulerConfiguration</span></span><br><span class="line"></span><br><span class="line"><span class="attr">profiles:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pluginConfig:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodTopologySpread</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">          <span class="attr">defaultConstraints:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">maxSkew:</span> <span class="number">1</span></span><br><span class="line">              <span class="attr">topologyKey:</span> <span class="string">topology.kubernetes.io/zone</span></span><br><span class="line">              <span class="attr">whenUnsatisfiable:</span> <span class="string">ScheduleAnyway</span></span><br><span class="line">          <span class="attr">defaultingType:</span> <span class="string">List</span></span><br></pre></td></tr></table></figure>



<h2 id="课后习题"><a href="#课后习题" class="headerlink" title="课后习题"></a>课后习题</h2><p>现在我们再去解决上节课留下的一个问题 - <strong>如果想在每个节点（或指定的一些节点）上运行 2 个（或多个）Pod 副本，如何实现？</strong></p>
<p>这里以我们的集群为例，加上 master 节点一共有 3 个节点，每个节点运行 2 个副本，总共就需要 6 个 Pod 副本，要在 master 节点上运行，则同样需要添加容忍，如果只想在一个节点上运行 2 个副本，则可以使用我们的拓扑分布约束来进行细粒度控制，对应的资源清单如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">topo-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">6</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">topo</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">topo</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&#x27;node-role.kubernetes.io/master&#x27;</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">&#x27;Exists&#x27;</span></span><br><span class="line">          <span class="attr">effect:</span> <span class="string">&#x27;NoSchedule&#x27;</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">ngpt</span></span><br><span class="line">      <span class="attr">topologySpreadConstraints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">maxSkew:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">whenUnsatisfiable:</span> <span class="string">DoNotSchedule</span></span><br><span class="line">          <span class="attr">labelSelector:</span></span><br><span class="line">            <span class="attr">matchLabels:</span></span><br><span class="line">              <span class="attr">app:</span> <span class="string">topo</span></span><br></pre></td></tr></table></figure>



<p>这里我们重点需要关注的就是 <code>topologySpreadConstraints</code> 部分的配置，我们选择使用 <code>kubernetes.io/hostname</code> 为拓扑域，相当于就是 3 个节点都是独立的，<code>maxSkew: 1</code> 表示最大的分布不均匀度为 1，所以只能出现的调度结果就是每个节点运行 2 个 Pod。</p>
<p><img data-src="https://picdn.youdianzhishi.com/images/20220119162204.png" alt="解析"></p>
<p>直接创建上面的资源即可验证：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get nodes</span><br><span class="line">NAME      STATUS   ROLES                  AGE   VERSION</span><br><span class="line">master1   Ready    control-plane,master   85d   v1.22.2</span><br><span class="line">node1     Ready    &lt;none&gt;                 85d   v1.22.2</span><br><span class="line">node2     Ready    &lt;none&gt;                 85d   v1.22.2</span><br><span class="line">➜ kubectl get pods -l app=topo -o wide</span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span><br><span class="line">topo-demo-6bbf65d967-7969w   1/1     Running   0          7m16s   10.244.2.40    node2     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">topo-demo-6bbf65d967-8vhb8   1/1     Running   0          7m16s   10.244.2.41    node2     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">topo-demo-6bbf65d967-cvg7j   1/1     Running   0          7m16s   10.244.1.211   node1     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">topo-demo-6bbf65d967-hzhv2   1/1     Running   0          7m16s   10.244.0.143   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">topo-demo-6bbf65d967-nvg4z   1/1     Running   0          7m16s   10.244.0.144   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">topo-demo-6bbf65d967-w7w29   1/1     Running   0          7m16s   10.244.1.212   node1     &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>可以看到符合我们的预期，每个节点上运行了 2 个 Pod 副本，如果是要求每个节点上运行 3 个 Pod 副本呢？大家也可以尝试去练习下。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/Pod%20%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/Pod%20%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6/" class="post-title-link" itemprop="url">Pod 使用进阶</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:40" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">基础知识</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Pod-使用进阶-深入理解-Pod-对象"><a href="#Pod-使用进阶-深入理解-Pod-对象" class="headerlink" title="Pod 使用进阶-深入理解 Pod 对象"></a>Pod 使用进阶-深入理解 Pod 对象</h1><h2 id="Pod-资源配置"><a href="#Pod-资源配置" class="headerlink" title="Pod 资源配置"></a>Pod 资源配置</h2><p>实际上上面几个步骤就是影响一个 Pod 生命周期的大的部分，但是还有一些细节也会在 Pod 的启动过程进行设置，比如在容器启动之前还会为当前的容器设置分配的 CPU、内存等资源，我们知道我们可以通过 CGroup 来对容器的资源进行限制，同样的，在 Pod 中我们也可以直接配置某个容器的使用的 CPU 或者内存的上限。那么 Pod 是如何来使用和控制这些资源的分配的呢？</p>
<p>首先对于 CPU，我们知道计算机里 CPU 的资源是按<code>“时间片”</code>的方式来进行分配的，系统里的每一个操作都需要 CPU 的处理，所以，哪个任务要是申请的 CPU 时间片越多，那么它得到的 CPU 资源就越多，这个很容器理解。</p>
<p>然后还需要了解下 CGroup 里面对于 CPU 资源的单位换算：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 CPU =  1000 millicpu（1 Core = 1000m）</span><br><span class="line">0.5 CPU = 500 millicpu （0.5 Core = 500m）</span><br></pre></td></tr></table></figure>

<p>这里的 <code>m</code> 就是毫、毫核的意思，Kubernetes 集群中的每一个节点可以通过操作系统的命令来确认本节点的 CPU 内核数量，然后将这个数量乘以1000，得到的就是节点总 CPU 总毫数。比如一个节点有四核，那么该节点的 CPU 总毫量为 4000m，如果你要使用0.5 core，则你要求的是 4000*0.5 &#x3D; 2000m。在 Pod 里面我们可以通过下面的两个参数来限制和请求 CPU 资源：</p>
<ul>
<li><code>spec.containers[].resources.limits.cpu</code>：CPU 上限值，可以短暂超过，容器也不会被停止</li>
<li><code>spec.containers[].resources.requests.cpu</code>：CPU请求值，Kubernetes 调度算法里的依据值，可以超过</li>
</ul>
<p>这里需要明白的是，如果 <code>resources.requests.cpu</code> 设置的值大于集群里每个节点的最大 CPU 核心数，那么这个 Pod 将无法调度，因为没有节点能满足它。</p>
<p>到这里应该明白了，<code>requests</code> 是用于集群调度使用的资源，而 <code>limits</code> 才是真正的用于资源限制的配置，如果你需要保证的你应用优先级很高，也就是资源吃紧的情况下最后再杀掉你的 Pod，那么你就把你的 requests 和 limits 的值设置成一致，在后面应用的 <code>Qos</code> 中会具体讲解。</p>
<p>比如，现在我们定义一个 Pod，给容器的配置如下的资源:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pod-resource-demo1.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">resource-demo1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">resource-demo1</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">50Mi</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">50m</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">100Mi</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">100m</span></span><br></pre></td></tr></table></figure>

<p>这里，CPU 我们给的是 50m，也就是 <code>0.05core</code>，这 <code>0.05core</code> 也就是占了 1 CPU 里的 5% 的资源时间。而限制资源是给的是 100m，但是需要注意的是 CPU 资源是可压缩资源，也就是容器达到了这个设定的上限后，容器性能会下降，但是不会终止或退出。比如我们直接创建上面这个 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f pod-resource-demo1.yaml</span><br></pre></td></tr></table></figure>

<p>创建完成后，我们可以看到 Pod 被调度到 node1 这个节点上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl get pods -o wide</span><br><span class="line">NAME             READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">resource-demo1   1/1     Running   0          24s   10.244.1.27   node1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>然后我们到 node1 节点上去查看 Pod 里面启动的 <code>resource-demo1</code> 这个容器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ crictl ps</span><br><span class="line">CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID</span><br><span class="line">1e4ef680a5a88       87a94228f133e       41 seconds ago      Running             resource-demo1      0                   a00af47f2a12e</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>我们可以去查看下主容器的信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ crictl inspect 1e4ef680a5a88</span><br><span class="line">&#123;</span><br><span class="line">  &quot;status&quot;: &#123;</span><br><span class="line">    &quot;id&quot;: &quot;1e4ef680a5a88af7eae88a6901f12eb103dc3f8e1807f26337cd9bfb3704ca05&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">      &quot;attempt&quot;: 0,</span><br><span class="line">      &quot;name&quot;: &quot;resource-demo1&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">......</span><br><span class="line">      &quot;linux&quot;: &#123;</span><br><span class="line">        &quot;resources&quot;: &#123;</span><br><span class="line">          &quot;devices&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">              &quot;allow&quot;: false,</span><br><span class="line">              &quot;access&quot;: &quot;rwm&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          &quot;memory&quot;: &#123;</span><br><span class="line">            &quot;limit&quot;: 104857600</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;cpu&quot;: &#123;</span><br><span class="line">            &quot;shares&quot;: 51,</span><br><span class="line">            &quot;quota&quot;: 10000,</span><br><span class="line">            &quot;period&quot;: 100000</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;cgroupsPath&quot;: &quot;kubepods-burstable-poda194c43a_9551_494b_bd72_ab898afdcc0c.slice:cri-containerd:1e4ef680a5a88af7eae88a6901f12eb103dc3f8e1807f26337cd9bfb3704ca05&quot;,</span><br><span class="line">     ......</span><br></pre></td></tr></table></figure>

<p>实际上我们就可以看到这个容器的一些资源情况，Pod 上的资源配置最终也还是通过底层的容器运行时去控制 CGroup 来实现的，我们可以进入如下目录查看 CGroup 的配置，该目录就是 CGroup 父级目录，而 CGroup 是通过文件系统来进行资源限制的，所以我们上面限制容器的资源就可以在该目录下面反映出来：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ cd /sys/fs/cgroup/cpu/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-poda194c43a_9551_494b_bd72_ab898afdcc0c.slice</span><br><span class="line">➜  ~ ls</span><br><span class="line">cgroup.clone_children  cpuacct.stat          cpu.cfs_period_us  cpu.rt_runtime_us  notify_on_release</span><br><span class="line">cgroup.event_control   cpuacct.usage         cpu.cfs_quota_us   cpu.shares         tasks</span><br><span class="line">cgroup.procs           cpuacct.usage_percpu  cpu.rt_period_us   cpu.stat</span><br><span class="line">➜  ~ cat cpu.cfs_quota_us</span><br><span class="line">10000</span><br></pre></td></tr></table></figure>

<p>其中 <code>cpu.cfs_quota_us</code> 就是 CPU 的限制值，如果要查看具体的容器的资源，我们也可以进入到容器目录下面去查看即可。</p>
<p>最后我们了解下内存这块的资源控制，内存的单位换算比较简单：</p>
<p><code>1 MiB = 1024 KiB</code>，内存这块在 Kubernetes 里一般用的是<code>Mi</code>单位，当然你也可以使用<code>Ki、Gi</code>甚至<code>Pi</code>，看具体的业务需求和资源容量。</p>
<p>单位换算</p>
<p>这里注意的是<code>MiB ≠ MB</code>，MB 是十进制单位，MiB 是二进制，平时我们以为 MB 等于 1024KB，其实<code>1MB=1000KB</code>，<code>1MiB</code>才等于<code>1024KiB</code>。中间带字母 i 的是国际电工协会（IEC）定的，走1024乘积；KB、MB、GB 是国际单位制，走1000乘积。</p>
<p>这里要注意的是，内存是不可压缩性资源，如果容器使用内存资源到达了上限，那么会<code>OOM</code>，造成内存溢出，容器就会终止和退出。我们也可以通过上面的方式去通过查看 CGroup 文件的值来验证资源限制。</p>
<h2 id="静态-Pod"><a href="#静态-Pod" class="headerlink" title="静态 Pod"></a>静态 Pod</h2><p>在 Kubernetes 集群中除了我们经常使用到的普通的 Pod 外，还有一种特殊的 Pod，叫做Static Pod，也就是我们说的静态 Pod，静态 Pod 有什么特殊的地方呢？</p>
<p>静态 Pod 直接由节点上的 kubelet 进程来管理，不通过 master 节点上的 apiserver。无法与我们常用的控制器 Deployment 或者 DaemonSet 进行关联，它由 kubelet 进程自己来监控，当 pod 崩溃时会重启该 pod，kubelet 也无法对他们进行健康检查。静态 pod 始终绑定在某一个 kubelet 上，并且始终运行在同一个节点上。kubelet 会自动为每一个静态 pod 在 Kubernetes 的 apiserver 上创建一个镜像 Pod，因此我们可以在 apiserver 中查询到该 pod，但是不能通过 apiserver 进行控制（例如不能删除）。</p>
<p>创建静态 Pod 有两种方式：<code>配置文件</code>和 <code>HTTP</code> 两种方式</p>
<p><strong>配置文件</strong></p>
<p>配置文件就是放在特定目录下的标准的 JSON 或 YAML 格式的 pod 定义文件。用 <code>kubelet --pod-manifest-path=&lt;the directory&gt;</code>来启动 kubelet 进程，kubelet 定期的去扫描这个目录，根据这个目录下出现或消失的 YAML&#x2F;JSON 文件来创建或删除静态 pod。</p>
<p>比如我们在 node1 这个节点上用静态 pod 的方式来启动一个 nginx 的服务，配置文件路径为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ cat /var/lib/kubelet/config.yaml</span><br><span class="line">......</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests  # 和命令行的 pod-manifest-path 参数一致</span><br><span class="line">......</span><br></pre></td></tr></table></figure>



<p>打开这个文件我们可以看到其中有一个属性为 <code>staticPodPath</code> 的配置，其实和命令行的 <code>--pod-manifest-path</code> 配置是一致的，所以如果我们通过 kubeadm 的方式来安装的集群环境，对应的 kubelet 已经配置了我们的静态 Pod 文件的路径，默认地址为 <code>/etc/kubernetes/manifests</code>，所以我们只需要在该目录下面创建一个标准的 Pod 的 JSON 或者 YAML 文件即可，如果你的 kubelet 启动参数中没有配置上面的<code>--pod-manifest-path</code> 参数的话，那么添加上这个参数然后重启 kubelet 即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ cat &lt;&lt;EOF &gt;/etc/kubernetes/manifests/static-web.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: static-web</span><br><span class="line">  labels:</span><br><span class="line">    app: static</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: web</span><br><span class="line">      image: nginx</span><br><span class="line">      ports:</span><br><span class="line">        - name: web</span><br><span class="line">          containerPort: 80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p><strong>通过 HTTP 创建静态 Pods</strong></p>
<p>kubelet 周期地从 <code>–manifest-url=</code> 参数指定的地址下载文件，并且把它翻译成 JSON&#x2F;YAML 格式的 pod 定义。此后的操作方式与<code>–pod-manifest-path=</code> 相同，kubelet 会不时地重新下载该文件，当文件变化时对应地终止或启动静态 pod。</p>
<p>kubelet 启动时，由 <code>--pod-manifest-path=</code> 或 <code>--manifest-url=</code> 参数指定的目录下定义的所有 pod 都会自动创建，例如，我们示例中的 <code>static-web</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ nerdctl -n k8s.io ps</span><br><span class="line">CONTAINER ID    IMAGE                                              COMMAND                   CREATED           STATUS    PORTS    NAMES</span><br><span class="line">6add7aa53969    docker.io/library/nginx:latest                     &quot;/docker-entrypoint.…&quot;    43 seconds ago    Up</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>现在我们通过kubectl工具可以看到这里创建了一个新的镜像 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME               READY   STATUS    RESTARTS   AGE</span><br><span class="line">static-web-node1   1/1     Running   0          109s</span><br></pre></td></tr></table></figure>

<p>静态 pod 的标签会传递给镜像 Pod，可以用来过滤或筛选。 需要注意的是，我们不能通过 API 服务器来删除静态 pod（例如，通过kubectl命令），kubelet 不会删除它。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl delete pod static-web-node1</span><br><span class="line">pod &quot;static-web-node1&quot; deleted</span><br><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME               READY   STATUS    RESTARTS   AGE</span><br><span class="line">static-web-node1   1/1     Running   0          4s</span><br></pre></td></tr></table></figure>



<p><strong>静态 Pod 的动态增加和删除</strong></p>
<p>运行中的 kubelet 周期扫描配置的目录（我们这个例子中就是 <code>/etc/kubernetes/manifests</code>）下文件的变化，当这个目录中有文件出现或消失时创建或删除 pods：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ mv /etc/kubernetes/manifests/static-web.yaml /tmp</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">sleep</span> 20</span></span><br><span class="line">➜  ~ nerdctl -n k8s.io ps</span><br><span class="line">// no nginx container is running</span><br><span class="line">➜  ~ mv /tmp/static-web.yaml  /etc/kubernetes/manifests</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">sleep</span> 20</span></span><br><span class="line">➜  ~ nerdctl -n k8s.io ps</span><br><span class="line">CONTAINER ID    IMAGE                                              COMMAND                   CREATED           STATUS    PORTS    NAMES</span><br><span class="line">902be9190538    docker.io/library/nginx:latest                     &quot;/docker-entrypoint.…&quot;    14 seconds ago    Up</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>其实我们用 kubeadm 安装的集群，master 节点上面的几个重要组件都是用静态 Pod 的方式运行的，我们登录到 master 节点上查看<code>/etc/kubernetes/manifests</code>目录：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ ls /etc/kubernetes/manifests/</span><br><span class="line">etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml</span><br></pre></td></tr></table></figure>

<p>现在明白了吧，这种方式也为我们将集群的一些组件容器化提供了可能，因为这些 Pod 都不会受到 apiserver 的控制，不然我们这里kube-apiserver怎么自己去控制自己呢？万一不小心把这个 Pod 删掉了呢？所以只能有kubelet自己来进行控制，这就是我们所说的静态 Pod。</p>
<h2 id="Downward-API"><a href="#Downward-API" class="headerlink" title="Downward API"></a>Downward API</h2><p>前面我们从 Pod 的原理到生命周期介绍了 Pod 的一些使用，作为 Kubernetes 中最核心的资源对象、最基本的调度单元，我们可以发现 Pod 中的属性还是非常繁多的，前面我们使用过一个 <code>volumes</code> 的属性，表示声明一个数据卷，我们可以通过命令<code>kubectl explain pod.spec.volumes</code>去查看该对象下面的属性非常多，前面我们只是简单使用了 <code>hostPath</code> 和 <code>emptyDir&#123;&#125;</code> 这两种模式，其中还有一种模式叫做<code>downwardAPI</code>，这个模式和其他模式不一样的地方在于它不是为了存放容器的数据也不是用来进行容器和宿主机的数据交换的，而是让 Pod 里的容器能够直接获取到这个 Pod 对象本身的一些信息。</p>
<p>目前 <code>Downward API</code> 提供了两种方式用于将 Pod 的信息注入到容器内部：</p>
<ul>
<li>环境变量：用于单个变量，可以将 Pod 信息和容器信息直接注入容器内部</li>
<li>Volume 挂载：将 Pod 信息生成为文件，直接挂载到容器内部中去</li>
</ul>
<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>我们通过 <code>Downward API</code> 来将 Pod 的 IP、名称以及所对应的 namespace 注入到容器的环境变量中去，然后在容器中打印全部的环境变量来进行验证，对应资源清单文件如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># env-pod.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">env-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">env-pod</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;env&quot;</span>]</span><br><span class="line">    <span class="attr">env:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">      <span class="attr">valueFrom:</span></span><br><span class="line">        <span class="attr">fieldRef:</span></span><br><span class="line">          <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">      <span class="attr">valueFrom:</span></span><br><span class="line">        <span class="attr">fieldRef:</span></span><br><span class="line">          <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_IP</span></span><br><span class="line">      <span class="attr">valueFrom:</span></span><br><span class="line">        <span class="attr">fieldRef:</span></span><br><span class="line">          <span class="attr">fieldPath:</span> <span class="string">status.podIP</span></span><br></pre></td></tr></table></figure>



<p>我们可以看到上面我们使用了一种新的方式来设置 env 的值：<code>valueFrom</code>，由于 Pod 的 name 和 namespace 属于元数据，是在 Pod 创建之前就已经定下来了的，所以我们可以使用 metata 就可以获取到了，但是对于 Pod 的 IP 则不一样，因为我们知道 Pod IP 是不固定的，Pod 重建了就变了，它属于状态数据，所以我们使用 status 这个属性去获取。另外除了使用 <code>fieldRef</code>获取 Pod 的基本信息外，还可以通过 <code>resourceFieldRef</code> 去获取容器的资源请求和资源限制信息。</p>
<p>我们直接创建上面的 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f env-pod.yaml</span><br><span class="line">pod &quot;env-pod&quot; created</span><br></pre></td></tr></table></figure>



<p>Pod 创建成功后，我们可以查看日志：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl logs env-pod -n kube-system |grep POD</span><br><span class="line">kubectl logs -f env-pod -n kube-system</span><br><span class="line">POD_IP=10.244.1.121</span><br><span class="line">KUBERNETES_SERVICE_PORT=443</span><br><span class="line">KUBERNETES_PORT=tcp://10.96.0.1:443</span><br><span class="line">KUBE_DNS_SERVICE_PORT_DNS_TCP=53</span><br><span class="line">HOSTNAME=env-pod</span><br><span class="line">SHLVL=1</span><br><span class="line">HOME=/root</span><br><span class="line">KUBE_DNS_SERVICE_HOST=10.96.0.10</span><br><span class="line">KUBE_DNS_PORT_9153_TCP_ADDR=10.96.0.10</span><br><span class="line">KUBE_DNS_PORT_9153_TCP_PORT=9153</span><br><span class="line">KUBE_DNS_PORT_9153_TCP_PROTO=tcp</span><br><span class="line">KUBE_DNS_SERVICE_PORT=53</span><br><span class="line">KUBE_DNS_PORT=udp://10.96.0.10:53</span><br><span class="line">POD_NAME=env-pod</span><br><span class="line">KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1</span><br><span class="line">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</span><br><span class="line">KUBE_DNS_PORT_53_TCP_ADDR=10.96.0.10</span><br><span class="line">KUBERNETES_PORT_443_TCP_PORT=443</span><br><span class="line">KUBE_DNS_SERVICE_PORT_METRICS=9153</span><br><span class="line">KUBERNETES_PORT_443_TCP_PROTO=tcp</span><br><span class="line">KUBE_DNS_PORT_9153_TCP=tcp://10.96.0.10:9153</span><br><span class="line">KUBE_DNS_PORT_53_UDP_ADDR=10.96.0.10</span><br><span class="line">KUBE_DNS_PORT_53_TCP_PORT=53</span><br><span class="line">KUBE_DNS_PORT_53_TCP_PROTO=tcp</span><br><span class="line">KUBE_DNS_PORT_53_UDP_PORT=53</span><br><span class="line">KUBE_DNS_SERVICE_PORT_DNS=53</span><br><span class="line">KUBE_DNS_PORT_53_UDP_PROTO=udp</span><br><span class="line">KUBERNETES_SERVICE_PORT_HTTPS=443</span><br><span class="line">KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443</span><br><span class="line">POD_NAMESPACE=kube-system</span><br><span class="line">KUBERNETES_SERVICE_HOST=10.96.0.1</span><br><span class="line">PWD=/</span><br><span class="line">KUBE_DNS_PORT_53_TCP=tcp://10.96.0.10:53</span><br><span class="line">KUBE_DNS_PORT_53_UDP=udp://10.96.0.10:53</span><br></pre></td></tr></table></figure>

<p>我们可以看到 Pod 的 IP、NAME、NAMESPACE 都通过环境变量打印出来了。</p>
<p>环境变量</p>
<p>上面打印 Pod 的环境变量可以看到有很多内置的变量，其中大部分是系统自动为我们添加的，Kubernetes 会把当前命名空间下面的 Service 信息通过环境变量的形式注入到 Pod 中去：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc -n kube-system</span><br><span class="line">NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   4d21h</span><br></pre></td></tr></table></figure>

<h3 id="Volume-挂载"><a href="#Volume-挂载" class="headerlink" title="Volume 挂载"></a>Volume 挂载</h3><p><code>Downward API</code>除了提供环境变量的方式外，还提供了通过 Volume 挂载的方式去获取 Pod 的基本信息。接下来我们通过<code>Downward API</code>将 Pod 的 Label、Annotation 等信息通过 Volume 挂载到容器的某个文件中去，然后在容器中打印出该文件的值来验证，对应的资源清单文件如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># volume-pod.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">test-volume</span></span><br><span class="line">    <span class="attr">node-env:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">own:</span> <span class="string">youdianzhishi</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podinfo</span></span><br><span class="line">    <span class="attr">downwardAPI:</span></span><br><span class="line">      <span class="attr">items:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">labels</span></span><br><span class="line">        <span class="attr">fieldRef:</span></span><br><span class="line">          <span class="attr">fieldPath:</span> <span class="string">metadata.labels</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">annotations</span></span><br><span class="line">        <span class="attr">fieldRef:</span></span><br><span class="line">          <span class="attr">fieldPath:</span> <span class="string">metadata.annotations</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-pod</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podinfo</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/etc/podinfo</span></span><br></pre></td></tr></table></figure>



<p>我们将元数据 labels 和 annotaions 以文件的形式挂载到了 <code>/etc/podinfo</code> 目录下，创建上面的 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl create -f volume-pod.yaml</span><br><span class="line">pod &quot;volume-pod&quot; created</span><br></pre></td></tr></table></figure>



<p>创建成功后，我们可以进入到容器中查看元信息是不是已经存入到文件中了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl exec -it volume-pod /bin/sh -n kube-system</span><br><span class="line">/ # ls /etc/podinfo/</span><br><span class="line">..2019_11_13_09_57_15.990445016/  annotations</span><br><span class="line">..data/                           labels</span><br><span class="line">/ # cat /etc/podinfo/labels</span><br><span class="line">k8s-app=&quot;test-volume&quot;</span><br><span class="line">/ # cat /etc/podinfo/annotations</span><br><span class="line">build=&quot;test&quot;</span><br><span class="line">kubectl.kubernetes.io/last-applied-configuration=&quot;&#123;\&quot;apiVersion\&quot;:\&quot;v1\&quot;,\&quot;kind\&quot;:\&quot;Pod\&quot;,\&quot;metadata\&quot;:&#123;\&quot;annotations\&quot;:&#123;\&quot;build\&quot;:\&quot;test\&quot;,\&quot;own\&quot;:\&quot;youdianzhishi\&quot;&#125;,\&quot;labels\&quot;:&#123;\&quot;k8s-app\&quot;:\&quot;test-volume\&quot;,\&quot;node-env\&quot;:\&quot;test\&quot;&#125;,\&quot;name\&quot;:\&quot;volume-pod\&quot;,\&quot;namespace\&quot;:\&quot;kube-system\&quot;&#125;,\&quot;spec\&quot;:&#123;\&quot;containers\&quot;:[&#123;\&quot;args\&quot;:[\&quot;sleep\&quot;,\&quot;3600\&quot;],\&quot;image\&quot;:\&quot;busybox\&quot;,\&quot;name\&quot;:\&quot;volume-pod\&quot;,\&quot;volumeMounts\&quot;:[&#123;\&quot;mountPath\&quot;:\&quot;/etc/podinfo\&quot;,\&quot;name\&quot;:\&quot;podinfo\&quot;&#125;]&#125;],\&quot;volumes\&quot;:[&#123;\&quot;downwardAPI\&quot;:&#123;\&quot;items\&quot;:[&#123;\&quot;fieldRef\&quot;:&#123;\&quot;fieldPath\&quot;:\&quot;metadata.labels\&quot;&#125;,\&quot;path\&quot;:\&quot;labels\&quot;&#125;,&#123;\&quot;fieldRef\&quot;:&#123;\&quot;fieldPath\&quot;:\&quot;metadata.annotations\&quot;&#125;,\&quot;path\&quot;:\&quot;annotations\&quot;&#125;]&#125;,\&quot;name\&quot;:\&quot;podinfo\&quot;&#125;]&#125;&#125;\n&quot;</span><br><span class="line">kubernetes.io/config.seen=&quot;2019-11-13T17:57:15.320894744+08:00&quot;</span><br><span class="line">kubernetes.io/config.source=&quot;api&quot;</span><br></pre></td></tr></table></figure>

<p>我们可以看到 Pod 的 Labels 和 Annotations 信息都被挂载到 <code>/etc/podinfo</code> 目录下面的 lables 和 annotations 文件了。</p>
<p>目前，<code>Downward API</code> 支持的字段已经非常丰富了，比如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1. 使用 fieldRef 可以声明使用:</span><br><span class="line"></span><br><span class="line">spec.nodeName - 宿主机名字</span><br><span class="line">status.hostIP - 宿主机IP</span><br><span class="line">metadata.name - Pod的名字</span><br><span class="line">metadata.namespace - Pod的Namespace</span><br><span class="line">status.podIP - Pod的IP</span><br><span class="line">spec.serviceAccountName - Pod的Service Account的名字</span><br><span class="line">metadata.uid - Pod的UID</span><br><span class="line">metadata.labels[&#x27;&lt;KEY&gt;&#x27;] - 指定&lt;KEY&gt;的Label值</span><br><span class="line">metadata.annotations[&#x27;&lt;KEY&gt;&#x27;] - 指定&lt;KEY&gt;的Annotation值</span><br><span class="line">metadata.labels - Pod的所有Label</span><br><span class="line">metadata.annotations - Pod的所有Annotation</span><br><span class="line"></span><br><span class="line">2. 使用 resourceFieldRef 可以声明使用:</span><br><span class="line"></span><br><span class="line">容器的 CPU limit</span><br><span class="line">容器的 CPU request</span><br><span class="line">容器的 memory limit</span><br><span class="line">容器的 memory request</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong></p>
<p>需要注意的是，<code>Downward API</code> 能够获取到的信息，一定是 Pod 里的容器进程启动之前就能够确定下来的信息。而如果你想要获取 Pod 容器运行后才会出现的信息，比如，容器进程的 PID，那就肯定不能使用 <code>Downward API</code> 了，而应该考虑在 Pod 里定义一个 sidecar 容器来获取了。</p>
<p>在实际应用中，如果你的应用有获取 Pod 的基本信息的需求，一般我们就可以利用<code>Downward API</code>来获取基本信息，然后编写一个启动脚本或者利用<code>initContainer</code>将 Pod 的信息注入到我们容器中去，然后在我们自己的应用中就可以正常的处理相关逻辑了。</p>
<p>除了通过 Downward API 可以获取到 Pod 本身的信息之外，其实我们还可以通过映射其他资源对象来获取对应的信息，比如 Secret、ConfigMap 资源对象，同样我们可以通过环境变量和挂载 Volume 的方式来获取他们的信息，但是，通过环境变量获取这些信息的方式，不具备自动更新的能力。所以，一般情况下，都建议使用 Volume 文件的方式获取这些信息，因为通过 Volume 的方式挂载的文件在 Pod 中会进行热更新。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/Pod%20%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/Pod%20%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/" class="post-title-link" itemprop="url">Pod 生命周期</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:35" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">基础知识</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>18k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>16 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Pod-生命周期"><a href="#Pod-生命周期" class="headerlink" title="Pod 生命周期"></a>Pod 生命周期</h1><p><img data-src="https://mudutestmenu.mudu.tv/upload/90q92j.jpg" alt="pod loap"></p>
<p>前面我们已经了解了 Pod 的设计原理，接下来我们来了解下 Pod 的生命周期。下图展示了一个 Pod 的完整生命周期过程，其中包含 <code>Init Container</code>、<code>Pod Hook</code>、<code>健康检查</code> 三个主要部分，接下来我们就来分别介绍影响 Pod 生命周期的部分：</p>
<p>首先在介绍 Pod 的生命周期之前，我们先了解下 Pod 的状态，因为 Pod 状态可以反应出当前我们的 Pod 的具体状态信息，也是我们分析排错的一个必备的方式。</p>
<h2 id="Pod-状态"><a href="#Pod-状态" class="headerlink" title="Pod 状态"></a>Pod 状态</h2><p>首先先了解下 Pod 的状态值，我们可以通过 <code>kubectl explain pod.status</code> 命令来了解关于 Pod 状态的一些信息，Pod 的状态定义在 <code>PodStatus</code> 对象中，其中有一个 <code>phase</code> 字段，下面是 <code>phase</code> 的可能取值：</p>
<ul>
<li>挂起（Pending）：Pod 信息已经提交给了集群，但是还没有被调度器调度到合适的节点或者 Pod 里的镜像正在下载</li>
<li>运行中（Running）：该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态</li>
<li>成功（Succeeded）：Pod 中的所有容器都被成功终止，并且不会再重启</li>
<li>失败（Failed）：Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非<code>0</code>状态退出或者被系统终止</li>
<li>未知（Unknown）：因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败导致的</li>
</ul>
<p>除此之外，<code>PodStatus</code> 对象中还包含一个 <code>PodCondition</code> 的数组，里面包含的属性有：</p>
<ul>
<li>lastProbeTime：最后一次探测 Pod Condition 的时间戳。</li>
<li>lastTransitionTime：上次 Condition 从一种状态转换到另一种状态的时间。</li>
<li>message：上次 Condition 状态转换的详细描述。</li>
<li>reason：Condition 最后一次转换的原因。</li>
<li>status：Condition 状态类型，可以为 “True”, “False”, and “Unknown”.</li>
<li>type：Condition 类型，包括以下方面：<ul>
<li>PodScheduled（Pod 已经被调度到其他 node 里）</li>
<li>Ready（Pod 能够提供服务请求，可以被添加到所有可匹配服务的负载平衡池中）</li>
<li>Initialized（所有的<code>init containers</code>已经启动成功）</li>
<li>Unschedulable（调度程序现在无法调度 Pod，例如由于缺乏资源或其他限制）</li>
<li>ContainersReady（Pod 里的所有容器都是 ready 状态）</li>
</ul>
</li>
</ul>
<h2 id="重启策略"><a href="#重启策略" class="headerlink" title="重启策略"></a>重启策略</h2><p>我们可以通过配置 <code>restartPolicy</code> 字段来设置 Pod 中所有容器的重启策略，其可能值为 <code>Always</code>、<code>OnFailure</code> 和 <code>Never</code>，默认值为 <code>Always</code>，<code>restartPolicy</code> 指通过 kubelet 在同一节点上重新启动容器。通过 kubelet 重新启动的退出容器将以指数增加延迟（10s，20s，40s…）重新启动，上限为 5 分钟，并在成功执行 10 分钟后重置。不同类型的的控制器可以控制 Pod 的重启策略：</p>
<ul>
<li><code>Job</code>：适用于一次性任务如批量计算，任务结束后 Pod 会被此类控制器清除。Job 的重启策略只能是<code>&quot;OnFailure&quot;</code>或者<code>&quot;Never&quot;</code>。</li>
<li><code>ReplicaSet</code>、<code>Deployment</code>：此类控制器希望 Pod 一直运行下去，它们的重启策略只能是<code>&quot;Always&quot;</code>。</li>
<li><code>DaemonSet</code>：每个节点上启动一个 Pod，很明显此类控制器的重启策略也应该是<code>&quot;Always&quot;</code>。</li>
</ul>
<h2 id="初始化容器"><a href="#初始化容器" class="headerlink" title="初始化容器"></a>初始化容器</h2><p>了解了 Pod 状态后，首先来了解下 Pod 中最新启动的 <code>Init Container</code>，也就是我们平时常说的<strong>初始化容器</strong>。<code>Init Container</code>就是用来做初始化工作的容器，可以是一个或者多个，如果有多个的话，这些容器会按定义的顺序依次执行。我们知道一个 Pod 里面的所有容器是共享数据卷和 <code>Network Namespace</code> 的，所以 <code>Init Container</code> 里面产生的数据可以被主容器使用到。从上面的 Pod 生命周期的图中可以看出初始化容器是独立与主容器之外的，只有所有的&#96;初始化容器执行完之后，主容器才会被启动。那么初始化容器有哪些应用场景呢：</p>
<ul>
<li>等待其他模块 Ready：这个可以用来解决服务之间的依赖问题，比如我们有一个 Web 服务，该服务又依赖于另外一个数据库服务，但是在我们启动这个 Web 服务的时候我们并不能保证依赖的这个数据库服务就已经启动起来了，所以可能会出现一段时间内 Web 服务连接数据库异常。要解决这个问题的话我们就可以在 Web 服务的 Pod 中使用一个 <code>InitContainer</code>，在这个初始化容器中去检查数据库是否已经准备好了，准备好了过后初始化容器就结束退出，然后我们主容器的 Web 服务才被启动起来，这个时候去连接数据库就不会有问题了。</li>
<li>做初始化配置：比如集群里检测所有已经存在的成员节点，为主容器准备好集群的配置信息，这样主容器起来后就能用这个配置信息加入集群。</li>
<li>其它场景：如将 Pod 注册到一个中央数据库、配置中心等。</li>
</ul>
<p>比如现在我们来实现一个功能，在 Nginx Pod 启动之前去重新初始化首页内容，如下所示的资源清单：（init-pod.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">init-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workdir</span></span><br><span class="line">      <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">wget</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">&#x27;-O&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">&#x27;/work-dir/index.html&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">http://www.baidu.com</span> <span class="comment"># https</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workdir</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">&#x27;/work-dir&#x27;</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">workdir</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br></pre></td></tr></table></figure>



<p>上面的资源清单中我们首先在 Pod 顶层声明了一个名为 workdir 的 <code>Volume</code>，前面我们用了 hostPath 的模式，这里我们使用的是 <code>emptyDir&#123;&#125;</code>，这个是一个临时的目录，数据会保存在 kubelet 的工作目录下面，生命周期等同于 Pod 的生命周期。</p>
<p>然后我们定义了一个初始化容器，该容器会下载一个 html 文件到 <code>/work-dir</code> 目录下面，但是由于我们又将该目录声明挂载到了全局的 Volume，同样的主容器 nginx 也将目录 <code>/usr/share/nginx/html</code> 声明挂载到了全局的 Volume，所以在主容器的该目录下面会同步初始化容器中创建的 <code>index.html</code> 文件。</p>
<p>直接创建上面的 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f init-pod.yaml</span><br></pre></td></tr></table></figure>



<p>创建完成后可以查看该 Pod 的状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME                            READY   STATUS     RESTARTS   AGE</span><br><span class="line">init-demo                       0/1     Init:0/1   0          4s</span><br></pre></td></tr></table></figure>



<p>可以发现 Pod 现在的状态处于 <code>Init:0/1</code> 状态，意思就是现在第一个初始化容器还在执行过程中，此时我们可以查看 Pod 的详细信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl describe pod init-demo</span><br><span class="line">Name:         init-demo</span><br><span class="line">Namespace:    default</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         node1/192.168.31.108</span><br><span class="line">Start Time:   Mon, 01 Nov 2021 18:58:40 +0800</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Running</span><br><span class="line">IP:           10.244.1.10</span><br><span class="line">IPs:</span><br><span class="line">  IP:  10.244.1.10</span><br><span class="line">Init Containers:</span><br><span class="line">  install:</span><br><span class="line">    Container ID:  containerd://ca0020473b613729e4c853cd0c163023677a631432531ceacbb1aed1ae65bea9</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker.io/library/busybox@sha256:15e927f78df2cc772b70713543d6b651e3cd8370abf86b2ea4644a9fba21107f</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      wget</span><br><span class="line">      -O</span><br><span class="line">      /work-dir/index.html</span><br><span class="line">      http://www.baidu.com</span><br><span class="line">    State:          Terminated</span><br><span class="line">      Reason:       Completed</span><br><span class="line">      Exit Code:    0</span><br><span class="line">      Started:      Mon, 01 Nov 2021 18:58:43 +0800</span><br><span class="line">      Finished:     Mon, 01 Nov 2021 18:58:43 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-htmjf (ro)</span><br><span class="line">      /work-dir from workdir (rw)</span><br><span class="line">Containers:</span><br><span class="line">  web:</span><br><span class="line">    Container ID:   containerd://18f08b312af9c464f8cc1313b82cfaf05d1910c8dc35d91dddd2810a184a0bfd</span><br><span class="line">    Image:          nginx</span><br><span class="line">    Image ID:       docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36</span><br><span class="line">    Port:           80/TCP</span><br><span class="line">    Host Port:      0/TCP</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Mon, 01 Nov 2021 18:58:59 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /usr/share/nginx/html from workdir (rw)</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-htmjf (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True</span><br><span class="line">  Ready             True</span><br><span class="line">  ContainersReady   True</span><br><span class="line">  PodScheduled      True</span><br><span class="line">Volumes:</span><br><span class="line">  workdir:</span><br><span class="line">    Type:       EmptyDir (a temporary directory that shares a pod&#x27;s lifetime)</span><br><span class="line">    Medium:</span><br><span class="line">    SizeLimit:  &lt;unset&gt;</span><br><span class="line">  kube-api-access-htmjf:</span><br><span class="line">    Type:                    Projected (a volume that contains injected data from multiple sources)</span><br><span class="line">    TokenExpirationSeconds:  3607</span><br><span class="line">    ConfigMapName:           kube-root-ca.crt</span><br><span class="line">    ConfigMapOptional:       &lt;nil&gt;</span><br><span class="line">    DownwardAPI:             true</span><br><span class="line">QoS Class:                   BestEffort</span><br><span class="line">Node-Selectors:              &lt;none&gt;</span><br><span class="line">Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span><br><span class="line">                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age   From               Message</span><br><span class="line">  ----    ------     ----  ----               -------</span><br><span class="line">  Normal  Scheduled  34s   default-scheduler  Successfully assigned default/init-demo to node1</span><br><span class="line">  Normal  Pulling    35s   kubelet            Pulling image &quot;busybox&quot;</span><br><span class="line">  Normal  Pulled     32s   kubelet            Successfully pulled image &quot;busybox&quot; in 2.655408135s</span><br><span class="line">  Normal  Created    32s   kubelet            Created container install</span><br><span class="line">  Normal  Started    32s   kubelet            Started container install</span><br><span class="line">  Normal  Pulling    31s   kubelet            Pulling image &quot;nginx&quot;</span><br><span class="line">  Normal  Pulled     16s   kubelet            Successfully pulled image &quot;nginx&quot; in 15.385097955s</span><br><span class="line">  Normal  Created    16s   kubelet            Created container web</span><br><span class="line">  Normal  Started    16s   kubelet            Started container web</span><br></pre></td></tr></table></figure>



<p>从上面的描述信息里面可以看到初始化容器已经启动了，现在处于 <code>Running</code> 状态，所以还需要稍等，到初始化容器执行完成后退出初始化容器会变成 <code>Completed</code> 状态，然后才会启动主容器。待到主容器也启动完成后，Pod 就会变成<code>Running</code> 状态，然后我们去访问下 Pod 主页，验证下是否有我们初始化容器中下载的页面信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl get pods -o wide</span><br><span class="line">NAME        READY   STATUS    RESTARTS   AGE   IP            NODE    NOMINATED NODE   READINESS GATES</span><br><span class="line">init-demo   1/1     Running   0          70s   10.244.1.10   node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">➜  ~ curl 10.244.1.10</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&#x27;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&#x27;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &#x27;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&#x27;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;</span><br></pre></td></tr></table></figure>



<h2 id="Pod-Hook"><a href="#Pod-Hook" class="headerlink" title="Pod Hook"></a>Pod Hook</h2><p>我们知道 Pod 是 Kubernetes 集群中的最小单元，而 Pod 是由容器组成的，所以在讨论 Pod 的生命周期的时候我们可以先来讨论下容器的生命周期。实际上 Kubernetes 为我们的容器提供了生命周期的钩子，就是我们说的 <code>Pod Hook</code>，Pod Hook 是由 kubelet 发起的，当容器中的进程启动前或者容器中的进程终止之前运行，这是包含在容器的生命周期之中。我们可以同时为 Pod 中的所有容器都配置 hook。</p>
<p>Kubernetes 为我们提供了两种钩子函数：</p>
<ul>
<li><code>PostStart</code>：这个钩子在容器创建后立即执行。但是，并不能保证钩子将在容器 <code>ENTRYPOINT</code> 之前运行，因为没有参数传递给处理程序。主要用于资源部署、环境准备等。不过需要注意的是如果钩子花费太长时间以至于不能运行或者挂起，容器将不能达到 running 状态。</li>
<li><code>PreStop</code>：这个钩子在容器终止之前立即被调用。它是阻塞的，意味着它是同步的，所以它必须在删除容器的调用发出之前完成。主要用于优雅关闭应用程序、通知其他系统等。如果钩子在执行期间挂起，Pod 阶段将停留在 running 状态并且永不会达到 failed 状态。</li>
</ul>
<p>如果 <code>PostStart</code> 或者 <code>PreStop</code> 钩子失败， 它会杀死容器。所以我们应该让钩子函数尽可能的轻量。当然有些情况下，长时间运行命令是合理的， 比如在停止容器之前预先保存状态。</p>
<p>另外我们有两种方式来实现上面的钩子函数：</p>
<ul>
<li><code>Exec</code> - 用于执行一段特定的命令，不过要注意的是该命令消耗的资源会被计入容器。</li>
<li><code>HTTP</code> - 对容器上的特定的端点执行 HTTP 请求。</li>
</ul>
<p>以下示例中，定义了一个 Nginx Pod，其中设置了 PostStart 钩子函数，即在容器创建成功后，写入一句话到 <code>/usr/share/message</code> 文件中：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pod-poststart.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hook-demo1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hook-demo1</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">lifecycle:</span></span><br><span class="line">        <span class="attr">postStart:</span></span><br><span class="line">          <span class="attr">exec:</span></span><br><span class="line">            <span class="attr">command:</span></span><br><span class="line">              [</span><br><span class="line">                <span class="string">&#x27;/bin/sh&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;-c&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;echo Hello from the postStart handler &gt; /usr/share/message&#x27;</span>,</span><br><span class="line">              ]</span><br></pre></td></tr></table></figure>



<p>直接创建上面的 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f pod-poststart.yaml</span><br><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME         READY   STATUS    RESTARTS   AGE</span><br><span class="line">hook-demo1   1/1     Running   0          26s</span><br></pre></td></tr></table></figure>



<p>创建成功后可以查看容器中 <code>/usr/share/message</code> 文件是否内容正确：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl exec -it hook-demo1 -- cat /usr/share/message</span><br><span class="line">Hello from the postStart handler</span><br></pre></td></tr></table></figure>



<p>当用户请求删除含有 Pod 的资源对象时（如 Deployment 等），K8S 为了让应用程序优雅关闭（即让应用程序完成正在处理的请求后，再关闭软件），K8S 提供两种信息通知：</p>
<ul>
<li>默认：K8S 通知 node 执行容器 <code>stop</code> 命令，容器运行时会先向容器中 PID 为 1 的进程发送系统信号 <code>SIGTERM</code>，然后等待容器中的应用程序终止执行，如果等待时间达到设定的超时时间，或者默认超时时间（30s），会继续发送 <code>SIGKILL</code> 的系统信号强行 kill 掉进程</li>
<li>使用 Pod 生命周期（利用 <code>PreStop</code> 回调函数），它在发送终止信号之前执行</li>
</ul>
<p>默认所有的优雅退出时间都在 30 秒内，<code>kubectl delete</code> 命令支持 <code>--grace-period=&lt;seconds&gt;</code> 选项，这个选项允许用户用他们自己指定的值覆盖默认值，值<code>0</code>代表强制删除 pod。 在 kubectl 1.5 及以上的版本里，执行强制删除时必须同时指定 <code>--force --grace-period=0</code>。</p>
<p>强制删除一个 pod 是从集群中还有 etcd 里立刻删除这个 pod，只是当 Pod 被强制删除时， APIServer 不会等待来自 Pod 所在节点上的 kubelet 的确认信息：pod 已经被终止。在 API 里 pod 会被立刻删除，在节点上， pods 被设置成立刻终止后，在强行杀掉前还会有一个很小的宽限期。</p>
<p>以下示例中，定义了一个 Nginx Pod，其中设置了 <code>PreStop</code> 钩子函数，即在容器退出之前，优雅的关闭 Nginx：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pod-prestop.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hook-demo2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hook-demo2</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">lifecycle:</span></span><br><span class="line">        <span class="attr">preStop:</span></span><br><span class="line">          <span class="attr">exec:</span></span><br><span class="line">            <span class="attr">command:</span> [<span class="string">&#x27;/usr/sbin/nginx&#x27;</span>, <span class="string">&#x27;-s&#x27;</span>, <span class="string">&#x27;quit&#x27;</span>] <span class="comment"># 优雅退出</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hook-demo3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">message</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/tmp</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hook-demo2</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">message</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/</span></span><br><span class="line">      <span class="attr">lifecycle:</span></span><br><span class="line">        <span class="attr">preStop:</span></span><br><span class="line">          <span class="attr">exec:</span></span><br><span class="line">            <span class="attr">command:</span></span><br><span class="line">              [</span><br><span class="line">                <span class="string">&#x27;/bin/sh&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;-c&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;echo Hello from the preStop Handler &gt; /usr/share/message&#x27;</span>,</span><br><span class="line">              ]</span><br></pre></td></tr></table></figure>



<p>上面定义的两个 Pod，一个是利用 <code>preStop</code> 来进行优雅删除，另外一个是利用 <code>preStop</code> 来做一些信息记录的事情，同样直接创建上面的 Pod：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f pod-prestop.yaml</span><br><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME         READY   STATUS    RESTARTS   AGE</span><br><span class="line">hook-demo2   1/1     Running   0          20s</span><br><span class="line">hook-demo3   1/1     Running   0          20s</span><br></pre></td></tr></table></figure>



<p>创建完成后，我们可以直接删除 hook-demo2 这个 Pod，在容器删除之前会执行 preStop 里面的优雅关闭命令，这个用法在后面我们的滚动更新的时候用来保证我们的应用零宕机非常有用。第二个 Pod 我们声明了一个 hostPath 类型的 Volume，在容器里面声明挂载到了这个 Volume，所以当我们删除 Pod，退出容器之前，在容器里面输出的信息也会同样的保存到宿主机（一定要是 Pod 被调度到的目标节点）的 <code>/tmp</code> 目录下面，我们可以查看 hook-demo3 这个 Pod 被调度的节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl describe pod hook-demo3</span><br><span class="line">Name:         hook-demo3</span><br><span class="line">Namespace:    default</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         node1/192.168.31.108</span><br><span class="line">......</span><br></pre></td></tr></table></figure>



<p>可以看到这个 Pod 被调度到了 <code>node1</code> 这个节点上，我们可以先到该节点上查看 <code>/tmp</code> 目录下面目前没有任何内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ ls /tmp/</span><br></pre></td></tr></table></figure>



<p>现在我们来删除 hook-demo3 这个 Pod，安装我们的设定在容器退出之前会执行 <code>preStop</code> 里面的命令，也就是会往 message 文件中输出一些信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl delete pod hook-demo3</span><br><span class="line">pod &quot;hook-demo3&quot; deleted</span><br><span class="line">➜  ~ ls /tmp/</span><br><span class="line">message</span><br><span class="line">➜  ~ cat /tmp/message</span><br><span class="line">Hello from the preStop Handle</span><br></pre></td></tr></table></figure>

<p>另外 Hook 调用的日志没有暴露给 Pod，所以只能通过 describe 命令来获取，如果有错误将可以看到 <code>FailedPostStartHook</code> 或 <code>FailedPreStopHook</code> 这样的 event。</p>
<h2 id="Pod-健康检查"><a href="#Pod-健康检查" class="headerlink" title="Pod 健康检查"></a>Pod 健康检查</h2><p>现在在 Pod 的整个生命周期中，能影响到 Pod 的就只剩下健康检查这一部分了。在 Kubernetes 集群当中，我们可以通过配置<code>liveness probe（存活探针</code>）和 <code>readiness probe（可读性探针）</code> 来影响容器的生命周期：</p>
<ul>
<li>kubelet 通过使用 <code>liveness probe</code> 来确定你的应用程序是否正在运行，通俗点将就是<strong>是否还活着</strong>。一般来说，如果你的程序一旦崩溃了， Kubernetes 就会立刻知道这个程序已经终止了，然后就会重启这个程序。而我们的 <code>liveness probe</code> 的目的就是来捕获到当前应用程序还没有终止，还没有崩溃，如果出现了这些情况，那么就重启处于该状态下的容器，使应用程序在存在 bug 的情况下依然能够继续运行下去。</li>
<li>kubelet 使用 <code>readiness probe</code> 来确定容器是否已经就绪可以接收流量过来了。这个探针通俗点讲就是说<strong>是否准备好了</strong>，现在可以开始工作了。只有当 Pod 中的容器都处于就绪状态的时候 kubelet 才会认定该 Pod 处于就绪状态，因为一个 Pod 下面可能会有多个容器。当然 Pod 如果处于非就绪状态，那么我们就会将他从 Service 的 Endpoints 列表中移除出来，这样我们的流量就不会被路由到这个 Pod 里面来了。</li>
</ul>
<p>和前面的钩子函数一样的，我们这两个探针的支持下面几种配置方式：</p>
<ul>
<li><code>exec</code>：执行一段命令</li>
<li><code>http</code>：检测某个 http 请求</li>
<li><code>tcpSocket</code>：使用此配置，kubelet 将尝试在指定端口上打开容器的套接字。如果可以建立连接，容器被认为是健康的，如果不能就认为是失败的。实际上就是检查端口。</li>
</ul>
<p>我们先来给大家演示下存活探针的使用方法，首先我们用 exec 执行命令的方式来检测容器的存活，如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># liveness-exec.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-exec</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">30</span><span class="string">;</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">600</span></span><br><span class="line">      <span class="attr">livenessProbe:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line">        <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br></pre></td></tr></table></figure>



<p>我们这里需要用到一个新的属性 <code>livenessProbe</code>，下面通过 exec 执行一段命令:</p>
<ul>
<li><code>periodSeconds</code>：表示让 kubelet 每隔 5 秒执行一次存活探针，也就是每 5 秒执行一次上面的 <code>cat /tmp/healthy</code> 命令，如果命令执行成功了，将返回 0，那么 kubelet 就会认为当前这个容器是存活的，如果返回的是非 0 值，那么 kubelet 就会把该容器杀掉然后重启它。默认是 10 秒，最小 1 秒。</li>
<li><code>initialDelaySeconds</code>：表示在第一次执行探针的时候要等待 5 秒，这样能够确保我们的容器能够有足够的时间启动起来。大家可以想象下，如果你的第一次执行探针等候的时间太短，是不是很有可能容器还没正常启动起来，所以存活探针很可能始终都是失败的，这样就会无休止的重启下去了，对吧？</li>
</ul>
<p>我们在容器启动的时候，执行了如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/sh -c &quot;touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600&quot;</span><br></pre></td></tr></table></figure>



<p>意思是说在容器最开始的 30 秒内创建了一个 <code>/tmp/healthy</code> 文件，在这 30 秒内执行 <code>cat /tmp/healthy</code> 命令都会返回一个成功的返回码。30 秒后，我们删除这个文件，现在执行 <code>cat /tmp/healthy</code> 是不是就会失败了（默认检测失败 3 次才认为失败），所以这个时候就会重启容器了。</p>
<p>我们来创建下该 Pod，然后在 30 秒内，查看 Pod 的 Event：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f liveness-exec.yaml</span><br><span class="line">➜  ~ kubectl describe pod liveness-exec</span><br><span class="line">Name:         liveness-exec</span><br><span class="line">Namespace:    default</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age               From               Message</span><br><span class="line">  ----     ------     ----              ----               -------</span><br><span class="line">  Normal   Scheduled  68s               default-scheduler  Successfully assigned default/liveness-exec to node1</span><br><span class="line">  Normal   Pulling    68s               kubelet            Pulling image &quot;busybox&quot;</span><br><span class="line">  Normal   Pulled     52s               kubelet            Successfully pulled image &quot;busybox&quot; in 15.352808024s</span><br><span class="line">  Normal   Created    52s               kubelet            Created container liveness</span><br><span class="line">  Normal   Started    52s               kubelet            Started container liveness</span><br><span class="line">  Warning  Unhealthy  8s (x3 over 18s)  kubelet            Liveness probe failed: cat: can&#x27;t open &#x27;/tmp/healthy&#x27;: No such file or directory</span><br><span class="line">  Normal   Killing    8s                kubelet            Container liveness failed liveness probe, will be restarted</span><br></pre></td></tr></table></figure>



<p>我们可以观察到容器是正常启动的，在隔一会儿，比如 40s 后，再查看下 Pod 的 Event，在最下面有一条信息显示 liveness probe 失败了，容器将要重启。然后可以查看到 Pod 的 <code>RESTARTS</code> 值加 1 了：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME            READY   STATUS    RESTARTS      AGE</span><br><span class="line">liveness-exec   1/1     Running   1 (16s ago)   106s</span><br></pre></td></tr></table></figure>



<p>同样的，我们还可以使用<code>HTTP GET</code>请求来配置我们的存活探针，我们这里使用一个 liveness 镜像来验证演示下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># liveness-http.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-http</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">cnych/liveness</span></span><br><span class="line">      <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/server</span></span><br><span class="line">      <span class="attr">livenessProbe:</span></span><br><span class="line">        <span class="attr">httpGet:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/healthz</span></span><br><span class="line">          <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">          <span class="attr">httpHeaders:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">X-Custom-Header</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">Awesome</span></span><br><span class="line">        <span class="attr">initialDelaySeconds:</span> <span class="number">3</span></span><br><span class="line">        <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>



<p>同样的，根据 <code>periodSeconds</code> 属性我们可以知道 kubelet 需要每隔 3 秒执行一次 <code>liveness Probe</code>，该探针将向容器中的 server 的 8080 端口发送一个 HTTP GET 请求。如果 server 的 <code>/healthz</code> 路径的 handler 返回一个成功的返回码，kubelet 就会认定该容器是活着的并且很健康，如果返回失败的返回码，kubelet 将杀掉该容器并重启它。initialDelaySeconds 指定 kubelet 在该执行第一次探测之前需要等待 3 秒钟。</p>
<p>返回码</p>
<p>通常来说，任何大于<code>200</code>小于<code>400</code>的状态码都会认定是成功的返回码。其他返回码都会被认为是失败的返回码。</p>
<p>我们可以来查看下上面的 healthz 的实现：</p>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">http.HandleFunc(<span class="string">&quot;/healthz&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    duration := time.Now().Sub(started)</span><br><span class="line">    <span class="keyword">if</span> duration.Seconds() &gt; <span class="number">10</span> &#123;</span><br><span class="line">        w.WriteHeader(<span class="number">500</span>)</span><br><span class="line">        w.Write([]<span class="type">byte</span>(fmt.Sprintf(<span class="string">&quot;error: %v&quot;</span>, duration.Seconds())))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        w.WriteHeader(<span class="number">200</span>)</span><br><span class="line">        w.Write([]<span class="type">byte</span>(<span class="string">&quot;ok&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>



<p>大概意思就是最开始前 10s 返回状态码 200，10s 过后就返回状态码 500。所以当容器启动 3 秒后，kubelet 开始执行健康检查。第一次健康检查会成功，因为是在 10s 之内，但是 10 秒后，健康检查将失败，因为现在返回的是一个错误的状态码了，所以 kubelet 将会杀掉和重启容器。</p>
<p>同样的，我们来创建下该 Pod 测试下效果，10 秒后，查看 Pod 的 event，确认 liveness probe 失败并重启了容器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kubectl apply -f liveness-http.yaml</span><br><span class="line">➜  ~ kubectl describe pod liveness-http</span><br><span class="line">Name:         liveness-http</span><br><span class="line">Namespace:    default</span><br><span class="line">......</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                From               Message</span><br><span class="line">  ----     ------     ----               ----               -------</span><br><span class="line">  Normal   Scheduled  44s                default-scheduler  Successfully assigned default/liveness-http to node2</span><br><span class="line">  Normal   Pulled     41s                kubelet            Successfully pulled image &quot;cnych/liveness&quot; in 3.359937074s</span><br><span class="line">  Normal   Pulling    21s (x2 over 45s)  kubelet            Pulling image &quot;cnych/liveness&quot;</span><br><span class="line">  Warning  Unhealthy  21s (x3 over 29s)  kubelet            Liveness probe failed: HTTP probe failed with statuscode: 500</span><br><span class="line">  Normal   Killing    21s                kubelet            Container liveness failed liveness probe, will be restarted</span><br><span class="line">  Normal   Created    6s (x2 over 41s)   kubelet            Created container liveness</span><br><span class="line">  Normal   Started    6s (x2 over 41s)   kubelet            Started container liveness</span><br><span class="line">  Normal   Pulled     6s                 kubelet            Successfully pulled image &quot;cnych/liveness&quot; in 15.300179047s</span><br><span class="line">➜  ~ kubectl get pods</span><br><span class="line">NAME            READY   STATUS    RESTARTS      AGE</span><br><span class="line">liveness-http   1/1     Running   2 (16s ago)   76s</span><br></pre></td></tr></table></figure>



<p>除了上面的 <code>exec</code> 和 <code>httpGet</code> 两种检测方式之外，还可以通过 <code>tcpSocket</code> 方式来检测端口是否正常，大家可以按照上面的方式结合 <code>kubectl explain</code> 命令自己来验证下这种方式。</p>
<p>另外前面我们提到了探针里面有一个 <code>initialDelaySeconds</code> 的属性，可以来配置第一次执行探针的等待时间，对于启动非常慢的应用这个参数非常有用，比如 <code>Jenkins</code>、<code>Gitlab</code> 这类应用，但是如何设置一个合适的初始延迟时间呢？这个就和应用具体的环境有关系了，所以这个值往往不是通用的，这样的话可能就会导致一个问题，我们的资源清单在别的环境下可能就会健康检查失败了，为解决这个问题，在 Kubernetes v1.16 版本官方特地新增了一个 <code>startupProbe（启动探针）</code>，该探针将推迟所有其他探针，直到 Pod 完成启动为止，使用方法和存活探针一样：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">startupProbe:</span></span><br><span class="line">  <span class="attr">httpGet:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/healthz</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">failureThreshold:</span> <span class="number">30</span> <span class="comment"># 尽量设置大点</span></span><br><span class="line">  <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>



<p>比如上面这里的配置表示我们的慢速容器最多可以有 5 分钟（30 个检查 * 10 秒&#x3D; 300s）来完成启动。</p>
<p>有的时候，应用程序可能暂时无法对外提供服务，例如，应用程序可能需要在启动期间加载大量数据或配置文件。在这种情况下，您不想杀死应用程序，也不想对外提供服务。那么这个时候我们就可以使用 <code>readiness probe</code> 来检测和减轻这些情况，Pod 中的容器可以报告自己还没有准备，不能处理 Kubernetes 服务发送过来的流量。<code>readiness probe</code> 的配置跟 <code>liveness probe</code> 基本上一致的，唯一的不同是使用 <code>readinessProbe</code> 而不是 <code>livenessProbe</code>，两者如果同时使用的话就可以确保流量不会到达还未准备好的容器，准备好过后，如果应用程序出现了错误，则会重新启动容器。对于就绪探针我们会在后面 Service 的章节和大家继续介绍。</p>
<p>另外除了上面的 <code>initialDelaySeconds</code> 和 <code>periodSeconds</code> 属性外，探针还可以配置如下几个参数：</p>
<ul>
<li><code>timeoutSeconds</code>：探测超时时间，默认 1 秒，最小 1 秒。</li>
<li><code>successThreshold</code>：探测失败后，最少连续探测成功多少次才被认定为成功，默认是 1，但是如果是 <code>liveness</code> 则必须是 1。最小值是 1。</li>
<li><code>failureThreshold</code>：探测成功后，最少连续探测失败多少次才被认定为失败，默认是 3，最小值是 1。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/11/Pod%20%E8%B0%83%E5%BA%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="六一">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hui's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/11/Pod%20%E8%B0%83%E5%BA%A6/" class="post-title-link" itemprop="url">Pod 调度</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-09-11 20:32:34 / 修改时间：21:51:23" itemprop="dateCreated datePublished" datetime="2025-09-11T20:32:34+08:00">2025-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/%E8%B0%83%E5%BA%A6%E5%99%A8/" itemprop="url" rel="index"><span itemprop="name">调度器</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>15k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h1><p>一般情况下我们部署的 Pod 是通过集群的自动调度策略来选择节点的，默认情况下调度器考虑的是资源足够，并且负载尽量平均，但是有的时候我们需要能够更加细粒度的去控制 Pod 的调度，比如我们希望一些机器学习的应用只跑在有 GPU 的节点上；但是有的时候我们的服务之间交流比较频繁，又希望能够将这服务的 Pod 都调度到同一个的节点上。这就需要使用一些调度方式来控制 Pod 的调度了，主要有两个概念：<strong>亲和性和反亲和性</strong>，亲和性又分成节点亲和性(nodeAffinity)和 Pod 亲和性(podAffinity)。</p>
<h2 id="nodeSelector"><a href="#nodeSelector" class="headerlink" title="nodeSelector"></a>nodeSelector</h2><p>在了解亲和性之前，我们先来了解一个非常常用的调度方式：<code>nodeSelector</code>。我们知道 label 标签是 kubernetes 中一个非常重要的概念，用户可以非常灵活的利用 label 来管理集群中的资源，比如最常见的 Service 对象通过 label 去匹配 Pod 资源，而 Pod 的调度也可以根据节点的 label 来进行调度。</p>
<p>我们可以通过下面的命令查看我们的 node 的 label：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get nodes --show-labels</span><br><span class="line">NAME      STATUS   ROLES                  AGE   VERSION   LABELS</span><br><span class="line">master1   Ready    control-plane,master   82d   v1.22.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/exclude-from-external-load-balancers=</span><br><span class="line">node1     Ready    &lt;none&gt;                 82d   v1.22.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node1,kubernetes.io/os=linux</span><br><span class="line">node2     Ready    &lt;none&gt;                 82d   v1.22.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node2,kubernetes.io/os=linux</span><br></pre></td></tr></table></figure>



<p>现在我们先给节点 node2 增加一个<code>com=youdianzhishi</code>的标签，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl label nodes node2 com=youdianzhishi</span><br><span class="line">node/node2 labeled</span><br></pre></td></tr></table></figure>



<p>我们可以通过上面的 <code>--show-labels</code> 参数可以查看上述标签是否生效。当节点被打上了相关标签后，在调度的时候就可以使用这些标签了，只需要在 Pod 的 spec 字段中添加 <code>nodeSelector</code> 字段，里面是我们需要被调度的节点的 label 标签，比如，下面的 Pod 我们要强制调度到 node2 这个节点上去，我们就可以使用 nodeSelector 来表示了：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># node-selector-demo.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">busybox-pod</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-busybox</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">test-busybox</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">com:</span> <span class="string">youdianzhishi</span></span><br></pre></td></tr></table></figure>



<p>然后我们可以通过 describe 命令查看调度结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f pod-selector-demo.yaml</span><br><span class="line">pod/test-busybox created</span><br><span class="line">➜ kubectl describe pod test-busybox</span><br><span class="line">Name:         test-busybox</span><br><span class="line">Namespace:    default</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         node2/192.168.31.46</span><br><span class="line">......</span><br><span class="line">Node-Selectors:  com=youdianzhishi</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age        From                 Message</span><br><span class="line">  ----    ------     ----       ----                 -------</span><br><span class="line">  Normal  Scheduled  &lt;unknown&gt;  default-scheduler    Successfully assigned default/test-busybox to node2</span><br><span class="line">  Normal  Pulling    13s        kubelet, node2  Pulling image &quot;busybox&quot;</span><br><span class="line">  Normal  Pulled     10s        kubelet, node2  Successfully pulled image &quot;busybox&quot;</span><br><span class="line">  Normal  Created    10s        kubelet, node2  Created container test-busybox</span><br><span class="line">  Normal  Started    9s         kubelet, node2  Started container test-busybox</span><br></pre></td></tr></table></figure>



<p>我们可以看到 Events 下面的信息，我们的 Pod 通过默认的 <code>default-scheduler</code> 调度器被绑定到了 node2 节点。不过需要注意的是<code>nodeSelector</code> 属于强制性的，如果我们的目标节点没有可用的资源，我们的 Pod 就会一直处于 <code>Pending</code> 状态。</p>
<p>通过上面的例子我们可以感受到 <code>nodeSelector</code> 的方式比较直观，但是还够灵活，控制粒度偏大，接下来我们再和大家了解下更加灵活的方式：节点亲和性(nodeAffinity)。</p>
<h2 id="亲和性和反亲和性调度"><a href="#亲和性和反亲和性调度" class="headerlink" title="亲和性和反亲和性调度"></a>亲和性和反亲和性调度</h2><p>前面我们了解了 kubernetes 调度器的调度流程，我们知道默认的调度器在使用的时候，经过了 <code>predicates</code> 和 <code>priorities</code> 两个阶段，但是在实际的生产环境中，往往我们需要根据自己的一些实际需求来控制 Pod 的调度，这就需要用到 <code>nodeAffinity(节点亲和性)</code>、<code>podAffinity(pod 亲和性)</code> 以及 <code>podAntiAffinity(pod 反亲和性)</code>。</p>
<p>亲和性调度可以分成<strong>软策略</strong>和<strong>硬策略</strong>两种方式:</p>
<ul>
<li><code>软策略</code>就是如果现在没有满足调度要求的节点的话，Pod 就会忽略这条规则，继续完成调度过程，说白了就是满足条件最好了，没有的话也无所谓</li>
<li><code>硬策略</code>就比较强硬了，如果没有满足条件的节点的话，就不断重试直到满足条件为止，简单说就是你必须满足我的要求，不然就不干了</li>
</ul>
<p>对于亲和性和反亲和性都有这两种规则可以设置： <code>preferredDuringSchedulingIgnoredDuringExecution</code> 和<code>requiredDuringSchedulingIgnoredDuringExecution</code>，前面的就是软策略，后面的就是硬策略。</p>
<h3 id="节点亲和性"><a href="#节点亲和性" class="headerlink" title="节点亲和性"></a>节点亲和性</h3><p>节点亲和性（nodeAffinity）主要是用来控制 Pod 要部署在哪些节点上，以及不能部署在哪些节点上的，它可以进行一些简单的逻辑组合了，不只是简单的相等匹配。</p>
<p>比如现在我们用一个 Deployment 来管理8个 Pod 副本，现在我们来控制下这些 Pod 的调度，如下例子：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># node-affinity-demo.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">node-affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">node-affinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">8</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">node-affinity</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">node-affinity</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginxweb</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 硬策略</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">NotIn</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">master1</span></span><br><span class="line">          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 软策略</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">preference:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">com</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">youdianzhishi</span></span><br></pre></td></tr></table></figure>



<p>上面这个 Pod 首先是要求不能运行在 master1 这个节点上，如果有个节点满足 <code>com=youdianzhishi</code> 的话就优先调度到这个节点上。</p>
<p>由于上面 node02 节点我们打上了 <code>com=youdianzhishi</code> 这样的 label 标签，所以按要求会优先调度到这个节点来的，现在我们来创建这个 Pod，然后查看具体的调度情况是否满足我们的要求。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f node-affinty-demo.yaml</span><br><span class="line">deployment.apps/node-affinity created</span><br><span class="line">➜ kubectl get pods -l app=node-affinity -o wide</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">node-affinity-cdd9d54d9-bgbbh   1/1     Running   0          2m28s   10.244.2.247   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-dlbck   1/1     Running   0          2m28s   10.244.4.16    node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-g2jr6   1/1     Running   0          2m28s   10.244.4.17    node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-gzr58   1/1     Running   0          2m28s   10.244.1.118   node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-hcv7r   1/1     Running   0          2m28s   10.244.2.246   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-kvxw4   1/1     Running   0          2m28s   10.244.2.245   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-p4mmk   1/1     Running   0          2m28s   10.244.2.244   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-affinity-cdd9d54d9-t5mff   1/1     Running   0          2m28s   10.244.1.117   node2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>从结果可以看出有5个 Pod 被部署到了 node2 节点上，但是可以看到并没有一个 Pod 被部署到 master1 这个节点上，因为我们的硬策略就是不允许部署到该节点上，而 node2 是软策略，所以会尽量满足。这里的匹配逻辑是 label 标签的值在某个列表中，现在 Kubernetes 提供的操作符有下面的几种：</p>
<ul>
<li>In：label 的值在某个列表中</li>
<li>NotIn：label 的值不在某个列表中</li>
<li>Gt：label 的值大于某个值</li>
<li>Lt：label 的值小于某个值</li>
<li>Exists：某个 label 存在</li>
<li>DoesNotExist：某个 label 不存在</li>
</ul>
<p>但是需要注意的是如果 <code>nodeSelectorTerms</code> 下面有多个选项的话，满足任何一个条件就可以了；如果 <code>matchExpressions</code>有多个选项的话，则必须同时满足这些条件才能正常调度 Pod。</p>
<h3 id="Pod-亲和性"><a href="#Pod-亲和性" class="headerlink" title="Pod 亲和性"></a>Pod 亲和性</h3><p>Pod 亲和性（podAffinity）主要解决 Pod 可以和哪些 Pod 部署在同一个拓扑域中的问题（其中拓扑域用主机标签实现，可以是单个主机，也可以是多个主机组成的 cluster、zone 等等），而 Pod 反亲和性主要是解决 Pod 不能和哪些 Pod 部署在同一个拓扑域中的问题，它们都是处理的 Pod 与 Pod 之间的关系，比如一个 Pod 在一个节点上了，那么我这个也得在这个节点，或者你这个 Pod 在节点上了，那么我就不想和你待在同一个节点上。</p>
<p>由于我们这里只有一个集群，并没有区域或者机房的概念，所以我们这里直接使用主机名来作为拓扑域，把 Pod 创建在同一个主机上面。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get nodes --show-labels</span><br><span class="line">NAME      STATUS   ROLES                  AGE   VERSION   LABELS</span><br><span class="line">master1   Ready    control-plane,master   82d   v1.22.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master1,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/exclude-from-external-load-balancers=</span><br><span class="line">node1     Ready    &lt;none&gt;                 82d   v1.22.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node1,kubernetes.io/os=linux</span><br><span class="line">node2     Ready    &lt;none&gt;                 82d   v1.22.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node2,kubernetes.io/os=linux,com=youdianzhishi</span><br></pre></td></tr></table></figure>



<p>同样，还是针对上面的资源对象，我们来测试下 Pod 的亲和性：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pod-affinity-demo.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">pod-affinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">pod-affinity</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">pod-affinity</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginxweb</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 硬策略</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">busybox-pod</span></span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure>



<p>上面这个例子中的 Pod 需要调度到某个指定的节点上，并且该节点上运行了一个带有 <code>app=busybox-pod</code> 标签的 Pod。我们可以查看有标签 <code>app=busybox-pod</code> 的 pod 列表：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -l app=busybox-pod -o wide</span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">test-busybox   1/1     Running   0          27m   10.244.2.242   node2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>我们看到这个 Pod 运行在了 node2 的节点上面，所以按照上面的亲和性来说，上面我们部署的3个 Pod 副本也应该运行在 node2 节点上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f pod-affinity-demo.yaml</span><br><span class="line">deployment.apps/pod-affinity created</span><br><span class="line">➜ kubectl get pods -o wide -l app=pod-affinity</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">pod-affinity-587f9b5b58-5nxmf   1/1     Running   0          26s   10.244.2.249   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-affinity-587f9b5b58-m2j7s   1/1     Running   0          26s   10.244.2.248   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-affinity-587f9b5b58-vrd7b   1/1     Running   0          26s   10.244.2.250   node2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>如果我们把上面的 test-busybox 和 pod-affinity 这个 Deployment 都删除，然后重新创建 pod-affinity 这个资源，看看能不能正常调度呢：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl delete -f node-selector-demo.yaml</span><br><span class="line">pod &quot;test-busybox&quot; deleted</span><br><span class="line">➜  kubectl delete -f pod-affinity-demo.yaml</span><br><span class="line">deployment.apps &quot;pod-affinity&quot; deleted</span><br><span class="line">➜ kubectl apply -f pod-affinity-demo.yaml</span><br><span class="line">deployment.apps/pod-affinity created</span><br><span class="line">➜ kubectl get pods -o wide -l app=pod-affinity</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">pod-affinity-587f9b5b58-bbfgr   0/1     Pending   0          18s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-affinity-587f9b5b58-lwc8n   0/1     Pending   0          18s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-affinity-587f9b5b58-pc7ql   0/1     Pending   0          18s   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>我们可以看到都处于 <code>Pending</code> 状态了，这是因为现在没有一个节点上面拥有 <code>app=busybox-pod</code> 这个标签的 Pod，而上面我们的调度使用的是硬策略，所以就没办法进行调度了，大家可以去尝试下重新将 test-busybox 这个 Pod 调度到其他节点上，观察下上面的3个副本会不会也被调度到对应的节点上去。</p>
<p>我们这个地方使用的是 <code>kubernetes.io/hostname</code> 这个<strong>拓扑域</strong>，意思就是我们当前调度的 Pod 要和目标的 Pod 处于同一个主机上面，因为要处于同一个拓扑域下面，为了说明这个问题，我们把拓扑域改成 <code>beta.kubernetes.io/os</code>，同样的我们当前调度的 Pod 要和目标的 Pod 处于同一个拓扑域中，目标的 Pod 是拥有 <code>beta.kubernetes.io/os=linux</code> 的标签，而我们这里所有节点都有这样的标签，这也就意味着我们所有节点都在同一个拓扑域中，所以我们这里的 Pod 可以被调度到任何一个节点，重新运行上面的 <code>app=busybox-pod</code> 的 Pod，然后再更新下我们这里的资源对象：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get pods -o wide -l app=pod-affinity</span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">pod-affinity-76c56567c-792n4   1/1     Running   0          2m59s   10.244.2.254   node2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-affinity-76c56567c-8s2pd   1/1     Running   0          3m53s   10.244.4.18    node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-affinity-76c56567c-hx7ck   1/1     Running   0          2m52s   10.244.3.23    node2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>可以看到现在是分别运行在2个节点下面的，因为他们都属于 <code>beta.kubernetes.io/os</code> 这个拓扑域。</p>
<h3 id="Pod-反亲和性"><a href="#Pod-反亲和性" class="headerlink" title="Pod 反亲和性"></a>Pod 反亲和性</h3><p>Pod 反亲和性（podAntiAffinity）则是反着来的，比如一个节点上运行了某个 Pod，那么我们的模板 Pod 则不希望被调度到这个节点上面去了。我们把上面的 <code>podAffinity</code> 直接改成 <code>podAntiAffinity</code>：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pod-antiaffinity-demo.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-antiaffinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">pod-antiaffinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">pod-antiaffinity</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">pod-antiaffinity</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginxweb</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 硬策略</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">busybox-pod</span></span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure>



<p>这里的意思就是如果一个节点上面有一个 <code>app=busybox-pod</code> 这样的 Pod 的话，那么我们的 Pod 就别调度到这个节点上面来，上面我们把<code>app=busybox-pod</code> 这个 Pod 固定到了 node2 这个节点上面的，所以正常来说我们这里的 Pod 不会出现在该节点上：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f pod-antiaffinity-demo.yaml</span><br><span class="line">deployment.apps/pod-antiaffinity created</span><br><span class="line">➜ kubectl get pods -l app=pod-antiaffinity -o wide</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">pod-antiaffinity-84d5bf9df4-9c9qk   1/1     Running   0          73s   10.244.4.19   node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-antiaffinity-84d5bf9df4-q6lkm   1/1     Running   0          67s   10.244.3.24   node1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod-antiaffinity-84d5bf9df4-vk9tc   1/1     Running   0          57s   10.244.3.25   node1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>我们可以看到没有被调度到 node2 节点上，因为我们这里使用的是 Pod 反亲和性。大家可以思考下，如果这里我们将拓扑域更改成 <code>beta.kubernetes.io/os</code> 会怎么样呢？可以自己去测试下看看。</p>
<h2 id="污点与容忍"><a href="#污点与容忍" class="headerlink" title="污点与容忍"></a>污点与容忍</h2><p>对于 <code>nodeAffinity</code> 无论是硬策略还是软策略方式，都是调度 Pod 到预期节点上，而污点（Taints）恰好与之相反，如果一个节点标记为 Taints ，除非 Pod 也被标识为可以容忍污点节点，否则该 Taints 节点不会被调度 Pod。</p>
<p>比如用户希望把 Master 节点保留给 Kubernetes 系统组件使用，或者把一组具有特殊资源预留给某些 Pod，则污点就很有用了，Pod 不会再被调度到 taint 标记过的节点。我们使用 kubeadm 搭建的集群默认就给 master 节点添加了一个污点标记，所以我们看到我们平时的 Pod 都没有被调度到 master 上去：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl describe node master1</span><br><span class="line">Name:               master1</span><br><span class="line">Roles:              master</span><br><span class="line">Labels:             beta.kubernetes.io/arch=amd64</span><br><span class="line">                    beta.kubernetes.io/os=linux</span><br><span class="line">                    kubernetes.io/arch=amd64</span><br><span class="line">                    kubernetes.io/hostname=master1</span><br><span class="line">                    kubernetes.io/os=linux</span><br><span class="line">                    node-role.kubernetes.io/master=</span><br><span class="line">......</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br><span class="line">Unschedulable:      false</span><br><span class="line">......</span><br></pre></td></tr></table></figure>



<p>我们可以使用上面的命令查看 master 节点的信息，其中有一条关于 Taints 的信息：<code>node-role.kubernetes.io/master:NoSchedule</code>，就表示master 节点打了一个污点的标记，其中影响的参数是 <code>NoSchedule</code>，表示 Pod 不会被调度到标记为 taints 的节点，除了 <code>NoSchedule</code> 外，还有另外两个选项：</p>
<ul>
<li>PreferNoSchedule：NoSchedule 的软策略版本，表示尽量不调度到污点节点上去</li>
<li>NoExecute：该选项意味着一旦 Taint 生效，如该节点内正在运行的 Pod 没有对应容忍（Tolerate）设置，则会直接被逐出</li>
</ul>
<p>污点 taint 标记节点的命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl taint nodes node2 test=node2:NoSchedule</span><br><span class="line">node &quot;node2&quot; tainted</span><br></pre></td></tr></table></figure>



<p>上面的命名将 node2 节点标记为了污点，影响策略是 <code>NoSchedule</code>，只会影响新的 Pod 调度，如果仍然希望某个 Pod 调度到 taint 节点上，则必须在 Spec 中做出 Toleration 定义，才能调度到该节点，比如现在我们想要将一个 Pod 调度到 master 节点：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># taint-demo.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">taint</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">taint</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">taint</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">taint</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;node-role.kubernetes.io/master&quot;</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></span><br></pre></td></tr></table></figure>



<p>由于 master 节点被标记为了污点，所以我们这里要想 Pod 能够调度到改节点去，就需要增加容忍的声明：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;node-role.kubernetes.io/master&quot;</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></span><br></pre></td></tr></table></figure>



<p>然后创建上面的资源，查看结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl apply -f taint-demo.yaml</span><br><span class="line">deployment.apps &quot;taint&quot; created</span><br><span class="line">➜ kubectl get pods -o wide</span><br><span class="line">NAME                                      READY     STATUS             RESTARTS   AGE       IP             NODE</span><br><span class="line">......</span><br><span class="line">taint-845d8bb4fb-57mhm                    1/1       Running            0          1m        10.244.4.247   node2</span><br><span class="line">taint-845d8bb4fb-bbvmp                    1/1       Running            0          1m        10.244.0.33    master1</span><br><span class="line">taint-845d8bb4fb-zb78x                    1/1       Running            0          1m        10.244.4.246   node2</span><br><span class="line">......</span><br></pre></td></tr></table></figure>



<p>我们可以看到有一个 Pod 副本被调度到了 master 节点，这就是容忍的使用方法。</p>
<p>对于 <code>tolerations</code> 属性的写法，其中的 key、value、effect 与 Node 的 Taint 设置需保持一致， 还有以下几点说明：</p>
<ul>
<li>如果 operator 的值是 <code>Exists</code>，则 value 属性可省略</li>
<li>如果 operator 的值是 <code>Equal</code>，则表示其 key 与 value 之间的关系是 equal(等于)</li>
<li>如果不指定 operator 属性，则默认值为 <code>Equal</code></li>
</ul>
<p>另外，还有两个特殊值：</p>
<ul>
<li>空的 key 如果再配合 <code>Exists</code> 就能匹配所有的 key 与 value，也就是是能容忍所有节点的所有 Taints</li>
<li>空的 effect 匹配所有的 effect</li>
</ul>
<p>最后如果我们要取消节点的污点标记，可以使用下面的命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl taint nodes node2 test-</span><br><span class="line">node &quot;node2&quot; untainted</span><br></pre></td></tr></table></figure>



<h2 id="课后习题"><a href="#课后习题" class="headerlink" title="课后习题"></a>课后习题</h2><p><strong>1.不用 DaemonSet，如何使用 Deployment 是否实现同样的功能？</strong></p>
<p>我们知道 DaemonSet 控制器的功能就是在每个节点上运行一个 Pod，如何要使用 Deployment 来实现，首先就要设置副本数量为节点数，比如我们这里加上 master 节点一共3个节点，则要设置3个副本，要在 master 节点上执行自然要添加容忍，那么要如何保证一个节点上只运行一个 Pod 呢？是不是前面的提到的 Pod 反亲和性就可以实现，以自己 Pod 的标签来进行过滤校验即可，新的 Pod 不能运行在一个已经具有该 Pod 的节点上，是不是就是一个节点只能运行一个？模拟的资源清单如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mock-ds-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">mock-ds-demo</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mock-ds-demo</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;node-role.kubernetes.io/master&quot;</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">ngpt</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span>  <span class="comment"># pod反亲合性</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span>  <span class="comment"># 硬策略</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span>   <span class="comment"># Pod的标签</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span> [<span class="string">&quot;mock-ds-demo&quot;</span>]</span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span>  <span class="comment"># 以hostname为拓扑域</span></span><br></pre></td></tr></table></figure>



<p>创建上面的资源清单验证：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜ kubectl get nodes</span><br><span class="line">NAME      STATUS   ROLES                  AGE   VERSION</span><br><span class="line">master1   Ready    control-plane,master   84d   v1.22.2</span><br><span class="line">node1     Ready    &lt;none&gt;                 84d   v1.22.2</span><br><span class="line">node2     Ready    &lt;none&gt;                 84d   v1.22.2</span><br><span class="line">➜ kubectl get pods -l app=mock-ds-demo -o wide</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES</span><br><span class="line">mock-ds-demo-8694759c69-tgqld   1/1     Running   0          30s   10.244.1.198   node1     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">mock-ds-demo-8694759c69-wtnwv   1/1     Running   0          30s   10.244.2.29    node2     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">mock-ds-demo-8694759c69-zt9pp   1/1     Running   0          30s   10.244.0.135   master1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<p>可以看到我们用 Deployment 部署的服务在每个节点上都运行了一个 Pod，实现的效果和 DaemonSet 是一致的。</p>
<p><strong>2.同样的如果想在每个节点（或指定的一些节点）上运行2个（或多个）Pod 副本，如何实现？</strong></p>
<p>DaemonSet 是在每个节点上运行1个 Pod 副本，显然我们去创建2个（或多个）DaemonSet 即可实现该目标，但是这不是一个好的接近方案，而 <code>PodAntiAffinity</code> 只能将一个 Pod 调度到某个拓扑域中去，所以都不能很好的来解决这个问题。</p>
<p>要实现这种更细粒度的控制，我们可以通过设置拓扑分布约束来进行调度，设置拓扑分布约束来将 Pod 分布到不同的拓扑域下，从而实现高可用性或节省成本，具体实现方式请看下文。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">六一</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">273</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/huiaz" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;huiaz" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">六一</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">1.7m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">25:34</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
