<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>在 Kubernetes 上部署 LLM 大语言模型 | Hui's Blog</title><meta name="author" content="六一"><meta name="copyright" content="六一"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="在 Kubernetes 上部署 LLM 大语言模型从今年开始，人们对大型语言模型 (LLM) 及其在 GPU 基础设施上的部署的兴趣显着增加。这种不断增长的热情是由人工智能和机器学习的进步推动的，这需要 GPU 能够有效提供大量的计算能力。GPU 领先制造商 Nvidia 的股价也因这一趋势而飙升。同样诞生了大量的大模型，对于这些模型的部署和管理也变得越来越重要，在这方面 Ollama 和 Op">
<meta property="og:type" content="article">
<meta property="og:title" content="在 Kubernetes 上部署 LLM 大语言模型">
<meta property="og:url" content="http://example.com/2025/09/11/%E5%9C%A8%20Kubernetes%20%E4%B8%8A%E9%83%A8%E7%BD%B2%20LLM%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Hui&#39;s Blog">
<meta property="og:description" content="在 Kubernetes 上部署 LLM 大语言模型从今年开始，人们对大型语言模型 (LLM) 及其在 GPU 基础设施上的部署的兴趣显着增加。这种不断增长的热情是由人工智能和机器学习的进步推动的，这需要 GPU 能够有效提供大量的计算能力。GPU 领先制造商 Nvidia 的股价也因这一趋势而飙升。同样诞生了大量的大模型，对于这些模型的部署和管理也变得越来越重要，在这方面 Ollama 和 Op">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-09-11T12:32:34.000Z">
<meta property="article:modified_time" content="2025-09-11T14:20:02.254Z">
<meta property="article:author" content="六一">
<meta property="article:tag" content="运维">
<meta property="article:tag" content="k8s">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "在 Kubernetes 上部署 LLM 大语言模型",
  "url": "http://example.com/2025/09/11/%E5%9C%A8%20Kubernetes%20%E4%B8%8A%E9%83%A8%E7%BD%B2%20LLM%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/",
  "image": "http://example.com/img/butterfly-icon.png",
  "datePublished": "2025-09-11T12:32:34.000Z",
  "dateModified": "2025-09-11T14:20:02.254Z",
  "author": [
    {
      "@type": "Person",
      "name": "六一",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/09/11/%E5%9C%A8%20Kubernetes%20%E4%B8%8A%E9%83%A8%E7%BD%B2%20LLM%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '在 Kubernetes 上部署 LLM 大语言模型',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">274</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Hui's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">在 Kubernetes 上部署 LLM 大语言模型</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">在 Kubernetes 上部署 LLM 大语言模型</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-11T12:32:34.000Z" title="发表于 2025-09-11 20:32:34">2025-09-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-11T14:20:02.254Z" title="更新于 2025-09-11 22:20:02">2025-09-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/k8s/">k8s</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/k8s/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="在-Kubernetes-上部署-LLM-大语言模型"><a href="#在-Kubernetes-上部署-LLM-大语言模型" class="headerlink" title="在 Kubernetes 上部署 LLM 大语言模型"></a>在 Kubernetes 上部署 LLM 大语言模型</h1><p>从今年开始，人们对大型语言模型 (LLM) 及其在 GPU 基础设施上的部署的兴趣显着增加。这种不断增长的热情是由人工智能和机器学习的进步推动的，这需要 GPU 能够有效提供大量的计算能力。GPU 领先制造商 Nvidia 的股价也因这一趋势而飙升。同样诞生了大量的大模型，对于这些模型的部署和管理也变得越来越重要，在这方面 <code>Ollama</code> 和 <code>OpenUI</code> 是一个不错的选择。</p>
<p><a target="_blank" rel="noopener" href="https://ollama.com/">Ollama</a> 是一个开源的机器学习模型部署工具，它可以帮助您将模型部署到生产环境中，简化大型语言模型 (LLM) 的管理和交互。Ollama 拥有各种一流的开源模型，例如 <code>Llama 3</code>、<code>Phi 3</code>、<code>Mistral</code> 等等，我们可以将 Ollama 看成是 Docker，但是专注于机器学习模型。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/5y0t41.png" alt="img"></p>
<p>使用 <code>Ollama</code> 部署模型非常简单，就类似于使用 Docker 部署应用程序一样。但是，如果你对 CLI 不熟悉，那么使用 <code>Ollama</code> 会有点痛苦。为了解决这个问题，我们可以使用一个 <a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui">open-webui</a> 的项目，它提供了一个漂亮的界面，可以让您更轻松地部署模型。</p>
<p>为了更好地管理 Ollama，我们可以将 Ollama 部署到 Kubernetes 集群中。这样，我们就可以更好地管理 Ollama，而不需要担心 Ollama 的高可用性、扩展性等问题。</p>
<p>当然首先需要一个 Kubernetes 集群，最好带有 GPU，但即使没有 GPU，<code>llama3</code> 模型在仅使用 CPU 的情况下也能表现得相对较好。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl version</span><br><span class="line">Client Version: v1.28.11</span><br><span class="line">Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3</span><br><span class="line">Server Version: v1.28.7</span><br></pre></td></tr></table></figure>

<h2 id="部署-Ollama-到-Kubernetes"><a href="#部署-Ollama-到-Kubernetes" class="headerlink" title="部署 Ollama 到 Kubernetes"></a>部署 Ollama 到 Kubernetes</h2><p>要部署 Ollama 和 Open-WebUI 到 Kubernetes 很简单，因为 Open-WebUI 项目提供了一个 Helm Chart，可以让我们更轻松地部署 Ollama 和 Open-WebUI。这个 charts 包被托管在 <a target="_blank" rel="noopener" href="https://helm.openwebui.com/">https://helm.openwebui.com</a>，我们可以使用 Helm 添加这个 repo：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add open-webui https://helm.openwebui.com/</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure>

<p><code>open-webui</code> 这个 charts 包默认情况下会部署 <code>Ollama</code>，我们可以根据自己的需求进行配置，例如我们可以配置 <code>Ollama</code> 是否使用 GPU，是否开启数据持久化等等，我们可以覆盖默认的配置来进行配置，如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># myvalues.yaml</span></span><br><span class="line"><span class="attr">ollama:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span> <span class="comment"># 自动安装 Ollama Helm Chart</span></span><br><span class="line">  <span class="attr">ollama:</span> <span class="comment"># 配置 Ollama</span></span><br><span class="line">    <span class="attr">gpu:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span> <span class="comment"># 是否使用 GPU</span></span><br><span class="line">    <span class="comment">#   type: &#x27;nvidia&#x27;</span></span><br><span class="line">    <span class="comment">#   number: 1</span></span><br><span class="line">    <span class="comment"># models:  # 容器启动的时候加载的模型</span></span><br><span class="line">    <span class="comment">#  - llama3</span></span><br><span class="line">    <span class="comment">#  - mistral</span></span><br><span class="line">  <span class="attr">persistentVolume:</span> <span class="comment"># 配置持久化存储</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">storageClass:</span> <span class="string">nfs-client</span> <span class="comment"># 指定 storageClass</span></span><br><span class="line">    <span class="comment"># existingClaim: &quot;&quot;  # 也可以使用已经存在的 PVC</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ========== Pipelines 配置 ==========</span></span><br><span class="line"></span><br><span class="line"><span class="attr">pipelines:</span> <span class="comment"># OpenAI API 插件框架</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">persistence:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">service:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ========== open-webui 配置 ==========</span></span><br><span class="line"><span class="comment"># ingress: # 配置 Ingress</span></span><br><span class="line"><span class="comment">#   enabled: false</span></span><br><span class="line"><span class="comment">#   host: &quot;open-webui.example.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置持久化存储</span></span><br><span class="line"><span class="attr">persistence:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">#   existingClaim: &quot;&quot;  # 也可以使用已经存在的 PVC</span></span><br><span class="line">  <span class="attr">storageClass:</span> <span class="string">&quot;nfs-client&quot;</span> <span class="comment"># 指定 storageClass</span></span><br><span class="line"></span><br><span class="line"><span class="attr">service:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> <span class="comment"># 设置 Service 类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定 OpenAI API URL，如果不指定，默认使用 Pipelines 服务的端点  https://api.openai.com/v1</span></span><br><span class="line"><span class="comment"># openaiBaseApiUrl: &quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置额外的环境变量</span></span><br><span class="line"><span class="attr">extraEnvVars:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HF_ENDPOINT</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">https://hf-mirror.com</span></span><br><span class="line"><span class="comment"># - name: OPENAI_API_KEY # 指定 OpenAI API Key</span></span><br><span class="line"><span class="comment">#   value: &quot;0p3n-w3bu!&quot;</span></span><br></pre></td></tr></table></figure>

<p>在上面的配置中，我们可以配置 <code>Ollama</code> 是否使用 GPU，是否开启数据持久化等等，对于 <code>open-webui</code> 部分，我们配置的是一个 <code>NodePort</code> 类型的 Service，这样我们就可以通过 Node 的 IP 和 NodePort 来访问 Open-WebUI 项目，当然你也可以配置 Ingress 来访问。</p>
<blockquote>
<p>注意：Open-WebUI 项目默认会去访问 <code>huggingface</code> 的模型仓库，因为某些原因，默认情况下国内是无法访问的，所以我们需要配置 <code>HF_ENDPOINT</code> 环境变量来指定一个镜像地址 <code>https://hf-mirror.com</code>，否则会出错。</p>
</blockquote>
<p>然后我们可以使用 Helm 安装这个 charts 包：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade --install ollama open-webui/open-webui -f myvalues.yaml --create-namespace --namespace kube-ai</span><br></pre></td></tr></table></figure>

<p>部署完成后，会在 <code>kube-ai</code> 这个命名空间下运行几个 Pod，我们可以查看 Pod 的状态：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-ai</span><br><span class="line">NAME                                    READY   STATUS    RESTARTS        AGE</span><br><span class="line">open-webui-0                            1/1     Running   0               2m11s</span><br><span class="line">open-webui-ollama-944dd68fc-wxsjf       1/1     Running   0               24h</span><br><span class="line">open-webui-pipelines-557f6f95cd-dfgh8   1/1     Running   0               25h</span><br></pre></td></tr></table></figure>

<p>因为上面我们配置的是 <code>NodePort</code> 类型的 Service，所以我们可以通过 Node 的 IP 和 NodePort 来访问 Open-WebUI 项目：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get svc -n kube-ai</span><br><span class="line">NAME                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">open-webui             NodePort    10.96.1.212   &lt;none&gt;        80:31009/TCP     25h</span><br><span class="line">open-webui-ollama      ClusterIP   10.96.2.112   &lt;none&gt;        11434/TCP        25h</span><br><span class="line">open-webui-pipelines   NodePort    10.96.2.170   &lt;none&gt;        9099:32322/TCP   25h</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>现在我们就可以通过 <code>http://NodeIP:31009</code> 来访问 Open-WebUI 项目了。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/hucrq0.png" alt="img"></p>
<p>第一次使用的时候需要注册一个账号，然后我们就可以登录到 Open-WebUI 项目主页了。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/uzhcjk.png" alt="img"></p>
<p>如果你有 <code>ollama</code> 在其他地方运行，我们可以将其添加为另一个连接。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/7j8rpp.png" alt="img"></p>
<p>首先需要配置连接 <code>ollama</code> 的地址，然后我们就可以连接到 <code>ollama</code> 了，连接成功后，我们就可以看到 <code>ollama</code> 的模型列表了。</p>
<p>点击左下角的用户头像，然后选择 <code>管理员面板</code>，在管理员面板页面选择 <code>设置</code> 标签页，然后切换到 <code>外部连接</code> 配置项，我们可以设置 <code>Ollama API</code> 地址，我们这里使用的是 Helm 部署的 <code>Ollama</code>，默认已经为我们配置好了 <code>Ollama API</code> 地址。</p>
<p>接下来切换到 <code>模型</code> 标签页，我们就可以从 <code>Ollama</code> 的模型仓库中拉取模型了，可以下载的模型可以从 <code>https://ollama.com/library</code> 查看。比如我们这里选择 <code>llama3</code> 模型，输入 <code>llama3</code> 然后点击右侧的拉取下载按钮，就会开始下载这个模型了，在页面中也可以看到下载的进度。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/irjyks.png" alt="img"></p>
<p>模型拉取完成后，切回到首页，我们就可以选择切换到 <code>llama3</code> 模型了。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/cmo4xw.png" alt="img"></p>
<p>接下来我们就可以使用 <code>llama3</code> 模型为我们服务了。</p>
<p><img src="https://mudutestmenu.mudu.tv/upload/h2auy4.png" alt="img"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在本文中，我们探讨了使用 Open WebUI 在 Kubernetes 集群上部署 <code>llama3</code> 的过程。通过容器化和编排技术，我们成功地将 AI powered 的聊天机器人部署到了可扩展和维护的环境中。Open WebUI 的简洁界面和 Kubernetes 的强大自动化能力，让我们简化了部署过程，减少了手动干预。随着世界对 AI 驱动解决方案的不断依赖，这种技术组合将扮演关键角色，快速地带领创新应用程序 llama3 告诉市场。 AI Powered 的聊天机器人的未来看起来非常光明，Open WebUI 和 Kubernetes 将继续领先，期待着下一个令人兴奋的发展！（这一段就来自 <code>llama3</code> 模型生成）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">六一</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/09/11/%E5%9C%A8%20Kubernetes%20%E4%B8%8A%E9%83%A8%E7%BD%B2%20LLM%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">http://example.com/2025/09/11/%E5%9C%A8%20Kubernetes%20%E4%B8%8A%E9%83%A8%E7%BD%B2%20LLM%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">Hui's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%BF%90%E7%BB%B4/">运维</a><a class="post-meta__tags" href="/tags/k8s/">k8s</a><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/09/11/%E5%9F%BA%E4%BA%8E%20Jenkins%E3%80%81Gitlab%E3%80%81Harbor%E3%80%81Helm%20%E5%92%8C%20Kubernetes%20%E7%9A%84%20CICD/" title="基于 Jenkins、Gitlab、Harbor、Helm 和 Kubernetes 的 CICD"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">基于 Jenkins、Gitlab、Harbor、Helm 和 Kubernetes 的 CICD</div></div><div class="info-2"><div class="info-item-1">基于 Jenkins、Gitlab、Harbor、Helm 和 Kubernetes 的 CI&#x2F;CD上节课和大家介绍了Gitlab CI结合Kubernetes进行 CI&#x2F;CD 的完整过程。这节课结合前面所学的知识点给大家介绍一个完整的示例：使用 Jenkins + Gitlab + Harbor + Helm + Kubernetes 来实现一个完整的 CI&#x2F;CD 流水线作业。 其实前面的课程中我们就已经学习了 Jenkins Pipeline 与 Kubernetes 的完美结合，我们利用 Kubernetes 来动态运行 Jenkins 的 Slave 节点，可以和好的来解决传统的 Jenkins Slave 浪费大量资源的缺点。之前的示例中我们是将项目放置在 Github 仓库上的，将 Docker 镜像推送到了 Docker Hub，这节课我们来结合我们前面学习的知识点来综合运用下，使用 Jenkins、Gitlab、Harbor、Helm、Kubernetes 来实现一个完整的持续集成和持续部署的流水线作业。 流程下图是我们当前示例的流程...</div></div></div></a><a class="pagination-related" href="/2025/09/11/%E5%8F%98%E5%8C%96%E7%8E%87/" title="变化率"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">变化率</div></div><div class="info-2"><div class="info-item-1">变化率通常来说直接绘制一个原始的 Counter 类型的指标数据用处不大，因为它们会一直增加，一般来说是不会去直接关心这个数值的，因为 Counter 一旦重置，总计数就没有意义了，比如我们直接执行下面的查询语句： 1demo_api_request_duration_seconds_count&#123;job=&quot;demo&quot;&#125;    可以得到下图所示的图形：  可以看到所有的都是不断增长的，一般来说我们更想要知道的是 Counter 指标的变化率，PromQL 提供了不同的函数来计算变化率。 rate用于计算变化率的最常见函数是 rate()，rate() 函数用于计算在指定时间范围内计数器平均每秒的增加量。因为是计算一个时间范围内的平均值，所以我们需要在序列选择器之后添加一个范围选择器。 例如我们要计算 demo_api_request_duration_seconds_count 在最近五分钟内的每秒平均变化率，则可以使用下面的查询语句： 1rate(demo_api_request_duration_seconds_count[5m])   ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/09/11/%E6%A3%80%E6%B5%8B/" title="检测"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-11</div><div class="info-item-2">检测</div></div><div class="info-2"><div class="info-item-1">检测本节我们将学习如何来检查我们的实例数据抓取健康状况。 检查抓取实例每当 Prometheus 抓取一个目标时，它都会存储一个合成的样本，其中包含指标名称 up 和被抓取实例的 job 和 instance 标签，如果抓取成功，则样本的值被设置为 1，如果抓取失败，则设置为 0，所以我们可以通过如下所示的查询来获取当前哪些实例处于正常或挂掉的状态： 1up&#123;job=&quot;demo&quot;&#125;  正常三个演示服务实例都处于正常状态，所以应该都为1。如果我们将第一个实例停掉，重新查询则第一个实例结果为0：  如果只希望显示 down 掉的实例，可以通过过滤0值来获取： 1up&#123;job=&quot;demo&quot;&#125; == 0   或者获取挂掉实例的总数： 1count by(job) (up&#123;job=&quot;demo&quot;&#125; == 0)   一般情况下这种类型的查询会用于指标抓取健康状态报警。  注意：因为 count() 是一个聚合运算符，它期望有一组维度的时间序列作为其输入，并且可以根据 by 或...</div></div></div></a><a class="pagination-related" href="/2025/09/11/kube-vip/" title="kube-vip"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-11</div><div class="info-item-2">kube-vip</div></div><div class="info-2"><div class="info-item-1">使用 kube-vip 搭建高可用 Kubernetes 集群kube-vip 可以在你的控制平面节点上提供一个 Kubernetes 原生的 HA 负载均衡，我们不需要再在外部设置 HAProxy 和 Keepalived 来实现集群的高可用了。 kube-vip 是一个为 Kubernetes 集群内部和外部提供高可用和负载均衡的开源项目，在 Vmware 的 Tanzu 项目中已经使用 kube-vip 替换了用于 vSphere 部署的 HAProxy 负载均衡器，本文我们将先来了解 kube-vip 如何用于 Kubernetes 控制平面的高可用和负载均衡功能。 特点Kube-Vip 最初是为 Kubernetes 控制平面提供 HA 解决方案而创建的，随着时间的推移，它已经发展为将相同的功能合并到 Kubernetes 的 LoadBalancer 类型的 Service 中了。  VIP 地址可以是 IPv4 或 IPv6 带有 ARP（第 2 层）或 BGP（第 3 层）的控制平面 使用领导选举或 raft 控制平面 带有 kubeadm（静态 Pod）的控制平...</div></div></div></a><a class="pagination-related" href="/2025/09/11/k8s_10/" title="k8s_10"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-11</div><div class="info-item-2">k8s_10</div></div><div class="info-2"><div class="info-item-1">请描述 Kubernetes 中的 Helm 的作用，并解释其使用场景。Of course. Helm is an indispensable tool in the Kubernetes ecosystem, and understanding its role is crucial for anyone managing applications at scale. Let’s dive into its purpose and common use cases. 🤔 分析过程：此问题旨在考察对Kubernetes应用部署和管理工具——Helm的理解。一个优秀的回答不能仅仅说“它是一个包管理器”，而需要深入解释它解决了什么核心痛点。核心痛点是：Kubernetes原生YAML文件缺乏模板化、版本控制和依赖管理能力，导致在多环境、复杂应用场景下难以管理。因此，回答的重点应围绕Helm如何通过打包（Charts）、模板化（Templating）和版本发布（Releases）来解决这些问题。 💡 答案生成：1. 概念或定义Helm 是Kubernetes的官方包管理器。它可以被...</div></div></div></a><a class="pagination-related" href="/2025/09/11/%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%20KubeBlocks/" title="数据管理平台 KubeBlocks"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-11</div><div class="info-item-2">数据管理平台 KubeBlocks</div></div><div class="info-2"><div class="info-item-1">云原生数据管理平台 KubeBlocksKubeBlocks 是基于 Kubernetes 的云原生数据基础设施，将顶级云服务提供商的大规模生产经验与增强的可用性和稳定性改进相结合，帮助用户轻松构建容器化、声明式的关系型、NoSQL、流计算和向量型数据库服务。  为什么需要 KubeBlocks？Kubernetes 已经成为容器编排的事实标准。它利用 ReplicaSet 提供的可扩展性和可用性以及 Deployment 提供的发布和回滚功能来管理日益增加的无状态工作负载。然而，管理有状态工作负载给 Kubernetes 带来了巨大的挑战，尽管 StatefulSet 提供了稳定的持久存储和唯一的网络标识符，但这些功能对于复杂的有状态工作负载来说远远不够。 为了应对这些挑战，并解决复杂性问题，KubeBlocks 引入了 ReplicationSet 和 ConsensusSet，具备以下能力：  基于角色的更新顺序可减少因升级版本、缩放和重新启动而导致的停机时间。 维护数据复制的状态，并自动修复复制错误或延迟。  KubeBlocks 具有以下特点：  支持多云，与 AWS、...</div></div></div></a><a class="pagination-related" href="/2025/09/11/Kubernetes%20%E5%AE%89%E5%85%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AE%BE%E7%BD%AE%E3%80%81/" title="Kubernetes 安全上下文设置、"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-11</div><div class="info-item-2">Kubernetes 安全上下文设置、</div></div><div class="info-2"><div class="info-item-1">Kubernetes 安全上下文设置在 Kubernetes 中安全地运行工作负载是很困的，有很多配置都可能会影响到整个 Kubernetes API 的安全性，这需要我们有大量的知识积累来正确的实施。Kubernetes 在安全方面提供了一个强大的工具 securityContext，每个 Pod 和容器清单都可以使用这个属性。在本文中我们将了解各种 securityContext 的配置，探讨它们的含义，以及我们应该如何使用它们。  securityContext 设置在 PodSpec 和ContainerSpec 规范中都有定义，这里我们分别用[P]和[C]来表示。需要注意的是，如果一个设置在两个作用域中都可以使用和配置，那么我们应该优先考虑设置容器级别的。  1. runAsNonRoot [P&#x2F;C]我们知道容器是使用 namespaces 和 cgroups 来限制其进程，但只要在部署的时候做了一次错误的配置，就可以让这些进程访问主机上的资源。如果该进程以 root 身份运行，它对这些资源的访问权限与主机 root 账户是相同的。此外，如果其他 pod 或容...</div></div></div></a><a class="pagination-related" href="/2025/09/11/k8s%20Namespace/" title="k8s Namespace"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-11</div><div class="info-item-2">k8s Namespace</div></div><div class="info-2"><div class="info-item-1">请描述 Kubernetes 中的 Namespace 的作用，并解释其使用场景。 🤔 分析过程：此问题考察的是对Kubernetes基本组织单元——Namespace（命名空间）的理解。一个优秀的回答需要解释其核心功能，即逻辑隔离，并能从不同维度（名称、资源、权限）阐述这种隔离。更重要的是，要能结合实际工作场景，说明为什么以及如何使用命名空间来组织集群，这直接反映了面试者的集群治理和多租户管理经验。 💡 答案生成：1. 概念或定义Namespace（命名空间）是Kubernetes中一种实现逻辑隔离的机制，它能将一个物理的Kubernetes集群划分为多个虚拟集群。每个命名空间都是一个独立的作用域，用于组织和隔离集群中的资源对象。 需要强调的是，这种隔离是逻辑上的，而非物理上的。不同命名空间中的Pod可能会运行在同一个物理节点上，但它们在API层面、策略层面和名称层面是相互隔离的。 2. Namespace 的核心作用Namespace为一组资源提供了三个维度的隔离：  1. 名称范围隔离 (Scope for Names):  作用： 这是最基本的作用。在同一个命名空间内...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">六一</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">274</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">45</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8-Kubernetes-%E4%B8%8A%E9%83%A8%E7%BD%B2-LLM-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">在 Kubernetes 上部署 LLM 大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2-Ollama-%E5%88%B0-Kubernetes"><span class="toc-number">1.1.</span> <span class="toc-text">部署 Ollama 到 Kubernetes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8"><span class="toc-number">1.2.</span> <span class="toc-text">使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.3.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/27/hexo-beautify/" title="Hexo 博客美化笔记：从零搭建高颜值技术博客">Hexo 博客美化笔记：从零搭建高颜值技术博客</a><time datetime="2026-02-27T04:00:00.000Z" title="发表于 2026-02-27 12:00:00">2026-02-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/11/Jenkens-Blue%20Ocean%20%E6%8F%92%E4%BB%B6/" title="Jenkins Blue Ocean">Jenkins Blue Ocean</a><time datetime="2025-09-11T12:42:57.000Z" title="发表于 2025-09-11 20:42:57">2025-09-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/11/jenkins-jenkinsfile/" title="Jenkins Jenkinsfile">Jenkins Jenkinsfile</a><time datetime="2025-09-11T12:40:44.000Z" title="发表于 2025-09-11 20:40:44">2025-09-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/11/shell-trap/" title="Linux-trap">Linux-trap</a><time datetime="2025-09-11T12:40:44.000Z" title="发表于 2025-09-11 20:40:44">2025-09-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/11/shell-%E6%95%B0%E7%BB%84/" title="Shell-数组">Shell-数组</a><time datetime="2025-09-11T12:40:44.000Z" title="发表于 2025-09-11 20:40:44">2025-09-11</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 六一</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.4</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body></html>